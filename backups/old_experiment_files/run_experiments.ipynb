{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ray.rllib.agents.trainer import Trainer, with_common_config\n",
    "from ray.rllib.utils.annotations import override\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.utils.seed import seed as rllib_seed\n",
    "import rl_toy\n",
    "from rl_toy.envs import RLToyEnv\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"RLToy-v0\", lambda config: RLToyEnv(config))\n",
    "\n",
    "# rllib_seed(0, 0, 0)\n",
    "ray.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space_sizes = [8, 10, 12, 14] # [2**i for i in range(1,6)]\n",
    "action_space_sizes = [2, 4, 8, 16] # [2**i for i in range(1,6)]\n",
    "delays = [0] + [2**i for i in range(5)]\n",
    "sequence_lengths = [i for i in range(1,6)]\n",
    "reward_densities = [0.25] # np.linspace(0.0, 1.0, num=5)\n",
    "# make_reward_dense = [True, False]\n",
    "terminal_state_densities = [0.25] # np.linspace(0.1, 1.0, num=5)\n",
    "algorithms = [\"DQN\"]\n",
    "\n",
    "print('# Algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density,'\n",
    "               'terminal_state_density ')\n",
    "print(algorithms, state_space_sizes, action_space_sizes, delays, sequence_lengths, reward_densities,\n",
    "      terminal_state_densities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over 5-10 runs\n",
    "# Keep minimum state size of 5 - so 1 terminal, 4 possible sequences of length 1 and 1 of them is rewarded - actually depends on densities\n",
    "# min action size of 2; max action size up to twice of state space size; \n",
    "# delay looks ok\n",
    "# sequence_lengths up to 6?\n",
    "\n",
    "# Hyperparam search over RL algo. hyperparams, optimizer hyperparams; only for max sequence length and min delay?\n",
    "# Hyperparams:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats\n",
    "# fout = open('rl_stats_temp.csv', 'a') #hardcoded\n",
    "# fout.write('# basename, n_points, n_features, n_trees ')\n",
    "\n",
    "# fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dir_name = '/home/rajanr/Backup/rl_toy'\n",
    "dir_name = '/home/rajanr/custom-gym-env' #run\n",
    "# stats_file = dir_name + '/' + 'lap_22' #Name of file to which benchmark stats were written\n",
    "stats_file = dir_name + '/' + '128' #Name of file to which benchmark stats were written20\n",
    "# stats_file = dir_name + '/' + 'rl_stats_temp_seeded_8.csv' #Name of file to which benchmark stats were written\n",
    "# rl_stats_temp_initial.csv has initial working run: All dynamics functions were randomly generated with diff. seeds\n",
    "# rl_stats_temp_seeded.csv has runs with fixed seeds for S and A, but not for Env. or Ray!!\n",
    "# rl_stats_temp_seeded_2.csv has another run like ...seeded.csv\n",
    "# rl_stats_temp_seeded_3.csv has same but for config space of S,A = 8,4 - so only 30 configs!\n",
    "# rl_stats_temp_seeded_4.csv has same seed for Env. also now - further restricted space (delay up to 8, seq_len of 1 or 2) - only 10 configs!\n",
    "# rl_stats_temp_seeded_5.csv same as 4 but seed for Ray would have differed\n",
    "# rl_stats_temp_seeded_6.csv same as 4 and tried using rllib_seed for Ray\n",
    "# rl_stats_temp_seeded_7.csv same as 4 and tried using rllib_seed for Ray\n",
    "# rl_stats_temp_seeded_8.csv uses completely_connected config - so S,A = 8,8, non-repeating sequences, ray agent seed to set a seed for it.\n",
    "# rl_stats_temp_seeded_9.csv same as 8\n",
    "# 10.csv same as 8\n",
    "# lap_1 removes \"hiddens\" layers\n",
    "# lap_2 and lap_3 are same\n",
    "# lap_4, lap_5, lap_6 have OHE\n",
    "# lap_7, 8, 9, 10 have runs with diff. NN sizes - 12 configs with fixed del, seq_len of 0, 1\n",
    "# lap_11, 12, 13 have fcnet_activation search - 3 configs and rest old \"default\" settings\n",
    "# lap_14, 15, 16 have learning_starts and target_net_upd_freqs - 5 x 3 = 15 configs;\n",
    "# lap_17, 18, 19 have double dqn tests - 2 configs\n",
    "# lap_20, 21, 22 (3x3 configs) same as 16 but changed target_net_upd_freq grid based on the results that higher value of 800 seemed much better for 14,15,16, also removed 1st and last values of learning_starts as it didn't seem to have much of an effect\n",
    "# 12.csv is with new target_nn_upd_freq but ran it for the 5x2 grid (of del x seq_len?) by mistake instead of NN size search\n",
    "# 13, 14 (4x3 configs of layers x width) is with nn search and new learning_starts of 1000 and target_net_upd_freq of 800\n",
    "# 15 changed widths to [128, 256, 512], rest same as 14\n",
    "# --16, 17 (5x2 configs) same as 12 but with Ray config[\"seed\"] set\n",
    "# --18, 19 same as 16 (with config seed of Ray) but with ray.init(local_mode=True)\n",
    "# 20, 21, 22 have 5x4 configs for learning_rates x adam_epsilon; \n",
    "# 23 same as 22 but changed adam_epsilon grid\n",
    "# 24 MAIN EXPERIMENT: has (5x4x10 configs of del x seq_len x seed): main experiment with DQN\n",
    "# 25 have (5x2x10 configs of del x seq_len x seed): main experiment with DQN; ran with wrong (smaller) grid for seq_len by mistake\n",
    "# 26: MAIN EXPERIMENT: (5x4x10 configs of del x seq_len x seed): main experiment with DQN; same as 24\n",
    "# 27: (5x4x10 configs of del x seq_len x seed): main experiment with DQN; same as 26 but with target_nn_upd_f=80 and learning_starts=2000 to see how poor hyperparam config. does\n",
    "# +28: (1x10 configs of seeds for del, seq of 0, 1): rest same as 26 but for 100,000 steps\n",
    "# +29: (1x10 configs of seeds for del, seq of 0, 1): rest same as 28 but for schedule_max_timesteps of 50,000\n",
    "# 30: A3C (5x2x3 configs of del x seq x seed): has some defaults for A3C run over diff. del x seq configs.\n",
    "# 31: ran 30 again by mistake\n",
    "# 32: (4x3x3 configs of num_layer x layer_width x seed): for HPO of NN size, rest same as 30\n",
    "# 33: (5x3x3 configs of lr x nn activation x seed): HPO, rest same as 32 (ran with NN of [256, 256] I think)\n",
    "# 34: (5x3x3 configs of lr x nn activation x seed): HPO, changed NN to [128, 128, 128] based on # 32, rest same as 33\n",
    "# 35: (4x3x3 configs of lambda x grad_clip x ...): HPO, keep lr and act. same based on 33 and 34: relu and sigmoid pretty bad in both\n",
    "# 36: (3x4x3 configs of vf_loss_coeff x entropy_coeff): HPO, changed lambda and grad_clip based on 35 to 0, 10\n",
    "# 37: MAIN EXPERIMENT: (5x4x10 of del x seq x seed): changed entropy_coeff to 0.1 based on 36\n",
    "# 38: LSTM (5x2x3 of del x seq x seed): used max_seq_len of LSTM = del + seq_len, rest same as 37\n",
    "# 39: (5x2x3 of del x seq x seed): changed lstm_use_prev_action_reward to True, rest same as 38\n",
    "# 40: (4x3x3 configs of num_layer x layer_width x seed): for HPO of NN size, rest same as 39 (because it seemed to do noisily better than 38)\n",
    "# 41: (5x3x3 configs of lr x nn activation x seed): HPO of lr and act., changed NN to [256, 256, 256, 256] based on 40\n",
    "# 42: (4x3x3 configs of lambda x grad_clip x ...): HPO, keep lr and act. same based on 41: sigmoid pretty bad in both\n",
    "# 43: (3x4x3 configs of vf_loss_coeff x entropy_coeff): HPO, changed lambda and grad_clip based on 42 to 1, 10\n",
    "# 44: (3x2x3 configs of lstm cell size x ... params): HPO, changed vf_loss_coeff and entropy_coeff to 0.1 based on 43\n",
    "# 45: MAIN EXPERIMENT: (5x4x10 of del x seq x seed): changed vf_loss_coeff and entropy_coeff to 0.1 based on 43\n",
    "# 46-50: Rainbow: (1x1x3 configs of del x seq x seed): has some defaults for rainbow; Faced problems with num_steps_trained to num_steps_sampled ratio\n",
    "# 51: (4x3x3 configs of num_layer x layer_width x seed): for HPO of NN size, train Batch size of 64, rest same as DQN best + some defaults for Rainbow.\n",
    "# 52: Tune rainbow params 1st and THEN the others: (4x3x3 configs of alpha x beta x seed): for HPO of rainbow params set 2 (forogt set 1), train Batch size of 64, rest same as DQN best + some defaults for Rainbow.\n",
    "# 53: (4x3x3 configs of n_step x num_atoms x seed): for HPO of rainbow params set 1, rest same as 52\n",
    "# 54: (4x3x3 configs of alpha x beta x seed): for HPO of rainbow params set 2, set n_step to 4, rest same as 53; seems num_steps trained is 16 times more now.\n",
    "# 55: (4x3x3 configs of num_layer x layer_width x seed): for HPO of NN size, train Batch size of 32, alpha = 0.75, rest same as 54\n",
    "# 56: (1x3x3 configs of nn activation x seed): HPO of nn_act., changed NN to [256, 256] based on 56 (512 was only slightly better - 256 should suffice, num_layers did not have a big impact)\n",
    "# 57: (1x5x3 configs of lr x seed): HPO of lr\n",
    "# 58: (4x3x3 configs of learning_starts x target_net_upd_freq): HPO; learning rate changed to 1e-3 based on 57\n",
    "# 59: MAIN EXPERIMENT: (5x4x10 of del x seq x seed): set learning_starts, target_net_upd_freq to 500, 80 based on 58\n",
    "# 60-69: Noise: initial experiments with transition and reward noise. In 66, changed evaluation_config to contain 0 noise.\n",
    "# 70: MAIN EXPERIMENT: Noises (6x6x10 of transition noise x reward noise)\n",
    "# 71-: Sparsity: \n",
    "# 72-91: Runs to fix evaluation_config to get proper eval metrics with a hack\n",
    "# 92: --MAIN EXPERIMENT: Sparsity: (1x4x10 of seq_len x seed): On best DQN config; eval results not proper due to Ray\n",
    "# 93: --MAIN EXPERIMENT: Noises A3C: Noises (5x5x10 of transition noise x reward noise) INTerrupted\n",
    "# 94: --MAIN EXPERIMENT: Noises A3C + LSTM: Noises (5x5x10 of transition noise x reward noise) INTerrupted\n",
    "# 95: Had to hack in more stuff for proper eval metrics.\n",
    "# 96: --MAIN EXPERIMENT: Sparsity: (1x3x10 of seq_len x seed): On best DQN config; eval horizon was unlimited!!\n",
    "# 97: --MAIN EXPERIMENT: Noises A3C: Noises (5x5x10 of transition noise x reward noise) INTerrupted, taking too long!\n",
    "# 98: Tried printing out eval rewards to make sure there are not multiple agents' rewards for A3C.\n",
    "# 99: --MAIN EXPERIMENT: Noises A3C + LSTM: Noises (5x5x10 of transition noise x reward noise) INTerrupted, taking too long!\n",
    "# 100: Tested horizon for eval metrics.\n",
    "# 101: relaunched 97 with eval horizon 100; INTerrupted due to Python Bus error\n",
    "# 102: relaunched 99 with eval horizon 100\n",
    "# 103: MAIN EXPERIMENT: (5x5x10 of del x seq x seed): relaunched 70 with eval metrics, eval horizon 100 and (5x5x10 of transition noise x reward noise)\n",
    "# 106: MAIN EXPERIMENT: (5x4x10 of del x seq x seed): relaunched 26 with eval metrics, eval horizon 100\n",
    "# 110: --MAIN EXPERIMENT: Noises Rainbow: (5x5x10 of transition noise x reward noise), eval horizon 100; INTerrupted by OS due to memory consumption\n",
    "# 111: MAIN EXPERIMENT: A3C (5x4x10 of del x seq x seed): relaunched 37 with eval metrics, eval horizon 100\n",
    "# 112: MAIN EXPERIMENT: A3C + LSTM (5x4x10 of del x seq x seed): relaunched 45 with eval metrics, eval horizon 100\n",
    "# 113: --MAIN EXPERIMENT: Noises Rainbow: (5x5x10 of transition noise x reward noise), eval horizon 100; relaunched 110 in parts due to memory leak issue\n",
    "# 114: --MAIN EXPERIMENT: Rainbow (5x4x10 of del x seq x seed); relaunched 59 with eval metrics, eval horizon 100; in parts due to memory leak issue\n",
    "# 115: MAIN EXPERIMENT: Noises A3C: (5x5x10 of transition noise x reward noise), eval horizon 100; relaunch of 97\n",
    "# 116: MAIN EXPERIMENT: Noises A3C + LSTM: (5x5x10 of transition noise x reward noise), eval horizon 100; relaunch of 99\n",
    "# 117: MAIN EXPERIMENT: Sparsity: (1x3x10 of seq_len x seed): On best DQN config; relaunch of 92\n",
    "# 118: MAIN EXPERIMENT: Sparsity A3C: (1x3x10 of seq_len x seed): On best A3C config;\n",
    "# 119: MAIN EXPERIMENT: Sparsity A3C + LSTM: (1x3x10 of seq_len x seed): On best A3C + LSTM config;\n",
    "# 120: MAIN EXPERIMENT: Sparsity Rainbow: (1x3x10 of seq_len x seed): On best Rainbow config;\n",
    "# 121: --MAIN EXPERIMENT: Rainbow (5x4x10 of del x seq x seed); Relaunched 114; apparently only ran 1st past of script, thanks to bash reloading from disk when running a new line\n",
    "# 122: MAIN EXPERIMENT: Noises Rainbow (5x5x10 of transition noise x reward noise); Relaunched 113\n",
    "# 123: MAIN EXPERIMENT: Rainbow (5x4x10 of del x seq x seed); Relaunched 114;\n",
    "# python custom_agents_sparsity_2.py 124 | tee 124.log\n",
    "# python custom_agents_a3c_sparsity_2.py 125 | tee 125.log\n",
    "# python custom_agents_a3c_lstm_sparsity_2.py 126 | tee 126.log\n",
    "# python custom_agents_rainbow_sparsity_2.py 127 | tee 127.log\n",
    "# 128: MAIN EXPERIMENT: Increase A3C + LSTM sequence length to 10 times old one and check results. (Had a mistake: 10 * delay + seq_len: should have had bracket around whole expression!!)\n",
    "# 129: MAIN EXPERIMENT: Launched # 129 with new Env seed for custom_agents.py to check effect of using a different env\n",
    "\n",
    "# ICML re-runs:\n",
    "# Some more in the 150s: need to check github commits for that\n",
    "# 159: --MAIN EXPERIMENT: Relaunched 111: A3C (5x4x10 of del x seq x seed): with timesteps_per_iteration = 1000 and timesteps_total = 20000\n",
    "# 160: --MAIN EXPERIMENT: Relaunched 112: A3C + LSTM (5x4x10 of del x seq x seed): with timesteps_per_iteration = 1000 and timesteps_total = 20000; Mistake: ran it with \"max_seq_len\": 10 * delay + sequence_length (it was another mistake to have not put brackets around delay + seq.len. when multiplying by 10 even in the old exp.!!)\n",
    "# 161: --MAIN EXPERIMENT: Relaunched 115: Noises A3C: (5x5x10 of transition noise x reward noise): with timesteps_per_iteration = 1000 and timesteps_total = 20000\n",
    "# 162: --MAIN EXPERIMENT: Relaunched 116: Noises A3C + LSTM: (5x5x10 of transition noise x reward noise): with timesteps_per_iteration = 1000 and timesteps_total = 20000\n",
    "# 163: --MAIN EXPERIMENT: Relaunched 160: A3C + LSTM (5x4x10 of del x seq x seed): with \"max_seq_len\": delay + sequence_length\n",
    "# 164: Relaunched 163: with \"max_seq_len\": 10 * (delay + sequence_length)\n",
    "# 165: --MAIN EXPERIMENT: Relaunched 118: Sparsity A3C: (1x3x10 of seq_len x seed): with timesteps_per_iteration = 1000 and timesteps_total = 20000\n",
    "# 166: --MAIN EXPERIMENT: Relaunched 119: Sparsity A3C + LSTM: (1x3x10 of seq_len x seed): with timesteps_per_iteration = 1000 and timesteps_total = 20000\n",
    "# 167: --MAIN EXPERIMENT: Relaunched 125: Sparsity 2 (changing reward densities) A3C (1x3x10 of rew dens x seed): with timesteps_per_iteration = 1000 and timesteps_total = 20000\n",
    "# 168: --MAIN EXPERIMENT: Relaunched 126: Sparsity 2 (changing reward densities) A3C + LSTM (1x3x10 of rew dens x seed): with timesteps_per_iteration = 1000 and timesteps_total = 20000\n",
    "\n",
    "# Final for paper: 103, 106, 111, 112, 115, 116, 117, 118, 119, 120, 123, more?\n",
    "# Others are in /home/rajanr/Backup/rl_toy files\n",
    "\n",
    "state_space_sizes = [8]#, 10, 12, 14] # [2**i for i in range(1,6)]\n",
    "action_space_sizes = [8]#2, 4, 8, 16] # [2**i for i in range(1,6)]\n",
    "delays = [0] + [2**i for i in range(4)]\n",
    "sequence_lengths = [1, 2]#i for i in range(1,4)]\n",
    "reward_densities = [0.25] # np.linspace(0.0, 1.0, num=5)\n",
    "# make_reward_dense = [True, False]\n",
    "terminal_state_densities = [0.25] # np.linspace(0.1, 1.0, num=5)\n",
    "algorithms = [\"DQN\"]\n",
    "\n",
    "print('# Algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density,'\n",
    "               'terminal_state_density ')\n",
    "print(algorithms, state_space_sizes, action_space_sizes, delays, sequence_lengths, reward_densities,\n",
    "      terminal_state_densities)\n",
    "\n",
    "\n",
    "print('# Algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density,'\n",
    "               'terminal_state_density ')\n",
    "print(algorithms, state_space_sizes, action_space_sizes, delays, sequence_lengths, reward_densities,\n",
    "      terminal_state_densities)\n",
    "\n",
    "datasets_info = np.loadtxt(stats_file + '.csv', dtype=object)\n",
    "print(datasets_info[0])\n",
    "print(datasets_info)\n",
    "print(type(datasets_info))\n",
    "print(datasets_info.shape)\n",
    "\n",
    "import pandas as pd\n",
    "stats_pd = pd.DataFrame(datasets_info)\n",
    "print(stats_pd[9])\n",
    "\n",
    "col_vals = np.array(datasets_info[:, 2:], dtype=float) # ignores 1st column - algo. name\n",
    "print(col_vals)\n",
    "#hack\n",
    "final_rows_for_a_config = []\n",
    "\n",
    "previous_i = 0\n",
    "list_of_learning_curves = []\n",
    "cols_to_take = 8\n",
    "for i in range(col_vals.shape[0] - 1):\n",
    "\n",
    "    if col_vals[i, -3] > col_vals[i + 1, -3]: #hack\n",
    "#         print(col_vals[i, 6])\n",
    "        list_of_learning_curves.append(col_vals[previous_i:i+1, -cols_to_take:])\n",
    "        previous_i = i + 1\n",
    "        final_rows_for_a_config.append(i)\n",
    "print(\"i, previous_i:\", i, previous_i)\n",
    "final_rows_for_a_config.append(i + 1)\n",
    "list_of_learning_curves.append(col_vals[previous_i:i + 2, -cols_to_take:])\n",
    "\n",
    "print(\"final_rows_for_a_config\", final_rows_for_a_config)\n",
    "print(\"len(final_rows_for_a_config), len(list_of_learning_curves)\",\n",
    "        len(final_rows_for_a_config), len(list_of_learning_curves))\n",
    "print(list_of_learning_curves[0])\n",
    "print(list_of_learning_curves[1])\n",
    "print(list_of_learning_curves[-1])\n",
    "total_in_lcs = 0\n",
    "for i in range(len(list_of_learning_curves)):\n",
    "    print(list_of_learning_curves[i].shape)\n",
    "    total_in_lcs += list_of_learning_curves[i].shape[0]\n",
    "print(\"total_in_lcs\", total_in_lcs)\n",
    "# print(col_vals[final_rows_for_a_config])\n",
    "final_vals = col_vals[final_rows_for_a_config]\n",
    "print(\"final_vals.shape\", final_vals.shape)\n",
    "# print(final_vals[-20:, :])\n",
    "metrics_ = final_vals[:, -3:]\n",
    "# print(metrics_)\n",
    "num_values_per_hyperparam = (1, 1, 1, 5, 4, 10, 1, 3) #hack\n",
    "metrics_reshaped = np.reshape(metrics_, num_values_per_hyperparam)\n",
    "print(\"metrics_reshaped.shape\", metrics_reshaped.shape)\n",
    "# print(\"metrics_reshaped[:, 0, 0, :, :, :, :, :]\", metrics_reshaped[:, 0, 0, :, :, :, :, :].shape, metrics_reshaped[:, 0, 0, :, :, :, :, :])\n",
    "to_plot_ = np.squeeze(metrics_reshaped[:, :, :, 0, 0, :, :, 1])\n",
    "print(to_plot_)\n",
    "\n",
    "# metrics_transposed = np.transpose(, ())\n",
    "\n",
    "# print(col_vals[:,0:1])\n",
    "# print(np.argwhere(col_vals[:,0:1] == [2, 2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading eval metrics from csv file\n",
    "# dir_name = '/home/rajanr/Backup/rl_toy'\n",
    "# dir_name = '/home/rajanr/custom-gym-env' #run\n",
    "# stats_file = dir_name + '/' + 'lap_22.csv' #Name of file to which benchmark stats were written\n",
    "stats_file_eval = stats_file + '_eval.csv' #Name of file to which benchmark stats were written\n",
    "eval_info = np.loadtxt(stats_file_eval, dtype=float)\n",
    "print(eval_info, eval_info.shape)\n",
    "\n",
    "i = 0\n",
    "hack_indices = []\n",
    "for line in open(stats_file_eval):\n",
    "    \n",
    "    line=line.strip()\n",
    "#    print(line)\n",
    "    if line.startswith(\"#HACK\"):\n",
    "#         print(line, i)\n",
    "        hack_indices.append(i - len(hack_indices)) # appends index of last eval in this training_iteration\n",
    "    i += 1\n",
    "    \n",
    "print(len(hack_indices), hack_indices)\n",
    "hack_indices_10 = np.array(hack_indices) - 10\n",
    "print(hack_indices_10.shape, hack_indices_10)\n",
    "print(np.array(hack_indices[1:]) - np.array(hack_indices[:-1]))\n",
    "print(\"Min:\", min(np.array(hack_indices[1:]) - np.array(hack_indices[:-1]))) # Some problem with Ray? Sometimes no. of eval episodes is less than 10.\n",
    "final_10_evals = []\n",
    "for i in range(len(hack_indices)):\n",
    "    final_10_evals.append(eval_info[hack_indices_10[i]:hack_indices[i]])\n",
    "#     print(final_10_evals[-1])\n",
    "\n",
    "final_10_evals = np.array(final_10_evals)\n",
    "print(final_10_evals.shape, final_10_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual plots of each seeded run of train metrics at end of training\n",
    "# fig = plt.figure(figsize=(9*4, 7*5)) #\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(np.arange(16).reshape((4, 4)), cmap='Purples', interpolation='none', extent=[2,32,2,8])\n",
    "# plt.colorbar()\n",
    "# # plt.xscale('log')\n",
    "# # plt.yscale('log')\n",
    "# # ticks = [1, 2]\n",
    "# # plt.xticks(ticks)\n",
    "# plt.title(\"ABC\")\n",
    "# plt.show()\n",
    "\n",
    "print('# Algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density,'\n",
    "               'terminal_state_density ')\n",
    "print(algorithms, state_space_sizes, action_space_sizes, delays, sequence_lengths, reward_densities,\n",
    "      terminal_state_densities)\n",
    "\n",
    "AVG = np.atleast_2d(np.squeeze(metrics_reshaped[:, 0, 0, :, :, 0, :, 1]).copy())\n",
    "AVG[:] = 0\n",
    "\n",
    "for k in range(metrics_reshaped.shape[-3]):\n",
    "    for i in range(len(state_space_sizes)):\n",
    "        for j in range(len(action_space_sizes)):\n",
    "            to_plot_ = np.squeeze(metrics_reshaped[:, i, j, :, :, k, :, 1])\n",
    "            print(np.squeeze(metrics_reshaped[:, i, j, :, :, k, :, 0]), metrics_reshaped[:, :, :, :, :, :, :, :].shape)\n",
    "            AVG += to_plot_\n",
    "            print(to_plot_)\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.imshow(np.atleast_2d(to_plot_), cmap='Purples', interpolation='none', vmin=0, vmax=np.max(to_plot_))#, extent=[0, 16, 8, 14])\n",
    "            plt.colorbar()\n",
    "    #         plt.xscale('log')\n",
    "    #         plt.yscale('log')\n",
    "            plt.title(str(state_space_sizes[i]) + ' ' + str(action_space_sizes[j]))\n",
    "            plt.show()\n",
    "\n",
    "print(\"AVG plot\")\n",
    "print(AVG)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(AVG/16, cmap='Purples', interpolation='none', vmin=0, vmax=np.max(to_plot_))#, extent=[0, 16, 8, 14])\n",
    "plt.colorbar()\n",
    "#         plt.xscale('log')\n",
    "#         plt.yscale('log')\n",
    "plt.title('AVG plot')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "AVG = np.squeeze(metrics_reshaped[:, :, :, 0, 0, :, :, 1].copy())\n",
    "AVG[:] = 0\n",
    "\n",
    "for i in range(len(delays)):\n",
    "    for j in range(len(sequence_lengths)):\n",
    "        to_plot_ = np.squeeze(metrics_reshaped[:, :, :, i, j, :, :, 1])\n",
    "        AVG += to_plot_\n",
    "        print(to_plot_)\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.imshow(to_plot_, cmap='Purples', interpolation='none', vmin=0, vmax=200)#, extent=[0, 16, 8, 14])\n",
    "        plt.colorbar()\n",
    "#         plt.xscale('log')\n",
    "#         plt.yscale('log')\n",
    "        plt.title(str(delays[i]) + ' ' + str(sequence_lengths[j]))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print(\"AVG plot\")\n",
    "print(AVG)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(AVG/16, cmap='Purples', interpolation='none', vmin=0, vmax=200)#, extent=[0, 16, 8, 14])\n",
    "plt.colorbar()\n",
    "#         plt.xscale('log')\n",
    "#         plt.yscale('log')\n",
    "plt.title('AVG plot')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9*4, 7*3)) #\n",
    "#ax_list = fig.axes\n",
    "for i in range(len(list_of_learning_curves)):\n",
    "#    for j in range(len(action_space_sizes)):\n",
    "    to_plot_ = list_of_learning_curves[i][:, 0:7]\n",
    "#         print(to_plot_)\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(to_plot_[:, -2], to_plot_[:, -1], label=\"noise \" + str(to_plot_[0, -4]) + \" seed \" + str(to_plot_[0, -3]))#, extent=[0, 16, 8, 14])\n",
    "#        plt.colorbar()\n",
    "#         plt.xscale('log')\n",
    "#         plt.yscale('log')\n",
    "plt.title('title')\n",
    "plt.legend(loc='upper left', prop={'size': 26})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVG_ = np.atleast_2d(np.squeeze(metrics_reshaped[:, 0, 0, :, :, 0, :, 1]).copy())\n",
    "# AVG_[:] = 0\n",
    "# temp_stack_ = []\n",
    "temp_stack_.append(metrics_reshaped[:, 0, 0, :, :, :, :, 1])\n",
    "print(temp_stack_[-1].shape, len(temp_stack_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hack these 2 cells.\n",
    "np_stack_ = np.concatenate(temp_stack_, axis=-1)\n",
    "print(np_stack_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots across 10 runs: Training: with std dev across the runs\n",
    "y_axis_label = 'Delay'\n",
    "x_axis_label = 'Sequence length'\n",
    "y_tick_labels_ = [0, 0, 1, 2, 4, 8]\n",
    "x_tick_labels_ = [0, 1, 2, 3, 4]\n",
    "y_axis_label = 'Transition noise'\n",
    "x_axis_label = 'Reward noise'\n",
    "y_tick_labels_ = [0, 0, 0.01, 0.02, 0.10, 0.25, 0.5]\n",
    "x_tick_labels_ = [0, 0, 1, 5, 10, 25, 100]\n",
    "# y_axis_label = 'Delay'\n",
    "# x_axis_label = 'Sequence Length'\n",
    "# y_tick_labels_ = [\"\", \"0\"]\n",
    "# x_tick_labels_ = [\"\", 2, \"\", 3, \" \", 4]\n",
    "\n",
    "y_axis_label = ''\n",
    "x_axis_label = 'Reward Density'\n",
    "y_tick_labels_ = [\"\", \"\"]\n",
    "x_tick_labels_ = [\"\", 0.25, \"\", 0.5, \" \", 0.75]\n",
    "\n",
    "# y_axis_label = 'n_step'\n",
    "# x_axis_label = 'n_atoms'\n",
    "# y_tick_labels_ = [\"\", 1,\"\", 2,\"\", 4,\"\", 8]\n",
    "# x_tick_labels_ = [0, 5, 10, 20]\n",
    "\n",
    "# y_axis_label = 'prioritized replay alpha'\n",
    "# x_axis_label = 'prioritized replay beta'\n",
    "# y_tick_labels_ = [\"\", 0.25, \"\", 0.5, \"\", 0.75, \"\", 1.0]\n",
    "# x_tick_labels_ = [0, 0.4, 0.7, 1.0]\n",
    "\n",
    "# y_axis_label = 'NN num layers'\n",
    "# x_axis_label = 'NN layer widths'\n",
    "# y_tick_labels_ = [\"\", 1, \"\", 2, \"\", 3, \"\", 4]\n",
    "# x_tick_labels_ = [0, 8, 32, 128]\n",
    "# x_tick_labels_ = [0, 128, 256, 512]\n",
    "\n",
    "# y_axis_label = ''\n",
    "# x_axis_label = 'NN neuron activation'\n",
    "# y_tick_labels_ = [\"\", \"\", \"\", 2, \"\", 3, \"\", 4]\n",
    "# x_tick_labels_ = [\"\", \"tanh\", \"\", \"relu\", \"\", \"sigmoid\"]\n",
    "\n",
    "# y_axis_label = ''\n",
    "# x_axis_label = 'Learning rate'\n",
    "# y_tick_labels_ = [\"\", \"\", \"\", 2, \"\", 3, \"\", 4]\n",
    "# x_tick_labels_ = [\"\", \"1e-2\", \"1e-3\", \"1e-4\", \"1e-5\", \"1e-6\", \"sigmoid\"]\n",
    "\n",
    "# y_axis_label = 'DQN learning starts'\n",
    "# x_axis_label = 'DQN target net update freq.'\n",
    "# y_tick_labels_ = [\"\", 500, \"\", 1000, \"\", 2000, \"\", 4000]\n",
    "# y_tick_labels_ = [\"\", 1000, \"\", 2000, \"\", 4000]\n",
    "# # y_tick_labels_ = [\"\", 500, \"1000\", 2000, \"4000\", 8000, \"\", 4000]\n",
    "# x_tick_labels_ = [0, 8, 80, 800]\n",
    "# x_tick_labels_ = [0, 80, \"\", 800, \"\", 8000]\n",
    "\n",
    "# y_axis_label = ''\n",
    "# x_axis_label = 'Double DQN'\n",
    "# y_tick_labels_ = [\"\", \"\", \"\", \"\",]\n",
    "# x_tick_labels_ = [0, \"False\", \"True\"]\n",
    "\n",
    "\n",
    "# y_axis_label = 'Learning rate'\n",
    "# x_axis_label = 'Adam epsilon'\n",
    "# y_tick_labels_ = [\"\", \"1e-2\", \"1e-3\", \"1e-4\", \"1e-5\", \"1e-6\"]\n",
    "# x_tick_labels_ = [\"\", \"1e-1\", \"1e-4\", \"1e-7\", \"1e-10\", \"\"]\n",
    "# x_tick_labels_ = [\"\", \"1e-3\", \"1e-4\", \"1e-5\", \"1e-6\", \"\"]\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "for i in range(len(state_space_sizes)):\n",
    "    for j in range(len(action_space_sizes)):\n",
    "        mean_data_ = np.mean(metrics_reshaped[:, i, j, :, :, :, :, 1], axis=-2)\n",
    "        to_plot_ = np.squeeze(mean_data_)\n",
    "#         mean_data_ = np.mean(np_stack_, axis=-1)\n",
    "#         to_plot_ = np.squeeze(mean_data_)\n",
    "        print(np.squeeze(metrics_reshaped[:, i, j, :, :, :, :, 0]),\n",
    "              metrics_reshaped[:, :, :, :, :, :, :, :].shape)\n",
    "        print(to_plot_, to_plot_.shape)\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.imshow(np.atleast_2d(to_plot_), cmap='Purples', interpolation='none', vmin=0, vmax=np.max(to_plot_) # 200 for DQN, 500 for A3C\n",
    "                  )#, extent=[1, 4, 3, 0])\n",
    "#         plt.xticks([1, 2])\n",
    "        plt.gca().set_xticklabels(x_tick_labels_)\n",
    "        plt.gca().set_yticklabels(y_tick_labels_)\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.ax.get_yaxis().labelpad = 15\n",
    "        cbar.set_label('Reward', rotation=270)\n",
    "        #plt.co\n",
    "#         plt.xscale('log')\n",
    "#         plt.yscale('log')\n",
    "#        plt.title('Final reward across Delay and Sequence length meta-features')\n",
    "        plt.xlabel(x_axis_label)\n",
    "        plt.ylabel(y_axis_label)\n",
    "        plt.show()\n",
    "        std_dev_ = np.std(metrics_reshaped[:, i, j, :, :, :, :, 1], axis=-2)\n",
    "        to_plot_ = np.squeeze(std_dev_)\n",
    "#         std_dev_ = np.std(np_stack_, axis=-1)\n",
    "#         to_plot_ = np.squeeze(std_dev_)\n",
    "        print(to_plot_, to_plot_.shape)\n",
    "        plt.imshow(np.atleast_2d(to_plot_), cmap='Purples', interpolation='none', vmin=0, vmax=np.max(to_plot_)) # 60 for DQN, 100 for A3C\n",
    "        #, extent=[0, 16, 8, 14])\n",
    "        plt.gca().set_xticklabels(x_tick_labels_)\n",
    "        plt.gca().set_yticklabels(y_tick_labels_)\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.ax.get_yaxis().labelpad = 15\n",
    "        cbar.set_label('Reward Std Dev.', rotation=270)\n",
    "#         plt.xscale('log')\n",
    "#         plt.yscale('log')\n",
    "#         plt.title(str(state_space_sizes[i]) + ' STD DEV ' + str(action_space_sizes[j]))\n",
    "        plt.xlabel(x_axis_label)\n",
    "        plt.ylabel(y_axis_label)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above but for eval metrics; Plots across 10 runs: with std dev across the runs\n",
    "y_axis_label = 'Delay'\n",
    "x_axis_label = 'Sequence length'\n",
    "y_tick_labels_ = [0, 0, 1, 2, 4, 8]\n",
    "x_tick_labels_ = [0, 1, 2, 3, 4]\n",
    "\n",
    "y_axis_label = 'Transition noise'\n",
    "x_axis_label = 'Reward noise'\n",
    "y_tick_labels_ = [0, 0, 0.01, 0.02, 0.10, 0.25, 0.5]\n",
    "x_tick_labels_ = [0, 0, 1, 5, 10, 25, 100]\n",
    "\n",
    "# y_axis_label = 'Delay'\n",
    "# x_axis_label = 'Sequence Length'\n",
    "# y_tick_labels_ = [\"\", \"0\"]\n",
    "# x_tick_labels_ = [\"\", 2, \"\", 3, \" \", 4]\n",
    "\n",
    "y_axis_label = ''\n",
    "x_axis_label = 'Reward Density'\n",
    "y_tick_labels_ = [\"\", \"\"]\n",
    "x_tick_labels_ = [\"\", 0.25, \"\", 0.5, \" \", 0.75]\n",
    "\n",
    "# final_vals = fin[final_rows_for_a_config]\n",
    "# print(\"final_vals.shape\", final_vals.shape)\n",
    "# # print(final_vals[-20:, :])\n",
    "\n",
    "print('final_rows_for_a_config', final_rows_for_a_config)\n",
    "print(\"len(final_10_evals)\", final_10_evals.shape, type(final_10_evals))\n",
    "mean_data_eval = np.mean(final_10_evals, axis=1) # this is mean over last 10 eval episodes\n",
    "print(mean_data_eval.shape, len(final_rows_for_a_config))\n",
    "final_eval_metrics_ = mean_data_eval[final_rows_for_a_config, -2:]\n",
    "print(final_eval_metrics_.shape)\n",
    "num_values_per_hyperparam = list(num_values_per_hyperparam)\n",
    "num_values_per_hyperparam[-1] = 2\n",
    "final_eval_metrics_reshaped = np.reshape(final_eval_metrics_, num_values_per_hyperparam)\n",
    "print(\"final_eval_metrics_reshaped.shape\", final_eval_metrics_reshaped.shape)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "for i in range(len(state_space_sizes)):\n",
    "    for j in range(len(action_space_sizes)):\n",
    "        mean_data_ = np.mean(final_eval_metrics_reshaped[:, i, j, :, :, :, :, 0], axis=-2)\n",
    "        to_plot_ = np.squeeze(mean_data_)\n",
    "        print(np.squeeze(final_eval_metrics_reshaped[:, i, j, :, :, :, :, 0]),\n",
    "              final_eval_metrics_reshaped[:, :, :, :, :, :, :, :].shape)\n",
    "        print(to_plot_, to_plot_.shape)\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.imshow(np.atleast_2d(to_plot_), cmap='Purples', interpolation='none', vmin=0, vmax=np.max(to_plot_) # 200 for DQN, 500 for A3C\n",
    "                  )#, extent=[1, 4, 3, 0])\n",
    "#         plt.xticks([1, 2])\n",
    "        plt.gca().set_xticklabels(x_tick_labels_)\n",
    "        plt.gca().set_yticklabels(y_tick_labels_)\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.ax.get_yaxis().labelpad = 15\n",
    "        cbar.set_label('Reward', rotation=270)\n",
    "        #plt.co\n",
    "#         plt.xscale('log')\n",
    "#         plt.yscale('log')\n",
    "#        plt.title('Final reward across Delay and Sequence length meta-features')\n",
    "        plt.xlabel(x_axis_label)\n",
    "        plt.ylabel(y_axis_label)\n",
    "        plt.show()\n",
    "        std_dev_ = np.std(final_eval_metrics_reshaped[:, i, j, :, :, :, :, 0], axis=-2)\n",
    "        to_plot_ = np.squeeze(std_dev_)\n",
    "        print(to_plot_, to_plot_.shape)\n",
    "        plt.imshow(np.atleast_2d(to_plot_), cmap='Purples', interpolation='none', vmin=0, vmax=np.max(to_plot_)) # 60 for DQN, 100 for A3C\n",
    "        #, extent=[0, 16, 8, 14])\n",
    "        plt.gca().set_xticklabels(x_tick_labels_)\n",
    "        plt.gca().set_yticklabels(y_tick_labels_)\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.ax.get_yaxis().labelpad = 15\n",
    "        cbar.set_label('Reward Std Dev.', rotation=270)\n",
    "#         plt.xscale('log')\n",
    "#         plt.yscale('log')\n",
    "#         plt.title(str(state_space_sizes[i]) + ' STD DEV ' + str(action_space_sizes[j]))\n",
    "        plt.xlabel(x_axis_label)\n",
    "        plt.ylabel(y_axis_label)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for train metrics: learning curves\n",
    "#fig = plt.figure(figsize=(9*4, 7*3)) #\n",
    "color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "print(\"color_cycle\", color_cycle)\n",
    "seq_lens = [2, 3, 4]\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "# metrics_reshaped_squeezed = np.squeeze(metrics_reshaped)\n",
    "# print(np.squeeze(metrics_reshaped).shape)\n",
    "delays = [0] + [2**i for i in range(4)]\n",
    "sequence_lengths = [1, 2, 3, 4]#i for i in range(1,4)]\n",
    "# transition_noises = [0, 0.01, 0.02, 0.10, 0.25]\n",
    "# reward_noises = [0, 1, 5, 10, 25] # Std dev. of normal dist. #, lambda a: a.normal(0, 0.1), lambda a: a.normal(0, 0.25), lambda a: a.normal(0, 0.5),]\n",
    "for i in range(len(final_rows_for_a_config)):\n",
    "    if i == 0:\n",
    "        to_plot_ = col_vals[0:final_rows_for_a_config[i]+1,-2]\n",
    "        to_plot_x = col_vals[0:final_rows_for_a_config[i]+1,-3]\n",
    "    else:\n",
    "        to_plot_ = col_vals[final_rows_for_a_config[i-1]+1:final_rows_for_a_config[i]+1,-2]\n",
    "        to_plot_x = col_vals[final_rows_for_a_config[i-1]+1:final_rows_for_a_config[i]+1,-3]\n",
    "    if i % 10 == 0:\n",
    "        fig = plt.figure(figsize=(12, 7))\n",
    "    plt.plot(to_plot_x, to_plot_)#, label=\"Seq len\" + str(seq_lens[i//10]))\n",
    "    if i % 10 == 9:\n",
    "#         pass\n",
    "        print(\"Plot no.\", i//10)\n",
    "        plt.xlabel(\"Train Timesteps\")\n",
    "        plt.ylabel(\"Reward\")\n",
    "        plt.title('Delay ' + str(delays[i//40]) + ', Sequence Length ' + str(sequence_lengths[(i//10) % 4]))\n",
    "#         plt.title('Transition Noise ' + str(transition_noises[i//50]) + ', Reward Noise ' + str(reward_noises[(i//10) % 5]))\n",
    "#         plt.legend(loc='upper left', prop={'size': 26})\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for train metrics: learning curves; with subplot\n",
    "nrows_ = num_values_per_hyperparam[-5]\n",
    "ncols_ = num_values_per_hyperparam[-4]\n",
    "fig, ax = plt.subplots(nrows=nrows_, ncols=ncols_, figsize=(36, 21))\n",
    "# print(ax)\n",
    "#fig = plt.figure(figsize=(9*4, 7*3)) #\n",
    "color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "print(\"color_cycle\", color_cycle)\n",
    "seq_lens = [2, 3, 4]\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "# metrics_reshaped_squeezed = np.squeeze(metrics_reshaped)\n",
    "# print(np.squeeze(metrics_reshaped).shape)\n",
    "delays = [0] + [2**i for i in range(4)]\n",
    "sequence_lengths = [1, 2, 3, 4]#i for i in range(1,4)]\n",
    "transition_noises = [0, 0.01, 0.02, 0.10, 0.25]\n",
    "reward_noises = [0, 1, 5, 10, 25] # Std dev. of normal dist. #, lambda a: a.normal(0, 0.1), lambda a: a.normal(0, 0.25), lambda a: a.normal(0, 0.5),]\n",
    "# sequence_lengths = [2, 3, 4]#i for i in range(1,4)]\n",
    "reward_densities = [0.25, 0.50, 0.75]\n",
    "for i in range(len(final_rows_for_a_config)):\n",
    "    i_index = i//(10 * ncols_) # = num_seeds * shape of more frequently changing hyperparam\n",
    "    j_index = (i//10) % ncols_ #\n",
    "    if i == 0:\n",
    "        to_plot_ = col_vals[0:final_rows_for_a_config[i]+1,-2]\n",
    "        to_plot_x = col_vals[0:final_rows_for_a_config[i]+1,-3]\n",
    "    else:\n",
    "        to_plot_ = col_vals[final_rows_for_a_config[i-1]+1:final_rows_for_a_config[i]+1,-2]\n",
    "        to_plot_x = col_vals[final_rows_for_a_config[i-1]+1:final_rows_for_a_config[i]+1,-3]\n",
    "#     if i % 10 == 0:\n",
    "#         fig = plt.figure(figsize=(12, 7))\n",
    "#     print(i//50, (i//10) % 5)\n",
    "    ax[i_index][j_index].plot(to_plot_x, to_plot_)#, label=\"Seq len\" + str(seq_lens[i//10]))\n",
    "    if i % 10 == 9: # 10 is num. of seeds\n",
    "#         pass\n",
    "#         print(\"Plot no.\", i//10)\n",
    "        ax[i_index][j_index].set_xlabel(\"Train Timesteps\")\n",
    "        ax[i_index][j_index].set_ylabel(\"Reward\")\n",
    "        ax[i_index][j_index].set_title('Delay ' + str(delays[i_index]) + ', Sequence Length ' + str(sequence_lengths[j_index]))\n",
    "#         ax[i_index][j_index].set_title('P Noise ' + str(transition_noises[i_index]) + ', R Noise ' + str(reward_noises[j_index]))\n",
    "#         ax[i_index][j_index].set_title('Sequence Length ' + str(sequence_lengths[j_index]))\n",
    "#         ax[i_index][j_index].set_title('Reward Density ' + str(reward_densities[j_index]))\n",
    "\n",
    "#         plt.legend(loc='upper left', prop={'size': 26})\n",
    "fig.tight_layout()\n",
    "# plt.suptitle(\"Training Learning Curves\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for eval metrics: learning curves\n",
    "#fig = plt.figure(figsize=(9*4, 7*3)) #\n",
    "color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "print(\"color_cycle\", color_cycle)\n",
    "seq_lens = [2, 3, 4]\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "print(mean_data_eval.shape, col_vals.shape)\n",
    "# metrics_reshaped_squeezed = np.squeeze(metrics_reshaped)\n",
    "# print(np.squeeze(metrics_reshaped).shape)\n",
    "delays = [0] + [2**i for i in range(4)]\n",
    "sequence_lengths = [1, 2, 3, 4]#i for i in range(1,4)]\n",
    "transition_noises = [0, 0.01, 0.02, 0.10, 0.25]\n",
    "reward_noises = [0, 1, 5, 10, 25] # Std dev. of normal dist. #, lambda a: a.normal(0, 0.1), lambda a: a.normal(0, 0.25), lambda a: a.normal(0, 0.5),]\n",
    "for i in range(len(final_rows_for_a_config)):\n",
    "    if i == 0:\n",
    "        to_plot_ = mean_data_eval[0:final_rows_for_a_config[i]+1,:]\n",
    "        to_plot_x = col_vals[0:final_rows_for_a_config[i]+1,-3]\n",
    "    else:\n",
    "        to_plot_ = mean_data_eval[final_rows_for_a_config[i-1]+1:final_rows_for_a_config[i]+1,:]\n",
    "        to_plot_x = col_vals[final_rows_for_a_config[i-1]+1:final_rows_for_a_config[i]+1,-3]\n",
    "    if i % 10 == 0:\n",
    "        fig = plt.figure(figsize=(12, 7))\n",
    "    plt.plot(to_plot_x, to_plot_[:, 0])#, label=\"Seq len\" + str(seq_lens[i//10]))\n",
    "    if i % 10 == 9:\n",
    "#         pass\n",
    "        print(\"Plot no.\", i//10)\n",
    "        plt.xlabel(\"Train Timesteps\")\n",
    "        plt.ylabel(\"Reward\")\n",
    "        plt.title('Transition Noise ' + str(transition_noises[i//50]) + ', Reward Noise ' + str(reward_noises[(i//10) % 5]))\n",
    "#         plt.legend(loc='upper left', prop={'size': 26})\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for eval metrics: learning curves; with subplots\n",
    "fig, ax = plt.subplots(nrows=nrows_, ncols=ncols_, figsize=(36, 21))\n",
    "#fig = plt.figure(figsize=(9*4, 7*3)) #\n",
    "color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "print(\"color_cycle\", color_cycle)\n",
    "seq_lens = [2, 3, 4]\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "print(mean_data_eval.shape, col_vals.shape)\n",
    "# metrics_reshaped_squeezed = np.squeeze(metrics_reshaped)\n",
    "# print(np.squeeze(metrics_reshaped).shape)\n",
    "delays = [0] + [2**i for i in range(4)]\n",
    "sequence_lengths = [1, 2, 3, 4]#i for i in range(1,4)]\n",
    "transition_noises = [0, 0.01, 0.02, 0.10, 0.25]\n",
    "reward_noises = [0, 1, 5, 10, 25] # Std dev. of normal dist. #, lambda a: a.normal(0, 0.1), lambda a: a.normal(0, 0.25), lambda a: a.normal(0, 0.5),]\n",
    "# sequence_lengths = [2, 3, 4]#i for i in range(1,4)]\n",
    "reward_densities = [0.25, 0.50, 0.75]\n",
    "for i in range(len(final_rows_for_a_config)):\n",
    "    i_index = i//(10 * ncols_) # = num_seeds * shape of more frequently changing hyperparam\n",
    "    j_index = (i//10) % ncols_ #\n",
    "    if i == 0:\n",
    "        to_plot_ = mean_data_eval[0:final_rows_for_a_config[i]+1,:]\n",
    "        to_plot_x = col_vals[0:final_rows_for_a_config[i]+1,-3]\n",
    "    else:\n",
    "        to_plot_ = mean_data_eval[final_rows_for_a_config[i-1]+1:final_rows_for_a_config[i]+1,:]\n",
    "        to_plot_x = col_vals[final_rows_for_a_config[i-1]+1:final_rows_for_a_config[i]+1,-3]\n",
    "#     if i % 10 == 0:\n",
    "#         fig = plt.figure(figsize=(12, 7))\n",
    "#     plt.plot(to_plot_x, to_plot_[:, 0])#, label=\"Seq len\" + str(seq_lens[i//10]))\n",
    "    ax[i_index][j_index].plot(to_plot_x, to_plot_[:, 0])#, label=\"Seq len\" + str(seq_lens[i//10]))\n",
    "    if i % 10 == 9: # 10 is num. of seeds\n",
    "#         pass\n",
    "#         print(\"Plot no.\", i//10)\n",
    "        ax[i_index][j_index].set_xlabel(\"Train Timesteps\")\n",
    "        ax[i_index][j_index].set_ylabel(\"Reward\")\n",
    "        ax[i_index][j_index].set_title('Delay ' + str(delays[i_index]) + ', Sequence Length ' + str(sequence_lengths[j_index]))\n",
    "#         ax[i_index][j_index].set_title('P Noise ' + str(transition_noises[i_index]) + ', R Noise ' + str(reward_noises[j_index]))\n",
    "#         ax[i_index][j_index].set_title('Sequence Length ' + str(sequence_lengths[j_index]))\n",
    "#         ax[i_index][j_index].set_title('Reward Density ' + str(reward_densities[j_index]))\n",
    "#         plt.legend(loc='upper left', prop={'size': 26})\n",
    "fig.tight_layout()#pad=1, w_pad=1, h_pad=2.0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(state_space_sizes)):\n",
    "    for j in range(len(action_space_sizes)):\n",
    "        for k in range(10):\n",
    "            mean_data_ = np.mean(metrics_reshaped[:, i, j, :, :, k, :, 1], axis=0)\n",
    "            to_plot_ = np.squeeze(mean_data_)\n",
    "            print(to_plot_, to_plot_.shape)\n",
    "            plt.imshow(np.atleast_2d(to_plot_), cmap='Purples', interpolation='none', vmin=0, vmax=200)#, extent=[0, 16, 8, 14])\n",
    "            plt.colorbar()\n",
    "    #         plt.xscale('log')\n",
    "    #         plt.yscale('log')\n",
    "            plt.title(str(state_space_sizes[i]) + ' ' + str(action_space_sizes[j]))\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####INCOMPLETE\n",
    "# 2-D heatmaps\n",
    "#\n",
    "# \n",
    "%matplotlib notebook\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "\n",
    "# alg_name = 'DQN'\n",
    "\n",
    "# measure = 'time'\n",
    "# measure = 'memory'\n",
    "# dataset_index = np.where(dataset_names==dataset_name)[0][0]\n",
    "# print(type(dataset_index), dataset_index.dtype)\n",
    "# column_no = 19 # Refer to comments above to decide the benchmark column or measure to choose\n",
    "\n",
    "fig = plt.figure(figsize=(9*4, 7*5)) #\n",
    "\n",
    "\n",
    "# column_names = ['train', '\\\"val\\\"','test_1','test_4']\n",
    "# column_nos = np.arange(4, 22, 5) #set starting value to 4 for performances, 5 for scoring times\n",
    "# print(column_nos.shape, dataset_names.shape)\n",
    "for i in range(len(state_space_sizes)):\n",
    "    for j in range(len(action_space_sizes)):\n",
    "        for k in range(len(delays)):\n",
    "            for l in range(len(sequence_lengths)):\n",
    "                print(\"Plotting for |S|, |A|, d, n: \", state_space_sizes[i], action_space_sizes[j], delays[k]\n",
    "                     sequence_lengths[l])\n",
    "                values_[0, i, j]\n",
    "\n",
    "        \n",
    "\n",
    "plt.savefig('/home/rajanr/Downloads/temp.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ = 5\n",
    "len_ = 3\n",
    "nums_ = list(range(num_ + 1 - len_, num_ + 1))\n",
    "print(nums_, np.random.randint(np.prod(nums_)))\n",
    "unique_seqs_ = []\n",
    "for i in range(np.prod(nums_)):\n",
    "    curr_num = i\n",
    "    seq_ = []\n",
    "    curr_rem_nums_ = list(range(num_))\n",
    "    for j in nums_[::-1]:\n",
    "        rem_ = curr_num % j\n",
    "        seq_.append(curr_rem_nums_[rem_])\n",
    "        del curr_rem_nums_[rem_]\n",
    "#         print(\"curr_rem_nums_\", curr_rem_nums_)\n",
    "        curr_num = curr_num // j\n",
    "#         print(rem_, curr_num, j, seq_)\n",
    "    print(\"T/F:\", seq_ in unique_seqs_)\n",
    "    unique_seqs_.append(seq_)\n",
    "#print(len(set(unique_seqs_))) #error\n",
    "\n",
    "print(np.unique(unique_seqs_))\n",
    "#         print(i % 3, i % 4, i % 5, i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "np.random.choice(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp\n",
    "\n",
    "new_file = \"/home/rajanr/temp.txt\"\n",
    "fout = open(new_file, 'a') #hardcoded\n",
    "for line in open(stats_file):\n",
    "    if line.startswith(\"#\"):\n",
    "        \n",
    "        vals = line.split(',')[-1]\n",
    "#         print(vals)\n",
    "    else:\n",
    "        vals2 = line\n",
    "#         print(line)\n",
    "    \n",
    "        print(vals[1:-1] + ' ' + vals2)\n",
    "        fout.write(vals[1:-1] + ' ' + vals2)\n",
    "# # fout.flush()\n",
    "fout.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd as pwd\n",
    "from glob import glob #ls = sorted(glob(filename))\n",
    "from ray.tune.analysis import ExperimentAnalysis\n",
    "\n",
    "for filename in sorted(glob('/mhome/rajanr/ray_results/DQN/*.json')):\n",
    "    print(filename)\n",
    "    try:\n",
    "        print(ExperimentAnalysis(filename, trials=None))\n",
    "    except Exception as e:\n",
    "        print(\"EXCEPTION\", filename, e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
