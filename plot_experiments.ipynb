{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = '/home/rajanr/custom-gym-env'\n",
    "exp_name = '103'\n",
    "save_fig = True\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MDPP_Analysis():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def load_data(self, dir_name, exp_name):\n",
    "        '''Loads training and evaluation data from given file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dir_name : str\n",
    "            The location where the training and evaluation CSV files were written\n",
    "        exp_name : str\n",
    "            The name of the experiment: the training and evaluation CSV filenames are formed using this string\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        train_stats : np.ndarray\n",
    "            Training stats at end of training: 8-D tensor with 1st 6 dims the meta-features of MDP Playground, 7th dim is across the seeds, 8th dim is across different stats saved\n",
    "        eval_stats : np.ndarray\n",
    "            Training stats at end of training: 8-D tensor with 1st 6 dims the meta-features of MDP Playground, 7th dim is across the seeds, 8th dim is across different stats saved\n",
    "        train_curves: np.ndarray\n",
    "            The loaded training CSV with the last 3 columns the train stats that were saved and the initial columns are various setting for the algorithm and environment.\n",
    "        eval_curves: np.ndarray\n",
    "            The loaded evaluation CSV with the columns the evaluation stats that were saved            \n",
    "        '''\n",
    "        \n",
    "        stats_file = dir_name + '/' + exp_name #Name of file to which benchmark stats were written\n",
    "        self.stats_file = stats_file\n",
    "        datasets_info = np.loadtxt(stats_file + '.csv', dtype=object)\n",
    "        # print(datasets_info[0])\n",
    "        # print(datasets_info)\n",
    "        # print(type(datasets_info))\n",
    "        # print(datasets_info.shape)\n",
    "\n",
    "        stats_pd = pd.read_csv(stats_file + '.csv', skip_blank_lines=True, header=None, comment='#', sep=' ')\n",
    "        # print(stats_pd)\n",
    "        # print(stats_pd[11].dtypes)\n",
    "        # print(stats_pd.dtypes)\n",
    "        # print(stats_pd.shape[0])\n",
    "\n",
    "        final_rows_for_a_config = []\n",
    "        previous_i = 0\n",
    "        list_of_learning_curves = []\n",
    "        cols_to_take = 8\n",
    "\n",
    "        for i in range(stats_pd.shape[0] - 1):\n",
    "            if stats_pd.iloc[i, -3] > stats_pd.iloc[i + 1, -3]: #hardcoded: 3rd last column is no. of timesteps for the current run\n",
    "                list_of_learning_curves.append(stats_pd.iloc[previous_i:i+1, -cols_to_take:])\n",
    "                previous_i = i + 1\n",
    "                final_rows_for_a_config.append(i)\n",
    "        # print(\"i, previous_i:\", i, previous_i)\n",
    "        final_rows_for_a_config.append(i + 1) # Always append the last row!\n",
    "        list_of_learning_curves.append(stats_pd.iloc[previous_i:i + 2, -cols_to_take:])\n",
    "        self.final_rows_for_a_config = final_rows_for_a_config\n",
    "\n",
    "        self.config_names = ['Delay', 'Sequence Length', 'Reward Density', 'Terminal State Density', 'P Noise', 'R Noise', 'dummy_seed']\n",
    "        config_counts = []\n",
    "        dims_values = []\n",
    "        for i in range(4, 11): #hardcoded corresponds to columns written to evaluation stats CSV file\n",
    "            dims_values.append(stats_pd[i].unique())\n",
    "            config_counts.append(stats_pd[i].nunique())\n",
    "\n",
    "        config_counts.append(3) #hardcoded number of training stats that were recorded\n",
    "        config_counts = tuple(config_counts)\n",
    "\n",
    "        # print(len(list_of_learning_curves))\n",
    "        # print(len(final_rows_for_a_config))\n",
    "        stats_end_of_training = stats_pd.iloc[final_rows_for_a_config]\n",
    "        stats_reshaped = stats_end_of_training.iloc[:, -3:] #hardcoded # last vals are timesteps_total, episode_reward_mean, episode_len_mean\n",
    "        stats_reshaped = np.reshape(np.array(stats_reshaped), config_counts)\n",
    "        # print(stats_end_of_training.head(10))\n",
    "        print(\"train stats shape:\", stats_reshaped.shape)\n",
    "#         to_plot_ = np.squeeze(stats_reshaped[:, :, :, :, 0, 0, :, 1])\n",
    "#         print('Episode reward (at end of training) for 10 seeds for vanilla env.:', to_plot_)\n",
    "\n",
    "\n",
    "        # Load evaluation stats\n",
    "        stats_file_eval = stats_file + '_eval.csv'\n",
    "        eval_stats = np.loadtxt(stats_file_eval, dtype=float)\n",
    "        # print(eval_stats, eval_stats.shape)\n",
    "\n",
    "        i = 0\n",
    "        hack_indices = []\n",
    "        for line in open(stats_file_eval):\n",
    "\n",
    "            line=line.strip()\n",
    "        #    print(line)\n",
    "            if line.startswith(\"#HACK\"):\n",
    "        #         print(line, i)\n",
    "                hack_indices.append(i - len(hack_indices)) # appends index of last eval in this training_iteration\n",
    "            i += 1\n",
    "\n",
    "        # print(len(hack_indices), hack_indices)\n",
    "        hack_indices_10 = np.array(hack_indices) - 10\n",
    "        # print(hack_indices_10.shape, hack_indices_10)\n",
    "        # print(np.array(hack_indices[1:]) - np.array(hack_indices[:-1]))\n",
    "        # print(\"Min:\", min(np.array(hack_indices[1:]) - np.array(hack_indices[:-1]))) # Some problem with Ray? Sometimes no. of eval episodes is less than 10.\n",
    "        final_10_evals = []\n",
    "        for i in range(len(hack_indices)):\n",
    "            final_10_evals.append(eval_stats[hack_indices_10[i]:hack_indices[i]])\n",
    "        #     print(final_10_evals[-1])\n",
    "\n",
    "        final_10_evals = np.array(final_10_evals) # has 2 columns: episode reward and episode length\n",
    "        # print(final_10_evals.shape, final_10_evals)\n",
    "\n",
    "\n",
    "        # final_vals = fin[final_rows_for_a_config]\n",
    "        # print('final_rows_for_a_config', final_rows_for_a_config)\n",
    "        # print(\"len(final_10_evals)\", final_10_evals.shape, type(final_10_evals))\n",
    "        mean_data_eval = np.mean(final_10_evals, axis=1) # this is mean over last 10 eval episodes\n",
    "#         print(np.array(stats_pd.iloc[:, -3]))\n",
    "        mean_data_eval = np.concatenate((np.atleast_2d(np.array(stats_pd.iloc[:, -3])).T, mean_data_eval), axis=1)\n",
    "#         print(mean_data_eval.shape, len(final_rows_for_a_config))\n",
    "\n",
    "        \n",
    "        final_eval_metrics_ = mean_data_eval[final_rows_for_a_config, :] # 1st column is episode reward, 2nd is episode length\n",
    "        # print(dims_values, config_counts)\n",
    "        final_eval_metrics_reshaped = np.reshape(final_eval_metrics_, config_counts)\n",
    "        # print(final_eval_metrics_)\n",
    "#         print(\"eval stats shapes (before and after reshape):\", final_eval_metrics_.shape, final_eval_metrics_reshaped.shape)\n",
    "        print(\"eval stats shape:\", final_eval_metrics_reshaped.shape)\n",
    "        \n",
    "        self.config_counts = config_counts[:-1] # -1 is added to ignore \"no. of stats that were saved\" as dimensions of difficulty\n",
    "        self.dims_values = dims_values\n",
    "        \n",
    "        # Catpure the dimensions that were varied, i.e. ones which had more than 1 value across experiments\n",
    "        x_axis_labels = []\n",
    "        x_tick_labels_ = []\n",
    "        dims_varied = []\n",
    "        for i in range(len(self.config_counts) - 1): # -1 is added to ignore seeds as dimensions of difficulty\n",
    "            if self.config_counts[i]> 1:\n",
    "                x_axis_labels.append(self.config_names[i])\n",
    "                x_tick_labels_.append([str(j) for j in self.dims_values[i]])\n",
    "                dims_varied.append(i)\n",
    "                \n",
    "        self.axis_labels = x_axis_labels\n",
    "        self.tick_labels = x_tick_labels_\n",
    "        self.dims_varied = dims_varied\n",
    "        \n",
    "        return stats_reshaped, final_eval_metrics_reshaped, np.array(stats_pd), mean_data_eval\n",
    "\n",
    "        \n",
    "    def plot_1d_dimensions(self, stats_data, save_fig=False, train=True):\n",
    "        '''Plots 1-D bar plots across a single dimension with mean and std. dev.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stats_data : np.array\n",
    "            8-D tensor with 1st 6 dims the meta-features of MDP Playground, 7th dim is across the seeds, 8th dim is across different stats saved\n",
    "        save_fig : bool, optional\n",
    "            A flag used to save a PDF (default is\n",
    "            False)\n",
    "        train : bool, optional\n",
    "            A flag used to insert either _train or _eval in the filename of the PDF (default is True)\n",
    "\n",
    "        '''\n",
    "        y_axis_label = 'Reward'\n",
    "\n",
    "        plt.rcParams.update({'font.size': 18}) # default 12, for poster: 30\n",
    "        print(stats_data.shape)\n",
    "\n",
    "        mean_data_ = np.mean(stats_data[:, :, :, :, :, :, :, -2], axis=-1)\n",
    "        to_plot_ = np.squeeze(mean_data_)\n",
    "        std_dev_ = np.std(stats_data[:, :, :, :, :, :, :, -2], axis=-1)\n",
    "        to_plot_std_ = np.squeeze(std_dev_)\n",
    "\n",
    "        plt.figure(figsize=(5, 1.5))\n",
    "\n",
    "        print(to_plot_.shape)\n",
    "        if len(to_plot_.shape) == 2: # Case when 2 meta-features were varied\n",
    "            plt.bar(self.tick_labels[0], to_plot_[:, 0], yerr=to_plot_std_[:, 0])\n",
    "        else:\n",
    "            plt.bar(self.tick_labels[0], to_plot_, yerr=to_plot_std_)    \n",
    "        plt.xlabel(self.axis_labels[0])\n",
    "        plt.ylabel(y_axis_label)\n",
    "        if save_fig:\n",
    "            plt.savefig(self.stats_file.split('/')[-1] + ('_train' if train else '_eval') + '_final_reward_' + self.axis_labels[0].replace(' ','_') + '_1d.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "        if len(to_plot_.shape) == 2: # Case when 2 meta-features were varied\n",
    "            plt.figure(figsize=(5, 1.5))\n",
    "            plt.bar(self.tick_labels[1], to_plot_[0, :], yerr=to_plot_std_[0, :])\n",
    "            # plt.tight_layout()\n",
    "            plt.xlabel(self.axis_labels[1])\n",
    "            plt.ylabel(y_axis_label)\n",
    "            if save_fig:\n",
    "                plt.savefig(self.stats_file.split('/')[-1] + ('_train' if train else '_eval') + '_final_reward_' + self.axis_labels[1].replace(' ','_') + '_1d.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "\n",
    "    def plot_2d_heatmap(self, stats_data, save_fig=False, train=True):\n",
    "        '''Plots 2 2-D heatmaps: 1 for mean and 1 for std. dev. across 2 meta-features of MDP Playground\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stats_data : np.array\n",
    "            8-D tensor with 1st 6 dims the meta-features of MDP Playground, 7th dim is across the seeds, 8th dim is across different stats saved\n",
    "        save_fig : bool, optional\n",
    "            A flag used to save a PDF (default is\n",
    "            False)\n",
    "        train : bool, optional\n",
    "            A flag used to insert either _train or _eval in the filename of the PDF (default is True)\n",
    "        '''\n",
    "        plt.rcParams.update({'font.size': 18}) # default 12, 24 for paper, for poster: 30\n",
    "\n",
    "        mean_data_ = np.mean(stats_data[:, :, :, :, :, :, :, -2], axis=-1)\n",
    "        to_plot_ = np.squeeze(mean_data_)\n",
    "        plt.imshow(np.atleast_2d(to_plot_), cmap='Purples', interpolation='none', vmin=0, vmax=np.max(to_plot_))\n",
    "        plt.gca().set_xticklabels(self.tick_labels[1]) # dims 1 and 0 are exchanged here because Y-axis has plot for 1st varying dim and X-axis has plot for 2nd varying dim\n",
    "        plt.gca().set_yticklabels(self.tick_labels[0])\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.ax.get_yaxis().labelpad = 15 # default 15, for poster: 25\n",
    "        cbar.set_label('Reward', rotation=270)\n",
    "        plt.xlabel(self.axis_labels[1])\n",
    "        plt.ylabel(self.axis_labels[0])\n",
    "        if save_fig:\n",
    "            plt.savefig(self.stats_file.split('/')[-1] + ('_train' if train else '_eval') + '_final_reward_mean_heat_map.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "        std_dev_ = np.std(stats_data[:, :, :, :, :, :, :, -2], axis=-1)\n",
    "        to_plot_ = np.squeeze(std_dev_)\n",
    "        # print(to_plot_, to_plot_.shape)\n",
    "        plt.imshow(np.atleast_2d(to_plot_), cmap='Purples', interpolation='none', vmin=0, vmax=np.max(to_plot_)) # 60 for DQN, 100 for A3C\n",
    "        plt.gca().set_xticklabels(self.tick_labels[1])\n",
    "        plt.gca().set_yticklabels(self.tick_labels[0])\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.ax.get_yaxis().labelpad = 15 # default 15, for poster: 30\n",
    "        cbar.set_label('Reward Std Dev.', rotation=270)\n",
    "        plt.xlabel(self.axis_labels[1])\n",
    "        plt.ylabel(self.axis_labels[0])\n",
    "        # plt.tight_layout()\n",
    "        if save_fig:\n",
    "            plt.savefig(self.stats_file.split('/')[-1] + ('_train' if train else '_eval') + '_final_reward_std_heat_map.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "            # plt.savefig(stats_file.split('/')[-1] + '_train_heat_map.png')#, dpi=300)\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_learning_curves(self, stats_data, save_fig=False, train=True):\n",
    "        '''Plots learning curves: Either across 1 or 2 meta-features of MDP Playground. Different colours represent learning curves for different seeds.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stats_data : np.array\n",
    "            8-D tensor with 1st 6 dims the meta-features of MDP Playground, 7th dim is across the seeds, 8th dim is across different stats saved\n",
    "        save_fig : bool, optional\n",
    "            A flag used to save a PDF (default is\n",
    "            False)\n",
    "        train : bool, optional\n",
    "            A flag used to insert either _train or _eval in the filename of the PDF (default is True)\n",
    "        '''\n",
    "        # Plot for train metrics: learning curves; with subplot\n",
    "        # Comment out unneeded labels in code lines 41-44 in this cell\n",
    "        ncols_ = self.config_counts[self.dims_varied[0]]\n",
    "        if len(self.dims_varied) > 1:\n",
    "            nrows_ = self.config_counts[self.dims_varied[1]]\n",
    "        else:\n",
    "            nrows_ = 1\n",
    "        nseeds_ = self.config_counts[-1]\n",
    "        # print(ax, type(ax), type(ax[0]))\n",
    "#         color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "        # print(\"color_cycle\", color_cycle)\n",
    "        plt.rcParams.update({'font.size': 25}) # 25 for 36x21 fig, 16 for 24x14 fig.\n",
    "        # 36x21 for better resolution but about 900kb file size, 24x14 for okay resolution and 550kb file size\n",
    "        fig, ax = plt.subplots(nrows=nrows_, ncols=ncols_, figsize=(7 * ncols_, 5 * nrows_))\n",
    "        ax = np.atleast_2d(ax)\n",
    "        # metrics_reshaped_squeezed = np.squeeze(metrics_reshaped)\n",
    "        # print(np.squeeze(metrics_reshaped).shape)\n",
    "        for i in range(len(self.final_rows_for_a_config)):\n",
    "            i_index = i//(nseeds_ * ncols_) # = num_seeds * shape of more frequently changing hyperparam\n",
    "            j_index = (i//nseeds_) % ncols_ #\n",
    "            if i == 0:\n",
    "                to_plot_ = stats_data[0:self.final_rows_for_a_config[i]+1,-2]\n",
    "                to_plot_x = stats_data[0:self.final_rows_for_a_config[i]+1,-3]\n",
    "            else:\n",
    "                to_plot_ = stats_data[self.final_rows_for_a_config[i-1]+1:self.final_rows_for_a_config[i]+1, -2]\n",
    "                to_plot_x = stats_data[self.final_rows_for_a_config[i-1]+1:self.final_rows_for_a_config[i]+1, -3]\n",
    "        #     if i % 10 == 0:\n",
    "        #         fig = plt.figure(figsize=(12, 7))\n",
    "        #     print(i//50, (i//10) % 5)\n",
    "            ax[i_index][j_index].plot(to_plot_x, to_plot_, rasterized=False)#, label=\"Seq len\" + str(seq_lens[i//10]))\n",
    "            if i % nseeds_ == nseeds_ - 1: # 10 is num. of seeds\n",
    "        #         pass\n",
    "        #         print(\"Plot no.\", i//10)\n",
    "                ax[i_index][j_index].set_xlabel(\"Train Timesteps\")\n",
    "                ax[i_index][j_index].set_ylabel(\"Reward\")\n",
    "        #         ax[i_index][j_index].set_title('Delay ' + str(delays[i_index]) + ', Sequence Length ' + str(sequence_lengths[j_index]))\n",
    "                ax[i_index][j_index].set_title(self.config_names[self.dims_varied[0]] + ' ' + str(self.dims_values[self.dims_varied[0]][i_index]) + ', ' + self.config_names[self.dims_varied[1]] + ' '  + str(self.dims_values[self.dims_varied[1]][j_index]))\n",
    "        #         ax[i_index][j_index].set_title('Sequence Length ' + str(seq_lens[j_index]))\n",
    "        #         ax[i_index][j_index].set_title('Reward Density ' + str(reward_densities[j_index]))\n",
    "\n",
    "        #         plt.legend(loc='upper left', prop={'size': 26})\n",
    "        fig.tight_layout()\n",
    "        # plt.suptitle(\"Training Learning Curves\")\n",
    "        plt.show()\n",
    "        if save_fig:\n",
    "            fig.savefig(self.stats_file.split('/')[-1] + ('_train' if train else '_eval') + '_learning_curves.pdf', dpi=300, bbox_inches=\"tight\") # Generates high quality vector graphic PDF 125kb; dpi doesn't matter for this\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdpp_analysis = MDPP_Analysis()\n",
    "train_stats, eval_stats, train_curves, eval_curves = mdpp_analysis.load_data(dir_name, exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-D: Plots showing reward after 20k timesteps when varying a single meta-feature\n",
    "# Plots across 10 runs: Training: with std dev across the runs\n",
    "\n",
    "mdpp_analysis.plot_1d_dimensions(train_stats, save_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdpp_analysis.plot_1d_dimensions(eval_stats, save_fig, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-D heatmap plots across 10 runs: Training runs: with std dev across the runs\n",
    "# There seems to be a bug with matplotlib - x and y axes tick labels are not correctly set even though we pass them. Please feel free to look into the code and suggest a correction if you find it.\n",
    "\n",
    "mdpp_analysis.plot_2d_heatmap(train_stats, save_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdpp_analysis.plot_2d_heatmap(eval_stats, save_fig, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves: Each curve corresponds to a different seed for the agent\n",
    "mdpp_analysis.plot_learning_curves(train_curves, save_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdpp_analysis.plot_learning_curves(eval_curves, save_fig, train=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
