# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 7500 6.39e-01 4.36e+00
2 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 15000 2.89e+00 7.43e+00
3 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 22500 3.98e+01 4.46e+01
4 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 30000 6.80e+01 7.12e+01
5 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 37500 7.92e+01 8.18e+01
6 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 45000 8.39e+01 8.62e+01
7 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 52500 8.71e+01 8.94e+01
8 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 60000 9.09e+01 9.34e+01
9 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 67500 9.19e+01 9.44e+01
10 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 75000 8.74e+01 8.97e+01
11 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 82500 8.94e+01 9.19e+01
12 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 90000 8.92e+01 9.06e+01
13 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 97500 8.92e+01 9.13e+01
14 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 105000 9.17e+01 9.42e+01
15 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 112500 9.07e+01 9.29e+01
16 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 120000 9.20e+01 9.45e+01
17 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 127500 8.84e+01 9.13e+01
18 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 135000 9.14e+01 9.53e+01
19 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 142500 9.19e+01 9.52e+01
20 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 0 150000 9.54e+01 9.90e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 7500 6.77e-01 4.31e+00
2 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 15000 2.86e+00 7.42e+00
3 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 22500 3.58e+01 4.01e+01
4 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 30000 6.63e+01 6.93e+01
5 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 37500 7.95e+01 8.22e+01
6 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 45000 8.68e+01 8.90e+01
7 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 52500 8.19e+01 8.42e+01
8 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 60000 9.00e+01 9.21e+01
9 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 67500 9.36e+01 9.54e+01
10 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 75000 9.09e+01 9.33e+01
11 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 82500 8.75e+01 8.94e+01
12 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 90000 9.12e+01 9.35e+01
13 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 97500 9.28e+01 9.50e+01
14 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 105000 9.01e+01 9.23e+01
15 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 112500 9.14e+01 9.34e+01
16 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 120000 9.49e+01 9.70e+01
17 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 127500 9.27e+01 9.54e+01
18 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 135000 9.42e+01 9.74e+01
19 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 142500 9.25e+01 9.59e+01
20 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 1 150000 9.25e+01 9.68e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 7500 5.92e-01 4.12e+00
2 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 15000 2.21e+00 7.29e+00
3 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 22500 2.66e+01 3.23e+01
4 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 30000 6.60e+01 6.90e+01
5 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 37500 7.98e+01 8.24e+01
6 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 45000 8.49e+01 8.75e+01
7 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 52500 9.11e+01 9.33e+01
8 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 60000 8.85e+01 9.11e+01
9 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 67500 8.76e+01 8.99e+01
10 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 75000 8.78e+01 8.97e+01
11 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 82500 8.71e+01 8.87e+01
12 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 90000 9.20e+01 9.40e+01
13 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 97500 9.03e+01 9.22e+01
14 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 105000 8.98e+01 9.19e+01
15 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 112500 8.66e+01 8.92e+01
16 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 120000 8.97e+01 9.18e+01
17 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 127500 8.44e+01 8.72e+01
18 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 135000 8.51e+01 8.76e+01
19 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 142500 8.88e+01 9.21e+01
20 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 2 150000 9.23e+01 9.56e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 7500 6.20e-01 4.28e+00
2 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 15000 3.06e+00 7.37e+00
3 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 22500 3.82e+01 4.30e+01
4 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 30000 7.06e+01 7.37e+01
5 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 37500 7.68e+01 8.00e+01
6 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 45000 8.49e+01 8.74e+01
7 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 52500 8.72e+01 8.97e+01
8 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 60000 8.76e+01 8.98e+01
9 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 67500 8.97e+01 9.21e+01
10 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 75000 9.26e+01 9.49e+01
11 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 82500 9.51e+01 9.73e+01
12 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 90000 9.50e+01 9.64e+01
13 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 97500 9.63e+01 9.80e+01
14 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 105000 9.47e+01 9.70e+01
15 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 112500 9.33e+01 9.62e+01
16 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 120000 9.48e+01 9.84e+01
17 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 127500 9.25e+01 9.63e+01
18 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 135000 9.42e+01 9.77e+01
19 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 142500 9.37e+01 9.75e+01
20 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 3 150000 9.46e+01 9.82e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 7500 6.53e-01 4.43e+00
2 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 15000 3.43e+00 8.32e+00
3 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 22500 3.64e+01 4.13e+01
4 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 30000 6.53e+01 7.01e+01
5 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 37500 7.88e+01 8.23e+01
6 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 45000 8.36e+01 8.61e+01
7 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 52500 8.59e+01 8.89e+01
8 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 60000 8.95e+01 9.24e+01
9 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 67500 8.78e+01 9.06e+01
10 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 75000 9.04e+01 9.30e+01
11 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 82500 9.17e+01 9.44e+01
12 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 90000 9.12e+01 9.35e+01
13 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 97500 9.02e+01 9.22e+01
14 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 105000 9.51e+01 9.65e+01
15 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 112500 8.95e+01 9.10e+01
16 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 120000 8.86e+01 9.03e+01
17 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 127500 8.98e+01 9.21e+01
18 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 135000 9.33e+01 9.53e+01
19 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 142500 9.45e+01 9.62e+01
20 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 4 150000 9.45e+01 9.72e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 7500 6.32e-01 4.21e+00
2 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 15000 2.33e+00 7.06e+00
3 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 22500 2.82e+01 3.34e+01
4 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 30000 6.80e+01 7.21e+01
5 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 37500 7.76e+01 8.09e+01
6 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 45000 8.45e+01 8.77e+01
7 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 52500 8.73e+01 8.94e+01
8 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 60000 9.24e+01 9.43e+01
9 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 67500 8.66e+01 8.92e+01
10 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 75000 9.01e+01 9.23e+01
11 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 82500 9.34e+01 9.58e+01
12 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 90000 9.37e+01 9.56e+01
13 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 97500 8.81e+01 9.02e+01
14 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 105000 8.98e+01 9.20e+01
15 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 112500 9.32e+01 9.56e+01
16 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 120000 9.12e+01 9.45e+01
17 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 127500 9.14e+01 9.54e+01
18 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 135000 8.95e+01 9.32e+01
19 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 142500 8.82e+01 9.23e+01
20 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 5 150000 9.30e+01 9.71e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 7500 6.75e-01 4.37e+00
2 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 15000 3.04e+00 7.92e+00
3 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 22500 3.80e+01 4.28e+01
4 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 30000 7.01e+01 7.33e+01
5 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 37500 7.46e+01 7.73e+01
6 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 45000 8.66e+01 8.89e+01
7 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 52500 8.72e+01 8.89e+01
8 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 60000 8.77e+01 8.95e+01
9 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 67500 9.22e+01 9.48e+01
10 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 75000 9.68e+01 9.94e+01
11 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 82500 9.21e+01 9.46e+01
12 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 90000 9.19e+01 9.46e+01
13 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 97500 9.20e+01 9.42e+01
14 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 105000 9.56e+01 9.80e+01
15 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 112500 8.97e+01 9.36e+01
16 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 120000 8.85e+01 9.28e+01
17 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 127500 8.98e+01 9.33e+01
18 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 135000 9.40e+01 9.69e+01
19 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 142500 9.46e+01 9.80e+01
20 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 6 150000 9.32e+01 9.66e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 7500 6.15e-01 4.44e+00
2 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 15000 2.78e+00 6.97e+00
3 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 22500 3.46e+01 3.87e+01
4 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 30000 6.62e+01 6.90e+01
5 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 37500 7.52e+01 7.78e+01
6 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 45000 8.34e+01 8.56e+01
7 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 52500 8.91e+01 9.25e+01
8 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 60000 8.67e+01 8.94e+01
9 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 67500 8.78e+01 9.01e+01
10 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 75000 9.08e+01 9.33e+01
11 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 82500 9.27e+01 9.52e+01
12 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 90000 9.46e+01 9.77e+01
13 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 97500 9.42e+01 9.72e+01
14 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 105000 9.37e+01 9.65e+01
15 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 112500 9.39e+01 9.67e+01
16 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 120000 9.66e+01 1.00e+02
17 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 127500 9.34e+01 9.73e+01
18 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 135000 9.40e+01 9.80e+01
19 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 142500 9.46e+01 9.82e+01
20 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 7 150000 9.49e+01 9.90e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 7500 6.24e-01 4.23e+00
2 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 15000 2.49e+00 6.98e+00
3 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 22500 2.96e+01 3.40e+01
4 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 30000 6.99e+01 7.24e+01
5 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 37500 7.78e+01 8.07e+01
6 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 45000 8.34e+01 8.57e+01
7 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 52500 8.21e+01 8.43e+01
8 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 60000 8.87e+01 9.13e+01
9 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 67500 9.10e+01 9.25e+01
10 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 75000 9.09e+01 9.28e+01
11 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 82500 9.20e+01 9.39e+01
12 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 90000 9.07e+01 9.33e+01
13 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 97500 8.96e+01 9.19e+01
14 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 105000 9.22e+01 9.44e+01
15 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 112500 9.33e+01 9.55e+01
16 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 120000 9.27e+01 9.53e+01
17 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 127500 8.94e+01 9.28e+01
18 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 135000 8.84e+01 9.26e+01
19 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 142500 9.34e+01 9.76e+01
20 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 8 150000 9.27e+01 9.64e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 7500 6.23e-01 4.25e+00
2 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 15000 3.19e+00 7.73e+00
3 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 22500 3.47e+01 3.93e+01
4 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 30000 6.57e+01 6.95e+01
5 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 37500 7.58e+01 7.89e+01
6 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 45000 8.24e+01 8.49e+01
7 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 52500 8.35e+01 8.57e+01
8 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 60000 9.06e+01 9.30e+01
9 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 67500 9.08e+01 9.30e+01
10 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 75000 9.23e+01 9.52e+01
11 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 82500 9.02e+01 9.26e+01
12 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 90000 9.15e+01 9.38e+01
13 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 97500 9.12e+01 9.35e+01
14 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 105000 9.49e+01 9.72e+01
15 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 112500 9.55e+01 9.81e+01
16 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 120000 9.18e+01 9.55e+01
17 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 127500 9.26e+01 9.66e+01
18 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 135000 9.39e+01 9.76e+01
19 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 142500 9.54e+01 9.88e+01
20 A3C 8 8 0 1 2.50e-01 False 2.50e-01 0 0 9 150000 9.52e+01 9.90e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 7500 3.38e-01 4.30e+00
2 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 15000 9.00e-01 6.80e+00
3 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 22500 4.46e+00 1.84e+01
4 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 30000 1.27e+01 4.07e+01
5 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 37500 2.02e+01 5.94e+01
6 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 45000 2.19e+01 6.07e+01
7 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 52500 2.50e+01 6.70e+01
8 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 60000 2.61e+01 6.82e+01
9 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 67500 3.13e+01 7.78e+01
10 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 75000 3.26e+01 8.00e+01
11 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 82500 3.38e+01 8.10e+01
12 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 90000 3.34e+01 7.95e+01
13 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 97500 3.39e+01 7.86e+01
14 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 105000 3.59e+01 8.16e+01
15 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 112500 3.81e+01 8.53e+01
16 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 120000 4.05e+01 9.04e+01
17 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 127500 3.98e+01 8.80e+01
18 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 135000 4.10e+01 9.00e+01
19 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 142500 4.14e+01 8.98e+01
20 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 0 150000 3.94e+01 8.63e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 7500 3.03e-01 4.39e+00
2 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 15000 9.08e-01 6.97e+00
3 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 22500 4.09e+00 1.75e+01
4 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 30000 1.46e+01 4.44e+01
5 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 37500 2.17e+01 5.80e+01
6 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 45000 2.63e+01 6.61e+01
7 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 52500 2.91e+01 6.87e+01
8 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 60000 3.13e+01 7.29e+01
9 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 67500 3.23e+01 7.25e+01
10 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 75000 3.41e+01 7.63e+01
11 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 82500 3.85e+01 8.51e+01
12 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 90000 3.66e+01 8.02e+01
13 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 97500 3.75e+01 8.23e+01
14 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 105000 3.93e+01 8.58e+01
15 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 112500 3.69e+01 8.03e+01
16 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 120000 4.13e+01 8.90e+01
17 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 127500 3.87e+01 8.33e+01
18 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 135000 4.15e+01 8.85e+01
19 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 142500 4.14e+01 8.87e+01
20 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 1 150000 4.16e+01 8.86e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 7500 3.11e-01 4.22e+00
2 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 15000 9.66e-01 7.16e+00
3 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 22500 4.80e+00 1.90e+01
4 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 30000 1.36e+01 4.58e+01
5 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 37500 1.72e+01 5.03e+01
6 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 45000 2.35e+01 6.32e+01
7 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 52500 3.11e+01 7.73e+01
8 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 60000 3.12e+01 7.46e+01
9 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 67500 3.23e+01 7.75e+01
10 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 75000 3.25e+01 7.68e+01
11 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 82500 3.65e+01 8.52e+01
12 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 90000 3.74e+01 8.44e+01
13 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 97500 3.78e+01 8.54e+01
14 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 105000 3.56e+01 8.08e+01
15 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 112500 3.96e+01 8.76e+01
16 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 120000 3.92e+01 8.63e+01
17 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 127500 4.09e+01 8.91e+01
18 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 135000 4.28e+01 9.32e+01
19 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 142500 3.89e+01 8.52e+01
20 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 2 150000 4.07e+01 8.86e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 7500 2.96e-01 4.18e+00
2 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 15000 7.82e-01 6.53e+00
3 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 22500 4.46e+00 1.95e+01
4 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 30000 1.22e+01 4.31e+01
5 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 37500 1.81e+01 5.49e+01
6 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 45000 2.03e+01 5.91e+01
7 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 52500 2.46e+01 6.65e+01
8 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 60000 2.83e+01 7.14e+01
9 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 67500 2.86e+01 7.06e+01
10 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 75000 3.30e+01 7.75e+01
11 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 82500 3.08e+01 7.14e+01
12 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 90000 3.49e+01 7.95e+01
13 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 97500 3.45e+01 7.91e+01
14 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 105000 3.70e+01 8.28e+01
15 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 112500 3.77e+01 8.32e+01
16 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 120000 3.95e+01 8.72e+01
17 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 127500 3.71e+01 8.20e+01
18 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 135000 3.94e+01 8.62e+01
19 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 142500 3.98e+01 8.70e+01
20 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 3 150000 4.13e+01 8.94e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 7500 3.06e-01 4.23e+00
2 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 15000 8.67e-01 6.55e+00
3 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 22500 4.90e+00 1.96e+01
4 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 30000 1.59e+01 4.80e+01
5 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 37500 2.01e+01 5.58e+01
6 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 45000 2.68e+01 6.81e+01
7 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 52500 3.02e+01 7.27e+01
8 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 60000 3.06e+01 7.25e+01
9 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 67500 3.47e+01 7.95e+01
10 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 75000 3.67e+01 8.24e+01
11 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 82500 3.57e+01 8.03e+01
12 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 90000 3.72e+01 8.22e+01
13 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 97500 3.83e+01 8.42e+01
14 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 105000 3.74e+01 8.29e+01
15 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 112500 3.98e+01 8.76e+01
16 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 120000 3.94e+01 8.56e+01
17 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 127500 4.12e+01 8.96e+01
18 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 135000 4.09e+01 8.88e+01
19 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 142500 3.99e+01 8.73e+01
20 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 4 150000 4.05e+01 8.74e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 7500 2.96e-01 4.31e+00
2 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 15000 8.45e-01 7.00e+00
3 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 22500 4.34e+00 1.83e+01
4 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 30000 1.77e+01 5.10e+01
5 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 37500 2.38e+01 6.12e+01
6 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 45000 2.68e+01 6.62e+01
7 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 52500 3.19e+01 7.50e+01
8 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 60000 3.14e+01 7.43e+01
9 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 67500 3.17e+01 7.33e+01
10 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 75000 3.45e+01 7.82e+01
11 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 82500 3.37e+01 7.58e+01
12 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 90000 3.51e+01 7.79e+01
13 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 97500 3.69e+01 8.18e+01
14 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 105000 3.64e+01 8.02e+01
15 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 112500 3.57e+01 7.95e+01
16 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 120000 3.94e+01 8.63e+01
17 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 127500 4.18e+01 9.14e+01
18 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 135000 3.93e+01 8.51e+01
19 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 142500 4.08e+01 8.81e+01
20 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 5 150000 4.02e+01 8.72e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 7500 3.15e-01 4.34e+00
2 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 15000 9.15e-01 7.14e+00
3 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 22500 5.18e+00 2.13e+01
4 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 30000 1.56e+01 4.66e+01
5 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 37500 2.07e+01 5.57e+01
6 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 45000 2.68e+01 6.77e+01
7 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 52500 2.90e+01 7.14e+01
8 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 60000 3.12e+01 7.39e+01
9 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 67500 3.18e+01 7.36e+01
10 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 75000 3.60e+01 8.11e+01
11 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 82500 3.52e+01 7.85e+01
12 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 90000 3.70e+01 8.19e+01
13 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 97500 3.66e+01 8.15e+01
14 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 105000 3.76e+01 8.22e+01
15 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 112500 3.86e+01 8.39e+01
16 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 120000 3.86e+01 8.41e+01
17 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 127500 3.74e+01 8.18e+01
18 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 135000 4.06e+01 8.68e+01
19 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 142500 4.16e+01 8.90e+01
20 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 6 150000 4.12e+01 8.90e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 7500 3.00e-01 4.13e+00
2 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 15000 7.81e-01 6.40e+00
3 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 22500 4.27e+00 1.81e+01
4 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 30000 1.40e+01 4.35e+01
5 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 37500 2.03e+01 5.66e+01
6 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 45000 2.49e+01 6.57e+01
7 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 52500 2.71e+01 6.79e+01
8 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 60000 2.83e+01 6.87e+01
9 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 67500 3.23e+01 7.64e+01
10 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 75000 3.41e+01 7.89e+01
11 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 82500 3.49e+01 8.09e+01
12 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 90000 3.37e+01 7.76e+01
13 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 97500 3.69e+01 8.39e+01
14 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 105000 3.71e+01 8.33e+01
15 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 112500 3.79e+01 8.50e+01
16 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 120000 3.76e+01 8.36e+01
17 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 127500 3.91e+01 8.56e+01
18 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 135000 3.97e+01 8.82e+01
19 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 142500 4.00e+01 8.76e+01
20 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 7 150000 4.08e+01 8.89e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 7500 3.26e-01 4.34e+00
2 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 15000 9.54e-01 7.14e+00
3 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 22500 5.22e+00 2.16e+01
4 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 30000 1.33e+01 4.40e+01
5 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 37500 1.97e+01 5.73e+01
6 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 45000 2.45e+01 6.50e+01
7 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 52500 3.01e+01 7.52e+01
8 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 60000 2.65e+01 6.58e+01
9 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 67500 3.28e+01 7.86e+01
10 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 75000 3.25e+01 7.62e+01
11 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 82500 3.30e+01 7.52e+01
12 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 90000 3.41e+01 7.78e+01
13 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 97500 3.76e+01 8.38e+01
14 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 105000 3.68e+01 8.26e+01
15 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 112500 3.88e+01 8.61e+01
16 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 120000 3.97e+01 8.76e+01
17 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 127500 3.94e+01 8.70e+01
18 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 135000 4.11e+01 8.95e+01
19 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 142500 4.02e+01 8.75e+01
20 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 8 150000 4.06e+01 8.80e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 7500 3.16e-01 4.31e+00
2 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 15000 9.30e-01 7.20e+00
3 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 22500 4.74e+00 1.97e+01
4 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 30000 1.38e+01 4.42e+01
5 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 37500 1.99e+01 5.99e+01
6 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 45000 2.62e+01 7.22e+01
7 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 52500 2.82e+01 7.48e+01
8 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 60000 2.90e+01 7.51e+01
9 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 67500 3.25e+01 8.07e+01
10 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 75000 3.22e+01 7.78e+01
11 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 82500 3.43e+01 8.17e+01
12 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 90000 3.68e+01 8.60e+01
13 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 97500 3.64e+01 8.42e+01
14 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 105000 3.89e+01 8.93e+01
15 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 112500 3.81e+01 8.67e+01
16 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 120000 3.87e+01 8.65e+01
17 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 127500 4.04e+01 9.04e+01
18 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 135000 3.96e+01 8.79e+01
19 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 142500 4.09e+01 9.02e+01
20 A3C 8 8 0 2 2.50e-01 False 2.50e-01 0 0 9 150000 4.15e+01 9.08e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 7500 1.06e-01 4.26e+00
2 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 15000 1.83e-01 5.22e+00
3 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 22500 3.06e-01 7.57e+00
4 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 30000 7.44e-01 1.34e+01
5 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 37500 1.91e+00 2.80e+01
6 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 45000 3.50e+00 4.19e+01
7 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 52500 4.81e+00 5.57e+01
8 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 60000 5.26e+00 6.20e+01
9 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 67500 5.83e+00 7.24e+01
10 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 75000 5.73e+00 7.14e+01
11 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 82500 6.38e+00 7.43e+01
12 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 90000 5.79e+00 7.27e+01
13 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 97500 6.38e+00 7.57e+01
14 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 105000 6.87e+00 7.83e+01
15 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 112500 6.96e+00 8.07e+01
16 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 120000 7.24e+00 8.65e+01
17 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 127500 6.85e+00 8.37e+01
18 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 135000 6.93e+00 8.12e+01
19 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 142500 6.97e+00 8.22e+01
20 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 0 150000 7.14e+00 8.94e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 7500 1.16e-01 4.07e+00
2 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 15000 1.55e-01 4.82e+00
3 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 22500 3.10e-01 6.92e+00
4 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 30000 7.32e-01 1.26e+01
5 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 37500 1.50e+00 2.30e+01
6 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 45000 3.20e+00 4.22e+01
7 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 52500 4.79e+00 6.04e+01
8 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 60000 4.76e+00 5.91e+01
9 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 67500 5.28e+00 6.42e+01
10 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 75000 5.91e+00 7.20e+01
11 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 82500 5.70e+00 7.02e+01
12 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 90000 6.14e+00 7.60e+01
13 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 97500 6.17e+00 7.20e+01
14 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 105000 6.17e+00 7.99e+01
15 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 112500 6.37e+00 8.13e+01
16 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 120000 6.26e+00 7.82e+01
17 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 127500 7.41e+00 8.55e+01
18 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 135000 6.34e+00 8.55e+01
19 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 142500 6.84e+00 8.47e+01
20 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 1 150000 6.22e+00 8.15e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 7500 1.22e-01 4.22e+00
2 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 15000 1.34e-01 4.87e+00
3 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 22500 2.66e-01 7.03e+00
4 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 30000 6.31e-01 1.31e+01
5 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 37500 1.45e+00 2.35e+01
6 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 45000 2.79e+00 3.90e+01
7 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 52500 4.25e+00 5.47e+01
8 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 60000 4.66e+00 5.47e+01
9 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 67500 5.33e+00 6.83e+01
10 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 75000 6.13e+00 7.50e+01
11 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 82500 5.93e+00 7.10e+01
12 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 90000 6.55e+00 7.99e+01
13 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 97500 6.79e+00 8.30e+01
14 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 105000 6.53e+00 8.01e+01
15 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 112500 5.60e+00 7.35e+01
16 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 120000 6.56e+00 8.17e+01
17 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 127500 7.22e+00 8.58e+01
18 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 135000 6.69e+00 8.43e+01
19 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 142500 6.09e+00 7.79e+01
20 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 2 150000 6.09e+00 8.35e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 7500 1.20e-01 4.13e+00
2 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 15000 1.59e-01 5.23e+00
3 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 22500 3.11e-01 7.36e+00
4 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 30000 7.03e-01 1.47e+01
5 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 37500 1.78e+00 2.65e+01
6 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 45000 3.24e+00 3.96e+01
7 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 52500 4.79e+00 5.58e+01
8 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 60000 5.48e+00 6.32e+01
9 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 67500 6.26e+00 6.99e+01
10 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 75000 6.06e+00 7.44e+01
11 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 82500 6.32e+00 7.79e+01
12 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 90000 6.32e+00 7.82e+01
13 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 97500 6.45e+00 8.02e+01
14 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 105000 6.45e+00 7.93e+01
15 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 112500 7.05e+00 8.60e+01
16 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 120000 6.35e+00 8.24e+01
17 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 127500 6.81e+00 8.63e+01
18 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 135000 6.45e+00 8.05e+01
19 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 142500 6.66e+00 8.45e+01
20 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 3 150000 6.67e+00 8.58e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 7500 1.12e-01 4.14e+00
2 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 15000 1.52e-01 4.95e+00
3 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 22500 3.08e-01 7.17e+00
4 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 30000 8.44e-01 1.43e+01
5 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 37500 1.68e+00 2.46e+01
6 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 45000 3.55e+00 4.65e+01
7 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 52500 4.88e+00 6.14e+01
8 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 60000 4.80e+00 6.13e+01
9 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 67500 5.28e+00 6.75e+01
10 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 75000 6.07e+00 7.03e+01
11 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 82500 5.91e+00 7.32e+01
12 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 90000 5.95e+00 7.77e+01
13 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 97500 6.11e+00 7.92e+01
14 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 105000 7.10e+00 8.03e+01
15 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 112500 6.57e+00 8.25e+01
16 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 120000 6.86e+00 8.40e+01
17 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 127500 7.20e+00 8.74e+01
18 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 135000 6.43e+00 8.21e+01
19 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 142500 6.21e+00 8.33e+01
20 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 4 150000 6.63e+00 8.48e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 7500 1.10e-01 4.07e+00
2 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 15000 1.26e-01 4.64e+00
3 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 22500 2.30e-01 6.51e+00
4 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 30000 6.26e-01 1.16e+01
5 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 37500 1.28e+00 2.24e+01
6 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 45000 3.04e+00 4.34e+01
7 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 52500 4.18e+00 5.21e+01
8 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 60000 5.09e+00 6.12e+01
9 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 67500 5.75e+00 7.27e+01
10 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 75000 5.56e+00 7.58e+01
11 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 82500 5.00e+00 6.72e+01
12 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 90000 5.47e+00 7.25e+01
13 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 97500 5.68e+00 8.00e+01
14 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 105000 5.82e+00 7.80e+01
15 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 112500 7.07e+00 8.50e+01
16 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 120000 6.36e+00 7.98e+01
17 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 127500 6.34e+00 7.83e+01
18 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 135000 7.12e+00 8.47e+01
19 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 142500 6.11e+00 8.10e+01
20 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 5 150000 6.63e+00 8.38e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 7500 1.05e-01 4.11e+00
2 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 15000 1.75e-01 5.35e+00
3 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 22500 3.79e-01 8.04e+00
4 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 30000 8.13e-01 1.56e+01
5 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 37500 1.85e+00 2.75e+01
6 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 45000 2.86e+00 3.86e+01
7 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 52500 4.25e+00 5.24e+01
8 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 60000 4.55e+00 5.79e+01
9 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 67500 5.70e+00 6.70e+01
10 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 75000 5.58e+00 6.87e+01
11 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 82500 7.04e+00 8.18e+01
12 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 90000 6.10e+00 7.28e+01
13 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 97500 6.21e+00 7.93e+01
14 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 105000 6.93e+00 8.61e+01
15 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 112500 6.70e+00 8.45e+01
16 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 120000 6.50e+00 8.12e+01
17 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 127500 6.48e+00 8.00e+01
18 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 135000 6.11e+00 7.92e+01
19 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 142500 7.03e+00 8.71e+01
20 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 6 150000 7.03e+00 8.55e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 7500 1.10e-01 4.15e+00
2 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 15000 1.65e-01 5.33e+00
3 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 22500 3.57e-01 7.81e+00
4 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 30000 1.09e+00 1.70e+01
5 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 37500 2.37e+00 3.30e+01
6 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 45000 3.86e+00 4.46e+01
7 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 52500 5.73e+00 6.46e+01
8 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 60000 5.31e+00 6.33e+01
9 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 67500 6.31e+00 6.75e+01
10 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 75000 5.70e+00 6.85e+01
11 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 82500 6.22e+00 7.60e+01
12 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 90000 5.77e+00 7.64e+01
13 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 97500 5.65e+00 7.12e+01
14 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 105000 5.82e+00 7.98e+01
15 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 112500 6.35e+00 8.63e+01
16 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 120000 6.49e+00 8.18e+01
17 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 127500 6.44e+00 8.08e+01
18 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 135000 7.11e+00 8.54e+01
19 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 142500 7.06e+00 8.65e+01
20 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 7 150000 6.54e+00 8.43e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 7500 9.52e-02 4.01e+00
2 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 15000 1.32e-01 4.51e+00
3 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 22500 2.30e-01 6.36e+00
4 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 30000 5.92e-01 1.13e+01
5 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 37500 1.56e+00 2.32e+01
6 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 45000 2.66e+00 4.02e+01
7 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 52500 3.71e+00 5.14e+01
8 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 60000 4.32e+00 5.73e+01
9 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 67500 5.17e+00 7.13e+01
10 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 75000 5.74e+00 7.25e+01
11 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 82500 5.93e+00 7.29e+01
12 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 90000 6.13e+00 8.04e+01
13 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 97500 6.28e+00 8.00e+01
14 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 105000 6.56e+00 8.39e+01
15 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 112500 6.36e+00 8.18e+01
16 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 120000 5.60e+00 7.75e+01
17 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 127500 6.38e+00 8.00e+01
18 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 135000 6.39e+00 8.52e+01
19 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 142500 7.20e+00 8.49e+01
20 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 8 150000 6.78e+00 8.48e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 7500 1.06e-01 4.15e+00
2 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 15000 1.54e-01 5.09e+00
3 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 22500 2.91e-01 7.22e+00
4 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 30000 6.96e-01 1.28e+01
5 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 37500 1.72e+00 2.54e+01
6 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 45000 3.39e+00 4.26e+01
7 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 52500 4.96e+00 5.68e+01
8 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 60000 5.21e+00 6.18e+01
9 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 67500 5.68e+00 6.10e+01
10 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 75000 5.87e+00 7.29e+01
11 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 82500 5.63e+00 7.52e+01
12 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 90000 5.28e+00 6.82e+01
13 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 97500 6.34e+00 7.66e+01
14 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 105000 6.34e+00 7.64e+01
15 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 112500 6.39e+00 8.24e+01
16 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 120000 6.52e+00 8.73e+01
17 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 127500 6.10e+00 8.02e+01
18 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 135000 6.96e+00 8.68e+01
19 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 142500 6.56e+00 8.25e+01
20 A3C 8 8 0 3 2.50e-01 False 2.50e-01 0 0 9 150000 6.47e+00 8.51e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 7500 3.00e-02 4.01e+00
2 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 15000 3.92e-02 4.43e+00
3 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 22500 4.99e-02 4.77e+00
4 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 30000 4.99e-02 5.01e+00
5 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 37500 6.25e-02 5.74e+00
6 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 45000 6.58e-02 5.87e+00
7 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 52500 6.80e-02 6.40e+00
8 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 60000 7.35e-02 6.93e+00
9 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 67500 1.05e-01 7.02e+00
10 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 75000 1.16e-01 8.45e+00
11 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 82500 1.18e-01 9.09e+00
12 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 90000 1.28e-01 9.34e+00
13 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 97500 1.44e-01 9.91e+00
14 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 105000 1.21e-01 1.03e+01
15 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 112500 1.47e-01 1.07e+01
16 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 120000 1.76e-01 1.17e+01
17 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 127500 2.14e-01 1.40e+01
18 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 135000 2.24e-01 1.49e+01
19 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 142500 3.03e-01 1.83e+01
20 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 0 150000 3.18e-01 2.16e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 7500 3.52e-02 4.01e+00
2 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 15000 3.37e-02 4.36e+00
3 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 22500 4.17e-02 4.61e+00
4 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 30000 4.76e-02 5.07e+00
5 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 37500 5.89e-02 5.37e+00
6 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 45000 7.76e-02 6.16e+00
7 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 52500 5.85e-02 6.70e+00
8 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 60000 8.29e-02 6.82e+00
9 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 67500 1.03e-01 7.64e+00
10 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 75000 1.09e-01 8.35e+00
11 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 82500 1.09e-01 8.20e+00
12 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 90000 1.28e-01 9.48e+00
13 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 97500 1.42e-01 1.01e+01
14 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 105000 1.59e-01 1.12e+01
15 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 112500 1.73e-01 1.21e+01
16 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 120000 2.48e-01 1.43e+01
17 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 127500 3.11e-01 1.81e+01
18 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 135000 3.17e-01 2.12e+01
19 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 142500 5.84e-01 2.74e+01
20 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 1 150000 6.36e-01 3.21e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 7500 2.76e-02 3.92e+00
2 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 15000 3.36e-02 4.24e+00
3 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 22500 3.38e-02 4.61e+00
4 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 30000 4.33e-02 4.80e+00
5 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 37500 5.44e-02 5.27e+00
6 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 45000 5.66e-02 5.46e+00
7 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 52500 6.10e-02 6.03e+00
8 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 60000 5.94e-02 6.04e+00
9 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 67500 9.68e-02 7.22e+00
10 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 75000 9.07e-02 7.15e+00
11 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 82500 1.26e-01 8.75e+00
12 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 90000 1.48e-01 9.80e+00
13 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 97500 1.58e-01 1.10e+01
14 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 105000 2.02e-01 1.24e+01
15 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 112500 2.43e-01 1.46e+01
16 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 120000 3.44e-01 1.86e+01
17 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 127500 3.82e-01 2.40e+01
18 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 135000 6.07e-01 2.81e+01
19 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 142500 5.66e-01 3.18e+01
20 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 2 150000 7.38e-01 4.01e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 7500 3.81e-02 4.19e+00
2 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 15000 4.07e-02 4.33e+00
3 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 22500 4.77e-02 4.80e+00
4 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 30000 4.81e-02 5.08e+00
5 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 37500 6.30e-02 5.43e+00
6 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 45000 8.29e-02 6.07e+00
7 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 52500 7.23e-02 6.85e+00
8 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 60000 7.84e-02 6.94e+00
9 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 67500 9.24e-02 7.45e+00
10 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 75000 1.07e-01 8.28e+00
11 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 82500 1.23e-01 8.54e+00
12 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 90000 1.60e-01 1.03e+01
13 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 97500 1.48e-01 1.13e+01
14 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 105000 1.42e-01 1.13e+01
15 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 112500 1.94e-01 1.14e+01
16 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 120000 1.81e-01 1.40e+01
17 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 127500 2.53e-01 1.46e+01
18 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 135000 2.86e-01 1.73e+01
19 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 142500 3.66e-01 2.03e+01
20 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 3 150000 4.47e-01 2.42e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 7500 3.70e-02 4.19e+00
2 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 15000 3.43e-02 4.29e+00
3 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 22500 3.87e-02 4.67e+00
4 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 30000 5.09e-02 5.11e+00
5 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 37500 6.72e-02 5.91e+00
6 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 45000 5.53e-02 5.82e+00
7 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 52500 6.33e-02 6.32e+00
8 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 60000 7.57e-02 6.49e+00
9 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 67500 7.10e-02 6.85e+00
10 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 75000 1.06e-01 7.57e+00
11 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 82500 1.02e-01 8.16e+00
12 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 90000 1.18e-01 9.29e+00
13 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 97500 1.69e-01 1.06e+01
14 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 105000 2.21e-01 1.26e+01
15 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 112500 2.30e-01 1.43e+01
16 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 120000 3.60e-01 1.82e+01
17 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 127500 4.26e-01 2.37e+01
18 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 135000 5.49e-01 2.94e+01
19 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 142500 5.71e-01 3.24e+01
20 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 4 150000 7.49e-01 3.98e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 7500 3.52e-02 4.11e+00
2 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 15000 3.56e-02 4.28e+00
3 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 22500 5.19e-02 4.75e+00
4 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 30000 5.17e-02 5.49e+00
5 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 37500 7.70e-02 6.07e+00
6 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 45000 7.41e-02 6.46e+00
7 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 52500 8.61e-02 7.20e+00
8 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 60000 9.74e-02 7.61e+00
9 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 67500 1.18e-01 8.46e+00
10 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 75000 1.26e-01 8.94e+00
11 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 82500 1.42e-01 1.00e+01
12 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 90000 1.66e-01 1.13e+01
13 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 97500 2.14e-01 1.30e+01
14 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 105000 2.86e-01 1.55e+01
15 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 112500 3.41e-01 2.07e+01
16 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 120000 4.22e-01 2.25e+01
17 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 127500 5.19e-01 2.81e+01
18 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 135000 7.37e-01 3.59e+01
19 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 142500 8.40e-01 3.99e+01
20 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 5 150000 1.06e+00 5.15e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 7500 2.42e-02 3.86e+00
2 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 15000 4.08e-02 4.37e+00
3 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 22500 4.44e-02 4.88e+00
4 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 30000 5.39e-02 5.14e+00
5 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 37500 6.59e-02 5.91e+00
6 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 45000 5.87e-02 6.15e+00
7 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 52500 7.22e-02 6.53e+00
8 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 60000 9.78e-02 7.23e+00
9 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 67500 9.81e-02 7.71e+00
10 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 75000 1.22e-01 8.33e+00
11 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 82500 1.15e-01 8.95e+00
12 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 90000 1.18e-01 9.70e+00
13 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 97500 2.03e-01 1.10e+01
14 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 105000 2.42e-01 1.36e+01
15 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 112500 2.25e-01 1.49e+01
16 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 120000 3.33e-01 1.75e+01
17 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 127500 4.22e-01 2.20e+01
18 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 135000 4.47e-01 2.46e+01
19 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 142500 6.43e-01 3.42e+01
20 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 6 150000 8.09e-01 3.91e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 7500 3.56e-02 4.02e+00
2 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 15000 3.81e-02 4.28e+00
3 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 22500 4.22e-02 4.67e+00
4 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 30000 4.79e-02 4.95e+00
5 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 37500 6.03e-02 5.33e+00
6 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 45000 6.86e-02 6.14e+00
7 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 52500 8.24e-02 6.71e+00
8 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 60000 9.02e-02 7.20e+00
9 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 67500 1.12e-01 8.12e+00
10 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 75000 1.39e-01 9.26e+00
11 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 82500 1.61e-01 1.02e+01
12 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 90000 1.71e-01 1.17e+01
13 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 97500 1.82e-01 1.26e+01
14 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 105000 2.70e-01 1.51e+01
15 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 112500 3.04e-01 1.79e+01
16 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 120000 3.73e-01 1.99e+01
17 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 127500 5.26e-01 2.67e+01
18 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 135000 7.39e-01 3.50e+01
19 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 142500 9.16e-01 4.11e+01
20 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 7 150000 9.80e-01 4.98e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 7500 2.40e-02 3.87e+00
2 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 15000 3.61e-02 4.26e+00
3 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 22500 4.62e-02 4.53e+00
4 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 30000 4.15e-02 4.80e+00
5 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 37500 4.77e-02 5.32e+00
6 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 45000 6.09e-02 5.74e+00
7 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 52500 8.72e-02 6.60e+00
8 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 60000 8.34e-02 7.00e+00
9 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 67500 1.16e-01 7.87e+00
10 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 75000 1.03e-01 8.10e+00
11 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 82500 1.10e-01 8.63e+00
12 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 90000 1.38e-01 9.53e+00
13 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 97500 1.70e-01 1.05e+01
14 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 105000 2.18e-01 1.30e+01
15 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 112500 2.86e-01 1.59e+01
16 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 120000 3.42e-01 1.96e+01
17 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 127500 4.10e-01 2.21e+01
18 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 135000 5.43e-01 2.83e+01
19 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 142500 6.46e-01 3.23e+01
20 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 8 150000 7.82e-01 4.17e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 7500 3.59e-02 4.17e+00
2 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 15000 3.12e-02 4.33e+00
3 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 22500 5.36e-02 4.70e+00
4 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 30000 5.49e-02 5.25e+00
5 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 37500 5.38e-02 5.72e+00
6 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 45000 6.41e-02 5.96e+00
7 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 52500 7.43e-02 6.75e+00
8 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 60000 9.90e-02 7.52e+00
9 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 67500 1.00e-01 8.17e+00
10 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 75000 8.54e-02 7.89e+00
11 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 82500 1.22e-01 8.48e+00
12 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 90000 1.39e-01 9.24e+00
13 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 97500 1.88e-01 1.14e+01
14 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 105000 2.13e-01 1.31e+01
15 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 112500 2.50e-01 1.46e+01
16 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 120000 2.87e-01 1.81e+01
17 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 127500 2.73e-01 1.83e+01
18 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 135000 3.84e-01 2.38e+01
19 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 142500 4.77e-01 2.59e+01
20 A3C 8 8 0 4 2.50e-01 False 2.50e-01 0 0 9 150000 5.88e-01 3.47e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 7500 6.13e-01 4.18e+00
2 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 15000 2.20e+00 6.78e+00
3 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 22500 3.05e+01 3.62e+01
4 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 30000 7.03e+01 7.41e+01
5 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 37500 7.65e+01 8.03e+01
6 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 45000 8.13e+01 8.50e+01
7 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 52500 8.33e+01 8.72e+01
8 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 60000 8.48e+01 8.78e+01
9 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 67500 9.13e+01 9.47e+01
10 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 75000 8.92e+01 9.34e+01
11 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 82500 8.78e+01 9.28e+01
12 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 90000 8.95e+01 9.49e+01
13 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 97500 8.45e+01 9.48e+01
14 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 105000 8.85e+01 9.65e+01
15 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 112500 8.31e+01 9.28e+01
16 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 120000 8.20e+01 9.17e+01
17 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 127500 8.73e+01 9.63e+01
18 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 135000 8.83e+01 9.74e+01
19 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 142500 8.61e+01 9.54e+01
20 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 0 150000 8.72e+01 9.60e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 7500 6.16e-01 4.18e+00
2 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 15000 2.46e+00 6.93e+00
3 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 22500 3.59e+01 4.06e+01
4 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 30000 7.19e+01 7.55e+01
5 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 37500 8.07e+01 8.46e+01
6 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 45000 7.93e+01 8.25e+01
7 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 52500 9.10e+01 9.50e+01
8 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 60000 8.71e+01 9.03e+01
9 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 67500 8.69e+01 9.01e+01
10 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 75000 8.92e+01 9.31e+01
11 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 82500 9.06e+01 9.43e+01
12 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 90000 8.74e+01 9.16e+01
13 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 97500 9.21e+01 9.74e+01
14 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 105000 8.46e+01 9.48e+01
15 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 112500 8.51e+01 9.68e+01
16 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 120000 8.85e+01 9.90e+01
17 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 127500 8.62e+01 9.80e+01
18 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 135000 8.81e+01 9.85e+01
19 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 142500 9.02e+01 9.74e+01
20 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 1 150000 9.03e+01 9.79e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 7500 5.91e-01 4.27e+00
2 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 15000 2.31e+00 6.96e+00
3 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 22500 3.12e+01 3.63e+01
4 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 30000 6.73e+01 7.04e+01
5 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 37500 8.02e+01 8.38e+01
6 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 45000 8.09e+01 8.42e+01
7 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 52500 8.73e+01 9.07e+01
8 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 60000 8.75e+01 9.09e+01
9 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 67500 8.64e+01 8.99e+01
10 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 75000 9.19e+01 9.58e+01
11 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 82500 9.12e+01 9.52e+01
12 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 90000 8.57e+01 9.12e+01
13 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 97500 8.39e+01 9.41e+01
14 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 105000 8.26e+01 9.47e+01
15 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 112500 8.80e+01 9.87e+01
16 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 120000 8.25e+01 9.36e+01
17 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 127500 8.45e+01 9.42e+01
18 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 135000 8.60e+01 9.63e+01
19 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 142500 8.87e+01 9.75e+01
20 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 2 150000 8.67e+01 9.57e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 7500 5.91e-01 4.14e+00
2 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 15000 2.55e+00 7.01e+00
3 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 22500 3.28e+01 3.74e+01
4 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 30000 7.37e+01 7.75e+01
5 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 37500 7.59e+01 7.99e+01
6 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 45000 9.01e+01 9.30e+01
7 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 52500 8.41e+01 8.73e+01
8 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 60000 8.58e+01 8.90e+01
9 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 67500 8.80e+01 9.23e+01
10 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 75000 9.07e+01 9.43e+01
11 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 82500 8.90e+01 9.27e+01
12 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 90000 8.73e+01 9.07e+01
13 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 97500 8.53e+01 9.22e+01
14 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 105000 7.98e+01 9.15e+01
15 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 112500 8.58e+01 9.57e+01
16 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 120000 8.83e+01 9.81e+01
17 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 127500 8.80e+01 9.65e+01
18 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 135000 9.08e+01 9.88e+01
19 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 142500 9.14e+01 9.91e+01
20 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 3 150000 8.79e+01 9.53e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 7500 6.02e-01 4.32e+00
2 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 15000 2.08e+00 6.79e+00
3 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 22500 2.57e+01 3.08e+01
4 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 30000 6.60e+01 6.97e+01
5 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 37500 7.90e+01 8.29e+01
6 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 45000 8.22e+01 8.45e+01
7 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 52500 8.83e+01 9.14e+01
8 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 60000 8.54e+01 8.83e+01
9 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 67500 8.86e+01 9.18e+01
10 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 75000 9.00e+01 9.29e+01
11 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 82500 9.28e+01 9.55e+01
12 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 90000 9.10e+01 9.35e+01
13 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 97500 8.60e+01 8.91e+01
14 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 105000 8.85e+01 9.20e+01
15 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 112500 8.19e+01 9.02e+01
16 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 120000 8.36e+01 9.34e+01
17 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 127500 8.76e+01 9.51e+01
18 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 135000 8.95e+01 9.70e+01
19 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 142500 9.12e+01 9.82e+01
20 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 4 150000 9.04e+01 9.71e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 7500 5.99e-01 4.10e+00
2 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 15000 2.94e+00 7.52e+00
3 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 22500 4.21e+01 4.75e+01
4 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 30000 7.65e+01 8.05e+01
5 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 37500 7.43e+01 7.76e+01
6 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 45000 8.38e+01 8.76e+01
7 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 52500 8.97e+01 9.29e+01
8 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 60000 9.02e+01 9.37e+01
9 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 67500 8.70e+01 9.10e+01
10 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 75000 8.81e+01 9.22e+01
11 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 82500 8.92e+01 9.27e+01
12 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 90000 9.03e+01 9.44e+01
13 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 97500 8.80e+01 9.48e+01
14 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 105000 8.59e+01 9.57e+01
15 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 112500 8.15e+01 9.41e+01
16 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 120000 8.79e+01 9.71e+01
17 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 127500 8.97e+01 9.64e+01
18 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 135000 8.54e+01 9.30e+01
19 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 142500 8.45e+01 9.38e+01
20 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 5 150000 8.77e+01 9.69e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 7500 5.88e-01 4.24e+00
2 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 15000 2.44e+00 7.18e+00
3 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 22500 3.36e+01 3.82e+01
4 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 30000 7.38e+01 7.72e+01
5 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 37500 8.26e+01 8.61e+01
6 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 45000 8.33e+01 8.67e+01
7 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 52500 8.55e+01 8.89e+01
8 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 60000 8.35e+01 8.70e+01
9 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 67500 8.82e+01 9.19e+01
10 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 75000 8.95e+01 9.28e+01
11 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 82500 8.83e+01 9.12e+01
12 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 90000 8.63e+01 9.00e+01
13 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 97500 8.97e+01 9.39e+01
14 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 105000 9.09e+01 9.42e+01
15 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 112500 9.00e+01 9.56e+01
16 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 120000 8.01e+01 9.10e+01
17 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 127500 8.35e+01 9.37e+01
18 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 135000 8.65e+01 9.46e+01
19 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 142500 8.76e+01 9.56e+01
20 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 6 150000 8.74e+01 9.52e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 7500 6.28e-01 4.28e+00
2 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 15000 2.42e+00 6.86e+00
3 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 22500 3.27e+01 3.76e+01
4 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 30000 7.19e+01 7.55e+01
5 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 37500 7.21e+01 7.58e+01
6 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 45000 8.27e+01 8.53e+01
7 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 52500 8.70e+01 8.98e+01
8 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 60000 8.42e+01 8.75e+01
9 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 67500 8.63e+01 8.98e+01
10 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 75000 9.08e+01 9.40e+01
11 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 82500 8.64e+01 9.03e+01
12 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 90000 9.03e+01 9.33e+01
13 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 97500 9.08e+01 9.39e+01
14 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 105000 8.74e+01 9.28e+01
15 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 112500 8.14e+01 9.04e+01
16 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 120000 8.52e+01 9.71e+01
17 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 127500 8.47e+01 9.41e+01
18 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 135000 8.84e+01 9.51e+01
19 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 142500 8.85e+01 9.48e+01
20 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 7 150000 8.89e+01 9.65e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 7500 5.76e-01 4.15e+00
2 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 15000 2.47e+00 7.31e+00
3 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 22500 3.19e+01 3.75e+01
4 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 30000 6.36e+01 6.70e+01
5 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 37500 7.60e+01 7.94e+01
6 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 45000 7.96e+01 8.23e+01
7 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 52500 8.91e+01 9.30e+01
8 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 60000 9.24e+01 9.57e+01
9 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 67500 8.58e+01 8.91e+01
10 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 75000 8.80e+01 9.18e+01
11 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 82500 8.92e+01 9.26e+01
12 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 90000 8.76e+01 9.12e+01
13 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 97500 8.83e+01 9.29e+01
14 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 105000 8.70e+01 9.31e+01
15 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 112500 8.71e+01 9.50e+01
16 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 120000 8.56e+01 9.45e+01
17 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 127500 8.53e+01 9.52e+01
18 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 135000 8.66e+01 9.57e+01
19 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 142500 8.51e+01 9.32e+01
20 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 8 150000 9.21e+01 9.90e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 7500 6.08e-01 4.23e+00
2 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 15000 2.22e+00 6.50e+00
3 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 22500 3.10e+01 3.64e+01
4 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 30000 7.28e+01 7.72e+01
5 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 37500 7.44e+01 7.81e+01
6 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 45000 8.50e+01 8.91e+01
7 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 52500 8.80e+01 9.24e+01
8 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 60000 8.91e+01 9.20e+01
9 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 67500 8.97e+01 9.30e+01
10 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 75000 9.08e+01 9.43e+01
11 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 82500 9.10e+01 9.46e+01
12 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 90000 8.76e+01 9.19e+01
13 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 97500 8.75e+01 9.26e+01
14 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 105000 7.88e+01 8.87e+01
15 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 112500 7.85e+01 9.06e+01
16 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 120000 7.69e+01 8.77e+01
17 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 127500 8.35e+01 9.46e+01
18 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 135000 8.22e+01 9.39e+01
19 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 142500 8.48e+01 9.44e+01
20 A3C 8 8 1 1 2.50e-01 False 2.50e-01 0 0 9 150000 8.72e+01 9.40e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 7500 2.67e-01 4.16e+00
2 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 15000 3.91e-01 5.25e+00
3 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 22500 7.65e-01 9.06e+00
4 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 30000 1.82e+00 1.91e+01
5 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 37500 3.51e+00 3.77e+01
6 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 45000 4.90e+00 5.60e+01
7 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 52500 6.18e+00 6.44e+01
8 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 60000 6.61e+00 6.43e+01
9 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 67500 8.21e+00 6.30e+01
10 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 75000 9.61e+00 6.55e+01
11 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 82500 9.99e+00 7.82e+01
12 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 90000 1.05e+01 7.95e+01
13 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 97500 1.05e+01 8.65e+01
14 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 105000 1.08e+01 8.49e+01
15 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 112500 1.15e+01 8.03e+01
16 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 120000 1.34e+01 8.74e+01
17 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 127500 1.13e+01 7.95e+01
18 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 135000 1.40e+01 8.32e+01
19 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 142500 1.36e+01 8.21e+01
20 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 0 150000 1.43e+01 8.40e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 7500 2.69e-01 4.27e+00
2 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 15000 3.80e-01 5.49e+00
3 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 22500 7.36e-01 9.21e+00
4 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 30000 1.54e+00 1.90e+01
5 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 37500 2.33e+00 3.08e+01
6 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 45000 3.91e+00 4.62e+01
7 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 52500 5.66e+00 5.67e+01
8 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 60000 7.35e+00 6.12e+01
9 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 67500 8.78e+00 6.45e+01
10 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 75000 9.93e+00 7.11e+01
11 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 82500 9.82e+00 7.04e+01
12 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 90000 1.22e+01 8.14e+01
13 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 97500 1.23e+01 7.81e+01
14 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 105000 1.16e+01 7.69e+01
15 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 112500 1.25e+01 8.50e+01
16 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 120000 1.21e+01 8.11e+01
17 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 127500 1.26e+01 8.10e+01
18 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 135000 1.34e+01 8.51e+01
19 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 142500 1.25e+01 8.69e+01
20 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 1 150000 1.18e+01 8.33e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 7500 2.64e-01 4.20e+00
2 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 15000 3.97e-01 5.28e+00
3 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 22500 7.71e-01 8.97e+00
4 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 30000 1.46e+00 1.78e+01
5 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 37500 2.32e+00 3.29e+01
6 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 45000 3.63e+00 4.68e+01
7 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 52500 4.40e+00 5.62e+01
8 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 60000 5.67e+00 6.23e+01
9 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 67500 6.90e+00 6.68e+01
10 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 75000 7.79e+00 6.44e+01
11 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 82500 8.37e+00 7.12e+01
12 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 90000 9.46e+00 7.89e+01
13 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 97500 1.02e+01 7.67e+01
14 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 105000 1.16e+01 8.05e+01
15 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 112500 1.05e+01 7.90e+01
16 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 120000 1.14e+01 8.29e+01
17 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 127500 1.17e+01 8.27e+01
18 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 135000 1.16e+01 8.18e+01
19 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 142500 1.29e+01 8.58e+01
20 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 2 150000 1.15e+01 7.94e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 7500 2.80e-01 4.13e+00
2 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 15000 3.88e-01 5.02e+00
3 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 22500 8.53e-01 8.80e+00
4 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 30000 2.02e+00 1.75e+01
5 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 37500 4.82e+00 4.20e+01
6 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 45000 6.68e+00 6.51e+01
7 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 52500 7.63e+00 7.16e+01
8 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 60000 8.31e+00 7.23e+01
9 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 67500 8.68e+00 7.53e+01
10 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 75000 8.58e+00 7.35e+01
11 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 82500 8.95e+00 6.52e+01
12 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 90000 1.25e+01 7.80e+01
13 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 97500 1.10e+01 7.32e+01
14 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 105000 1.22e+01 8.33e+01
15 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 112500 1.14e+01 7.62e+01
16 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 120000 1.34e+01 8.63e+01
17 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 127500 1.32e+01 8.43e+01
18 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 135000 1.30e+01 7.93e+01
19 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 142500 1.47e+01 8.45e+01
20 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 3 150000 1.43e+01 8.28e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 7500 2.47e-01 4.07e+00
2 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 15000 4.22e-01 5.35e+00
3 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 22500 8.31e-01 9.34e+00
4 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 30000 1.70e+00 1.96e+01
5 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 37500 3.10e+00 3.62e+01
6 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 45000 3.64e+00 4.49e+01
7 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 52500 4.70e+00 5.51e+01
8 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 60000 5.25e+00 5.42e+01
9 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 67500 7.33e+00 7.02e+01
10 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 75000 9.82e+00 7.17e+01
11 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 82500 9.77e+00 7.37e+01
12 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 90000 9.66e+00 7.41e+01
13 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 97500 9.91e+00 7.48e+01
14 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 105000 1.17e+01 8.10e+01
15 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 112500 1.12e+01 7.94e+01
16 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 120000 1.20e+01 8.26e+01
17 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 127500 1.30e+01 8.48e+01
18 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 135000 1.23e+01 8.14e+01
19 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 142500 1.41e+01 8.64e+01
20 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 4 150000 1.41e+01 8.28e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 7500 2.91e-01 4.25e+00
2 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 15000 4.17e-01 5.41e+00
3 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 22500 7.92e-01 8.57e+00
4 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 30000 1.73e+00 1.82e+01
5 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 37500 3.43e+00 3.78e+01
6 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 45000 5.39e+00 5.43e+01
7 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 52500 6.79e+00 5.74e+01
8 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 60000 9.11e+00 6.03e+01
9 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 67500 9.60e+00 6.74e+01
10 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 75000 1.03e+01 6.84e+01
11 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 82500 1.23e+01 7.90e+01
12 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 90000 1.26e+01 7.59e+01
13 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 97500 1.32e+01 8.14e+01
14 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 105000 1.20e+01 8.06e+01
15 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 112500 1.29e+01 8.48e+01
16 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 120000 1.28e+01 7.70e+01
17 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 127500 1.35e+01 8.16e+01
18 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 135000 1.32e+01 8.26e+01
19 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 142500 1.31e+01 8.23e+01
20 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 5 150000 1.34e+01 8.84e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 7500 2.69e-01 4.21e+00
2 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 15000 4.13e-01 5.41e+00
3 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 22500 8.53e-01 9.97e+00
4 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 30000 1.93e+00 1.92e+01
5 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 37500 3.70e+00 3.65e+01
6 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 45000 5.77e+00 5.58e+01
7 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 52500 6.50e+00 6.16e+01
8 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 60000 1.00e+01 7.06e+01
9 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 67500 9.62e+00 7.01e+01
10 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 75000 9.98e+00 7.13e+01
11 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 82500 1.02e+01 7.49e+01
12 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 90000 1.15e+01 7.95e+01
13 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 97500 1.21e+01 7.95e+01
14 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 105000 1.13e+01 7.76e+01
15 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 112500 1.16e+01 7.75e+01
16 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 120000 1.31e+01 8.38e+01
17 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 127500 1.29e+01 8.56e+01
18 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 135000 1.33e+01 8.75e+01
19 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 142500 1.43e+01 8.40e+01
20 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 6 150000 1.50e+01 8.82e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 7500 2.74e-01 4.17e+00
2 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 15000 3.54e-01 5.03e+00
3 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 22500 7.85e-01 8.48e+00
4 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 30000 1.59e+00 1.54e+01
5 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 37500 3.45e+00 3.26e+01
6 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 45000 5.67e+00 5.60e+01
7 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 52500 6.34e+00 6.20e+01
8 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 60000 8.20e+00 6.93e+01
9 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 67500 1.02e+01 7.43e+01
10 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 75000 1.13e+01 7.13e+01
11 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 82500 1.25e+01 7.17e+01
12 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 90000 1.17e+01 7.48e+01
13 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 97500 1.26e+01 8.07e+01
14 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 105000 1.30e+01 8.75e+01
15 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 112500 1.29e+01 8.39e+01
16 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 120000 1.30e+01 8.28e+01
17 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 127500 1.27e+01 8.85e+01
18 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 135000 1.14e+01 8.86e+01
19 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 142500 1.28e+01 8.96e+01
20 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 7 150000 1.36e+01 9.02e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 7500 2.64e-01 4.01e+00
2 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 15000 3.63e-01 5.04e+00
3 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 22500 6.67e-01 8.34e+00
4 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 30000 1.43e+00 1.56e+01
5 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 37500 3.06e+00 3.30e+01
6 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 45000 4.45e+00 5.25e+01
7 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 52500 6.08e+00 5.76e+01
8 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 60000 7.27e+00 5.83e+01
9 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 67500 1.02e+01 6.72e+01
10 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 75000 1.21e+01 7.54e+01
11 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 82500 1.11e+01 7.46e+01
12 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 90000 1.10e+01 7.47e+01
13 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 97500 1.22e+01 7.58e+01
14 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 105000 1.26e+01 7.97e+01
15 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 112500 1.41e+01 8.75e+01
16 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 120000 1.40e+01 8.32e+01
17 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 127500 1.35e+01 8.11e+01
18 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 135000 1.43e+01 8.30e+01
19 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 142500 1.34e+01 8.26e+01
20 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 8 150000 1.41e+01 8.43e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 7500 2.55e-01 4.02e+00
2 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 15000 3.96e-01 5.19e+00
3 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 22500 7.15e-01 9.31e+00
4 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 30000 1.53e+00 1.79e+01
5 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 37500 2.58e+00 3.06e+01
6 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 45000 4.35e+00 4.97e+01
7 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 52500 5.15e+00 5.43e+01
8 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 60000 6.99e+00 6.35e+01
9 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 67500 7.21e+00 6.49e+01
10 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 75000 1.01e+01 7.56e+01
11 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 82500 9.98e+00 7.39e+01
12 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 90000 1.12e+01 7.76e+01
13 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 97500 1.12e+01 7.91e+01
14 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 105000 1.12e+01 7.94e+01
15 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 112500 1.27e+01 8.66e+01
16 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 120000 1.21e+01 8.36e+01
17 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 127500 1.25e+01 8.89e+01
18 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 135000 1.33e+01 8.78e+01
19 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 142500 1.36e+01 8.58e+01
20 A3C 8 8 1 2 2.50e-01 False 2.50e-01 0 0 9 150000 1.27e+01 8.36e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 7500 9.84e-02 4.01e+00
2 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 15000 1.24e-01 4.55e+00
3 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 22500 1.69e-01 5.57e+00
4 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 30000 2.37e-01 7.48e+00
5 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 37500 3.87e-01 1.07e+01
6 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 45000 6.27e-01 1.63e+01
7 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 52500 1.08e+00 2.55e+01
8 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 60000 1.63e+00 3.86e+01
9 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 67500 2.14e+00 4.71e+01
10 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 75000 1.82e+00 5.22e+01
11 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 82500 2.92e+00 6.66e+01
12 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 90000 2.72e+00 6.70e+01
13 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 97500 2.58e+00 6.89e+01
14 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 105000 3.15e+00 7.29e+01
15 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 112500 3.29e+00 7.58e+01
16 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 120000 3.64e+00 7.60e+01
17 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 127500 3.36e+00 7.61e+01
18 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 135000 3.40e+00 7.82e+01
19 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 142500 3.56e+00 8.25e+01
20 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 0 150000 3.17e+00 7.24e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 7500 1.09e-01 3.98e+00
2 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 15000 1.20e-01 4.49e+00
3 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 22500 1.71e-01 5.46e+00
4 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 30000 2.32e-01 6.98e+00
5 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 37500 3.43e-01 1.00e+01
6 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 45000 6.30e-01 1.54e+01
7 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 52500 1.06e+00 2.52e+01
8 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 60000 1.45e+00 3.39e+01
9 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 67500 1.58e+00 4.13e+01
10 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 75000 2.55e+00 5.81e+01
11 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 82500 2.63e+00 6.04e+01
12 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 90000 2.67e+00 6.64e+01
13 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 97500 2.67e+00 6.51e+01
14 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 105000 2.92e+00 7.04e+01
15 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 112500 3.11e+00 7.63e+01
16 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 120000 3.49e+00 7.94e+01
17 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 127500 3.38e+00 7.99e+01
18 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 135000 3.56e+00 7.80e+01
19 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 142500 3.71e+00 8.32e+01
20 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 1 150000 3.76e+00 8.69e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 7500 1.04e-01 4.03e+00
2 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 15000 1.29e-01 4.52e+00
3 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 22500 1.76e-01 5.43e+00
4 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 30000 2.37e-01 6.82e+00
5 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 37500 4.07e-01 1.06e+01
6 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 45000 6.35e-01 1.68e+01
7 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 52500 1.06e+00 2.68e+01
8 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 60000 1.66e+00 3.71e+01
9 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 67500 1.67e+00 4.41e+01
10 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 75000 2.07e+00 5.59e+01
11 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 82500 2.38e+00 5.83e+01
12 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 90000 2.45e+00 6.31e+01
13 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 97500 3.17e+00 7.65e+01
14 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 105000 3.27e+00 7.52e+01
15 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 112500 3.39e+00 7.56e+01
16 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 120000 3.19e+00 7.62e+01
17 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 127500 3.46e+00 7.75e+01
18 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 135000 3.41e+00 8.16e+01
19 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 142500 3.52e+00 7.56e+01
20 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 2 150000 3.26e+00 7.99e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 7500 1.05e-01 4.01e+00
2 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 15000 1.27e-01 4.54e+00
3 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 22500 1.59e-01 5.14e+00
4 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 30000 2.27e-01 7.03e+00
5 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 37500 3.48e-01 9.70e+00
6 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 45000 6.43e-01 1.67e+01
7 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 52500 9.22e-01 2.42e+01
8 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 60000 1.48e+00 3.56e+01
9 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 67500 1.83e+00 4.26e+01
10 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 75000 2.39e+00 5.52e+01
11 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 82500 2.66e+00 6.03e+01
12 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 90000 2.82e+00 6.44e+01
13 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 97500 2.61e+00 6.60e+01
14 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 105000 2.87e+00 6.63e+01
15 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 112500 3.11e+00 7.04e+01
16 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 120000 3.50e+00 7.65e+01
17 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 127500 3.66e+00 7.87e+01
18 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 135000 3.42e+00 7.88e+01
19 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 142500 3.77e+00 8.14e+01
20 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 3 150000 3.78e+00 8.18e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 7500 9.38e-02 4.03e+00
2 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 15000 1.14e-01 4.45e+00
3 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 22500 1.69e-01 5.50e+00
4 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 30000 3.18e-01 8.06e+00
5 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 37500 4.85e-01 1.23e+01
6 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 45000 8.23e-01 2.03e+01
7 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 52500 1.32e+00 3.00e+01
8 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 60000 1.79e+00 4.08e+01
9 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 67500 2.11e+00 5.38e+01
10 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 75000 2.07e+00 5.25e+01
11 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 82500 2.86e+00 6.38e+01
12 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 90000 2.83e+00 6.54e+01
13 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 97500 3.29e+00 6.81e+01
14 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 105000 2.72e+00 7.06e+01
15 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 112500 3.58e+00 7.74e+01
16 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 120000 3.53e+00 7.70e+01
17 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 127500 3.40e+00 8.05e+01
18 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 135000 3.47e+00 8.30e+01
19 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 142500 3.65e+00 8.15e+01
20 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 4 150000 3.90e+00 8.46e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 7500 1.02e-01 4.12e+00
2 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 15000 1.37e-01 4.47e+00
3 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 22500 1.75e-01 5.27e+00
4 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 30000 2.26e-01 7.04e+00
5 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 37500 3.89e-01 1.07e+01
6 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 45000 6.49e-01 1.62e+01
7 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 52500 1.07e+00 2.55e+01
8 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 60000 1.40e+00 3.39e+01
9 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 67500 1.96e+00 4.63e+01
10 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 75000 2.12e+00 5.12e+01
11 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 82500 2.57e+00 6.29e+01
12 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 90000 2.50e+00 6.37e+01
13 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 97500 3.02e+00 6.64e+01
14 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 105000 2.81e+00 6.85e+01
15 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 112500 2.95e+00 7.30e+01
16 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 120000 3.34e+00 8.11e+01
17 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 127500 3.11e+00 7.42e+01
18 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 135000 3.32e+00 7.81e+01
19 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 142500 3.80e+00 8.30e+01
20 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 5 150000 3.63e+00 8.41e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 7500 1.10e-01 4.20e+00
2 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 15000 1.18e-01 4.62e+00
3 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 22500 1.71e-01 5.47e+00
4 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 30000 2.58e-01 7.24e+00
5 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 37500 3.62e-01 9.97e+00
6 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 45000 6.78e-01 1.60e+01
7 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 52500 1.20e+00 2.46e+01
8 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 60000 1.64e+00 3.43e+01
9 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 67500 2.29e+00 4.70e+01
10 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 75000 2.54e+00 5.98e+01
11 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 82500 3.08e+00 6.58e+01
12 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 90000 2.92e+00 6.40e+01
13 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 97500 2.84e+00 6.73e+01
14 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 105000 3.12e+00 6.79e+01
15 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 112500 3.47e+00 7.58e+01
16 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 120000 3.19e+00 7.74e+01
17 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 127500 3.58e+00 7.95e+01
18 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 135000 3.58e+00 8.31e+01
19 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 142500 3.39e+00 7.69e+01
20 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 6 150000 3.96e+00 8.40e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 7500 1.16e-01 4.28e+00
2 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 15000 1.30e-01 4.52e+00
3 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 22500 1.71e-01 5.28e+00
4 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 30000 2.34e-01 7.01e+00
5 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 37500 4.01e-01 1.02e+01
6 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 45000 6.30e-01 1.63e+01
7 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 52500 1.28e+00 2.71e+01
8 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 60000 1.66e+00 3.86e+01
9 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 67500 2.01e+00 4.83e+01
10 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 75000 2.43e+00 5.61e+01
11 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 82500 2.76e+00 6.35e+01
12 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 90000 3.20e+00 6.63e+01
13 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 97500 2.66e+00 6.69e+01
14 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 105000 3.12e+00 7.39e+01
15 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 112500 3.13e+00 6.67e+01
16 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 120000 3.45e+00 7.65e+01
17 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 127500 3.33e+00 7.45e+01
18 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 135000 3.76e+00 8.32e+01
19 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 142500 3.92e+00 8.40e+01
20 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 7 150000 4.28e+00 8.76e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 7500 1.07e-01 4.10e+00
2 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 15000 1.41e-01 4.68e+00
3 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 22500 1.73e-01 5.78e+00
4 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 30000 2.48e-01 7.29e+00
5 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 37500 4.86e-01 1.26e+01
6 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 45000 7.07e-01 1.69e+01
7 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 52500 1.06e+00 2.70e+01
8 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 60000 1.33e+00 3.30e+01
9 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 67500 1.92e+00 4.90e+01
10 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 75000 2.04e+00 5.20e+01
11 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 82500 2.27e+00 6.14e+01
12 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 90000 2.72e+00 6.62e+01
13 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 97500 2.69e+00 6.64e+01
14 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 105000 2.89e+00 7.16e+01
15 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 112500 3.04e+00 7.62e+01
16 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 120000 3.32e+00 7.52e+01
17 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 127500 3.50e+00 7.87e+01
18 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 135000 3.46e+00 7.68e+01
19 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 142500 3.85e+00 7.76e+01
20 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 8 150000 3.97e+00 8.26e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 7500 1.05e-01 4.13e+00
2 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 15000 1.14e-01 4.50e+00
3 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 22500 1.83e-01 5.84e+00
4 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 30000 2.49e-01 7.53e+00
5 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 37500 4.35e-01 1.12e+01
6 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 45000 7.48e-01 1.66e+01
7 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 52500 1.10e+00 2.58e+01
8 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 60000 1.56e+00 3.54e+01
9 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 67500 2.02e+00 4.92e+01
10 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 75000 2.28e+00 5.60e+01
11 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 82500 2.52e+00 6.01e+01
12 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 90000 2.71e+00 6.66e+01
13 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 97500 2.92e+00 6.86e+01
14 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 105000 2.94e+00 6.96e+01
15 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 112500 2.88e+00 6.97e+01
16 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 120000 3.33e+00 7.62e+01
17 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 127500 3.06e+00 7.44e+01
18 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 135000 3.27e+00 7.81e+01
19 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 142500 3.25e+00 8.42e+01
20 A3C 8 8 1 3 2.50e-01 False 2.50e-01 0 0 9 150000 3.22e+00 8.25e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 7500 3.74e-02 3.96e+00
2 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 15000 3.21e-02 4.23e+00
3 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 22500 3.53e-02 4.36e+00
4 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 30000 3.62e-02 4.53e+00
5 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 37500 3.68e-02 4.69e+00
6 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 45000 5.77e-02 4.90e+00
7 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 52500 4.70e-02 5.24e+00
8 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 60000 4.05e-02 5.38e+00
9 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 67500 4.99e-02 5.16e+00
10 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 75000 5.56e-02 5.50e+00
11 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 82500 5.76e-02 5.58e+00
12 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 90000 7.86e-02 6.15e+00
13 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 97500 8.02e-02 6.39e+00
14 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 105000 6.89e-02 6.64e+00
15 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 112500 9.15e-02 6.83e+00
16 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 120000 9.49e-02 7.02e+00
17 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 127500 9.49e-02 7.53e+00
18 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 135000 1.14e-01 7.87e+00
19 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 142500 1.13e-01 8.52e+00
20 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 0 150000 9.64e-02 8.00e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 7500 3.96e-02 4.12e+00
2 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 15000 3.30e-02 4.21e+00
3 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 22500 4.13e-02 4.55e+00
4 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 30000 4.39e-02 4.71e+00
5 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 37500 5.26e-02 4.85e+00
6 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 45000 4.93e-02 5.18e+00
7 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 52500 5.24e-02 5.21e+00
8 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 60000 5.15e-02 5.29e+00
9 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 67500 6.64e-02 5.61e+00
10 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 75000 6.70e-02 6.14e+00
11 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 82500 7.42e-02 6.10e+00
12 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 90000 7.22e-02 6.53e+00
13 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 97500 8.26e-02 6.89e+00
14 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 105000 1.04e-01 7.45e+00
15 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 112500 8.71e-02 7.61e+00
16 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 120000 9.42e-02 7.32e+00
17 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 127500 9.63e-02 8.14e+00
18 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 135000 1.03e-01 8.08e+00
19 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 142500 1.11e-01 8.47e+00
20 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 1 150000 8.63e-02 8.39e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 7500 2.92e-02 3.98e+00
2 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 15000 3.73e-02 4.34e+00
3 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 22500 4.03e-02 4.46e+00
4 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 30000 4.89e-02 4.52e+00
5 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 37500 4.81e-02 4.99e+00
6 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 45000 4.60e-02 5.16e+00
7 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 52500 4.86e-02 5.18e+00
8 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 60000 5.39e-02 5.31e+00
9 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 67500 5.41e-02 5.52e+00
10 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 75000 6.75e-02 5.80e+00
11 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 82500 6.71e-02 5.95e+00
12 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 90000 5.97e-02 5.87e+00
13 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 97500 5.27e-02 6.21e+00
14 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 105000 7.53e-02 6.10e+00
15 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 112500 7.47e-02 6.38e+00
16 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 120000 7.07e-02 6.45e+00
17 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 127500 7.01e-02 6.77e+00
18 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 135000 6.77e-02 6.55e+00
19 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 142500 8.14e-02 6.62e+00
20 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 2 150000 7.86e-02 6.62e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 7500 3.65e-02 4.04e+00
2 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 15000 4.42e-02 4.45e+00
3 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 22500 4.08e-02 4.42e+00
4 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 30000 4.32e-02 4.72e+00
5 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 37500 4.77e-02 4.97e+00
6 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 45000 5.75e-02 5.46e+00
7 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 52500 4.74e-02 5.31e+00
8 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 60000 6.35e-02 5.47e+00
9 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 67500 5.89e-02 5.59e+00
10 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 75000 7.78e-02 5.95e+00
11 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 82500 6.97e-02 6.32e+00
12 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 90000 5.72e-02 6.11e+00
13 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 97500 6.74e-02 6.24e+00
14 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 105000 6.86e-02 6.41e+00
15 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 112500 6.01e-02 6.19e+00
16 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 120000 7.65e-02 6.44e+00
17 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 127500 6.38e-02 6.69e+00
18 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 135000 6.34e-02 6.39e+00
19 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 142500 7.59e-02 6.47e+00
20 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 3 150000 8.10e-02 6.75e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 7500 2.97e-02 3.97e+00
2 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 15000 3.71e-02 4.33e+00
3 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 22500 3.28e-02 4.38e+00
4 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 30000 3.19e-02 4.47e+00
5 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 37500 5.37e-02 4.78e+00
6 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 45000 4.60e-02 5.22e+00
7 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 52500 5.42e-02 5.32e+00
8 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 60000 6.10e-02 5.62e+00
9 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 67500 5.81e-02 5.74e+00
10 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 75000 6.37e-02 5.94e+00
11 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 82500 7.08e-02 6.00e+00
12 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 90000 6.97e-02 6.32e+00
13 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 97500 5.84e-02 6.41e+00
14 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 105000 8.86e-02 6.53e+00
15 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 112500 7.51e-02 6.56e+00
16 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 120000 9.24e-02 7.08e+00
17 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 127500 9.06e-02 7.79e+00
18 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 135000 8.50e-02 7.27e+00
19 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 142500 7.84e-02 7.42e+00
20 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 4 150000 5.88e-02 6.73e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 7500 3.31e-02 4.02e+00
2 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 15000 3.94e-02 4.09e+00
3 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 22500 4.37e-02 4.41e+00
4 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 30000 3.15e-02 4.52e+00
5 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 37500 3.80e-02 4.70e+00
6 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 45000 4.52e-02 4.82e+00
7 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 52500 4.85e-02 5.04e+00
8 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 60000 4.58e-02 5.40e+00
9 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 67500 5.09e-02 5.38e+00
10 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 75000 6.84e-02 5.76e+00
11 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 82500 6.89e-02 6.02e+00
12 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 90000 7.07e-02 6.06e+00
13 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 97500 7.37e-02 6.17e+00
14 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 105000 5.81e-02 5.96e+00
15 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 112500 5.89e-02 6.66e+00
16 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 120000 7.64e-02 6.36e+00
17 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 127500 8.54e-02 6.83e+00
18 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 135000 8.66e-02 6.89e+00
19 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 142500 8.92e-02 6.98e+00
20 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 5 150000 5.32e-02 6.76e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 7500 3.08e-02 3.94e+00
2 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 15000 3.23e-02 4.14e+00
3 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 22500 3.79e-02 4.31e+00
4 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 30000 4.37e-02 4.49e+00
5 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 37500 4.14e-02 5.11e+00
6 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 45000 5.66e-02 5.26e+00
7 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 52500 5.67e-02 5.40e+00
8 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 60000 5.00e-02 5.47e+00
9 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 67500 5.72e-02 5.65e+00
10 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 75000 5.89e-02 5.82e+00
11 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 82500 5.66e-02 5.88e+00
12 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 90000 6.79e-02 5.95e+00
13 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 97500 6.66e-02 6.00e+00
14 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 105000 7.07e-02 6.39e+00
15 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 112500 8.16e-02 6.54e+00
16 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 120000 8.73e-02 6.63e+00
17 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 127500 8.65e-02 6.96e+00
18 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 135000 7.50e-02 6.69e+00
19 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 142500 8.54e-02 7.22e+00
20 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 6 150000 8.61e-02 7.05e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 7500 2.80e-02 4.02e+00
2 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 15000 2.84e-02 4.16e+00
3 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 22500 3.53e-02 4.18e+00
4 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 30000 4.22e-02 4.46e+00
5 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 37500 4.45e-02 4.62e+00
6 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 45000 3.77e-02 4.80e+00
7 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 52500 4.50e-02 5.01e+00
8 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 60000 4.64e-02 5.10e+00
9 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 67500 4.09e-02 5.14e+00
10 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 75000 4.44e-02 4.98e+00
11 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 82500 6.08e-02 5.36e+00
12 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 90000 6.51e-02 5.85e+00
13 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 97500 7.71e-02 5.98e+00
14 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 105000 7.01e-02 6.58e+00
15 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 112500 8.24e-02 6.67e+00
16 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 120000 7.51e-02 6.84e+00
17 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 127500 6.66e-02 6.26e+00
18 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 135000 7.42e-02 6.37e+00
19 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 142500 7.43e-02 6.89e+00
20 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 7 150000 8.77e-02 6.85e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 7500 3.18e-02 3.96e+00
2 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 15000 3.41e-02 4.04e+00
3 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 22500 3.88e-02 4.39e+00
4 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 30000 4.54e-02 4.72e+00
5 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 37500 5.48e-02 5.05e+00
6 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 45000 5.74e-02 5.17e+00
7 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 52500 5.79e-02 5.85e+00
8 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 60000 5.57e-02 6.20e+00
9 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 67500 7.80e-02 6.25e+00
10 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 75000 6.93e-02 6.33e+00
11 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 82500 5.98e-02 6.21e+00
12 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 90000 5.76e-02 6.01e+00
13 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 97500 6.26e-02 6.34e+00
14 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 105000 7.39e-02 6.40e+00
15 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 112500 7.18e-02 6.49e+00
16 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 120000 7.31e-02 6.76e+00
17 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 127500 7.87e-02 6.88e+00
18 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 135000 5.93e-02 6.59e+00
19 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 142500 7.97e-02 6.74e+00
20 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 8 150000 7.30e-02 6.94e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 7500 3.71e-02 4.01e+00
2 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 15000 3.24e-02 4.09e+00
3 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 22500 4.84e-02 4.49e+00
4 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 30000 3.86e-02 4.74e+00
5 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 37500 3.77e-02 4.77e+00
6 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 45000 4.88e-02 5.00e+00
7 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 52500 4.82e-02 5.31e+00
8 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 60000 4.92e-02 5.34e+00
9 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 67500 5.07e-02 5.55e+00
10 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 75000 5.02e-02 5.51e+00
11 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 82500 5.38e-02 5.76e+00
12 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 90000 5.32e-02 5.63e+00
13 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 97500 5.89e-02 5.83e+00
14 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 105000 5.54e-02 5.59e+00
15 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 112500 6.58e-02 5.82e+00
16 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 120000 5.98e-02 6.02e+00
17 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 127500 6.27e-02 6.05e+00
18 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 135000 5.36e-02 6.05e+00
19 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 142500 6.86e-02 6.04e+00
20 A3C 8 8 1 4 2.50e-01 False 2.50e-01 0 0 9 150000 5.89e-02 6.27e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 7500 3.98e-01 4.12e+00
2 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 15000 6.07e-01 5.50e+00
3 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 22500 1.44e+00 1.05e+01
4 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 30000 4.43e+00 2.31e+01
5 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 37500 1.61e+01 4.37e+01
6 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 45000 6.02e+01 7.63e+01
7 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 52500 8.03e+01 8.98e+01
8 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 60000 8.73e+01 9.36e+01
9 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 67500 8.93e+01 9.56e+01
10 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 75000 8.92e+01 9.44e+01
11 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 82500 8.88e+01 9.41e+01
12 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 90000 8.36e+01 8.89e+01
13 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 97500 8.88e+01 9.38e+01
14 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 105000 8.45e+01 9.10e+01
15 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 112500 7.82e+01 8.89e+01
16 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 120000 7.23e+01 9.27e+01
17 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 127500 6.92e+01 9.50e+01
18 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 135000 7.13e+01 9.70e+01
19 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 142500 7.33e+01 9.57e+01
20 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 0 150000 7.63e+01 9.66e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 7500 3.79e-01 4.09e+00
2 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 15000 5.65e-01 5.08e+00
3 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 22500 1.15e+00 8.44e+00
4 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 30000 3.42e+00 1.74e+01
5 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 37500 1.96e+01 4.48e+01
6 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 45000 6.91e+01 8.26e+01
7 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 52500 8.08e+01 8.78e+01
8 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 60000 8.62e+01 9.34e+01
9 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 67500 8.94e+01 9.57e+01
10 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 75000 9.04e+01 9.65e+01
11 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 82500 8.76e+01 9.38e+01
12 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 90000 8.48e+01 9.00e+01
13 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 97500 8.76e+01 9.27e+01
14 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 105000 8.80e+01 9.42e+01
15 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 112500 8.11e+01 9.20e+01
16 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 120000 7.37e+01 8.90e+01
17 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 127500 7.61e+01 9.63e+01
18 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 135000 7.62e+01 9.55e+01
19 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 142500 7.77e+01 9.56e+01
20 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 1 150000 7.93e+01 9.59e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 7500 4.03e-01 4.21e+00
2 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 15000 6.12e-01 5.75e+00
3 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 22500 1.34e+00 9.88e+00
4 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 30000 5.81e+00 2.41e+01
5 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 37500 4.16e+01 6.14e+01
6 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 45000 7.53e+01 8.62e+01
7 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 52500 7.86e+01 8.76e+01
8 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 60000 8.40e+01 9.14e+01
9 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 67500 8.79e+01 9.41e+01
10 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 75000 8.85e+01 9.56e+01
11 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 82500 8.86e+01 9.49e+01
12 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 90000 8.44e+01 9.01e+01
13 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 97500 8.77e+01 9.38e+01
14 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 105000 8.57e+01 9.43e+01
15 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 112500 8.22e+01 9.75e+01
16 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 120000 7.29e+01 9.31e+01
17 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 127500 7.12e+01 9.34e+01
18 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 135000 7.12e+01 9.59e+01
19 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 142500 7.33e+01 9.60e+01
20 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 2 150000 7.51e+01 9.39e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 7500 4.03e-01 4.21e+00
2 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 15000 5.45e-01 5.31e+00
3 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 22500 1.10e+00 9.02e+00
4 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 30000 2.86e+00 1.97e+01
5 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 37500 6.05e+00 3.47e+01
6 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 45000 2.42e+01 5.95e+01
7 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 52500 6.32e+01 7.62e+01
8 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 60000 8.18e+01 9.13e+01
9 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 67500 8.72e+01 9.54e+01
10 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 75000 8.72e+01 9.31e+01
11 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 82500 8.82e+01 9.39e+01
12 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 90000 8.74e+01 9.32e+01
13 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 97500 8.93e+01 9.60e+01
14 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 105000 8.87e+01 9.80e+01
15 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 112500 7.86e+01 9.39e+01
16 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 120000 7.15e+01 9.12e+01
17 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 127500 6.77e+01 9.28e+01
18 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 135000 6.76e+01 9.28e+01
19 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 142500 7.61e+01 9.76e+01
20 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 3 150000 7.98e+01 9.74e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 7500 3.71e-01 4.12e+00
2 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 15000 6.00e-01 5.46e+00
3 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 22500 1.28e+00 9.98e+00
4 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 30000 2.83e+00 1.90e+01
5 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 37500 6.48e+00 3.91e+01
6 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 45000 1.37e+01 5.78e+01
7 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 52500 4.60e+01 7.33e+01
8 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 60000 7.69e+01 9.02e+01
9 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 67500 8.53e+01 9.38e+01
10 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 75000 8.70e+01 9.43e+01
11 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 82500 9.01e+01 9.65e+01
12 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 90000 8.78e+01 9.32e+01
13 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 97500 8.84e+01 9.38e+01
14 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 105000 8.64e+01 9.29e+01
15 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 112500 8.19e+01 9.53e+01
16 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 120000 7.29e+01 9.10e+01
17 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 127500 7.11e+01 9.20e+01
18 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 135000 7.10e+01 9.12e+01
19 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 142500 7.59e+01 9.55e+01
20 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 4 150000 7.82e+01 9.74e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 7500 4.01e-01 4.10e+00
2 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 15000 6.01e-01 5.50e+00
3 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 22500 1.41e+00 9.88e+00
4 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 30000 3.53e+00 2.01e+01
5 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 37500 1.62e+01 5.18e+01
6 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 45000 5.28e+01 7.30e+01
7 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 52500 7.74e+01 9.02e+01
8 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 60000 8.15e+01 9.35e+01
9 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 67500 8.51e+01 9.43e+01
10 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 75000 7.99e+01 8.89e+01
11 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 82500 8.13e+01 8.91e+01
12 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 90000 8.51e+01 9.28e+01
13 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 97500 8.27e+01 9.36e+01
14 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 105000 7.10e+01 8.48e+01
15 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 112500 6.75e+01 8.62e+01
16 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 120000 7.07e+01 9.04e+01
17 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 127500 7.52e+01 9.39e+01
18 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 135000 7.44e+01 9.36e+01
19 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 142500 6.95e+01 9.11e+01
20 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 5 150000 7.24e+01 9.51e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 7500 3.97e-01 4.18e+00
2 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 15000 6.21e-01 5.54e+00
3 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 22500 1.49e+00 1.03e+01
4 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 30000 3.90e+00 2.18e+01
5 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 37500 1.26e+01 4.49e+01
6 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 45000 4.61e+01 6.77e+01
7 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 52500 7.72e+01 8.83e+01
8 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 60000 8.49e+01 9.19e+01
9 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 67500 8.61e+01 9.47e+01
10 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 75000 8.54e+01 9.24e+01
11 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 82500 8.72e+01 9.35e+01
12 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 90000 8.85e+01 9.53e+01
13 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 97500 8.67e+01 9.46e+01
14 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 105000 8.15e+01 9.29e+01
15 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 112500 6.88e+01 9.22e+01
16 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 120000 6.70e+01 9.47e+01
17 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 127500 7.01e+01 9.61e+01
18 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 135000 7.44e+01 9.57e+01
19 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 142500 7.85e+01 9.83e+01
20 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 6 150000 7.79e+01 9.60e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 7500 3.92e-01 4.04e+00
2 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 15000 6.65e-01 5.83e+00
3 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 22500 1.72e+00 1.12e+01
4 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 30000 4.74e+00 2.30e+01
5 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 37500 2.21e+01 5.17e+01
6 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 45000 5.99e+01 7.73e+01
7 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 52500 7.66e+01 8.90e+01
8 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 60000 8.19e+01 9.10e+01
9 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 67500 8.56e+01 9.52e+01
10 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 75000 8.82e+01 9.60e+01
11 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 82500 8.82e+01 9.48e+01
12 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 90000 8.68e+01 9.34e+01
13 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 97500 8.63e+01 9.37e+01
14 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 105000 8.28e+01 9.23e+01
15 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 112500 7.79e+01 9.53e+01
16 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 120000 7.02e+01 9.10e+01
17 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 127500 7.33e+01 9.38e+01
18 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 135000 7.40e+01 9.49e+01
19 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 142500 7.99e+01 9.75e+01
20 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 7 150000 7.86e+01 9.68e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 7500 4.08e-01 4.27e+00
2 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 15000 6.89e-01 6.09e+00
3 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 22500 1.62e+00 1.10e+01
4 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 30000 6.29e+00 2.76e+01
5 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 37500 2.35e+01 4.81e+01
6 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 45000 6.59e+01 7.95e+01
7 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 52500 7.69e+01 8.52e+01
8 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 60000 7.58e+01 8.40e+01
9 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 67500 8.21e+01 8.80e+01
10 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 75000 8.80e+01 9.27e+01
11 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 82500 8.87e+01 9.39e+01
12 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 90000 9.08e+01 9.64e+01
13 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 97500 8.71e+01 9.36e+01
14 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 105000 8.36e+01 9.21e+01
15 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 112500 7.82e+01 9.05e+01
16 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 120000 7.53e+01 9.26e+01
17 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 127500 7.02e+01 9.37e+01
18 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 135000 6.91e+01 9.39e+01
19 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 142500 6.77e+01 8.92e+01
20 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 8 150000 7.28e+01 9.59e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 7500 4.40e-01 4.20e+00
2 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 15000 6.09e-01 5.29e+00
3 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 22500 1.21e+00 8.82e+00
4 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 30000 3.14e+00 1.79e+01
5 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 37500 1.03e+01 3.85e+01
6 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 45000 3.31e+01 6.19e+01
7 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 52500 7.08e+01 8.35e+01
8 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 60000 8.36e+01 9.27e+01
9 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 67500 8.68e+01 9.39e+01
10 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 75000 8.95e+01 9.48e+01
11 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 82500 9.10e+01 9.63e+01
12 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 90000 8.68e+01 9.18e+01
13 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 97500 8.88e+01 9.43e+01
14 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 105000 8.73e+01 9.47e+01
15 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 112500 8.18e+01 9.50e+01
16 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 120000 7.25e+01 9.38e+01
17 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 127500 6.75e+01 9.08e+01
18 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 135000 7.46e+01 9.60e+01
19 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 142500 8.01e+01 9.70e+01
20 A3C 8 8 2 1 2.50e-01 False 2.50e-01 0 0 9 150000 8.42e+01 9.80e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 7500 1.93e-01 4.05e+00
2 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 15000 2.62e-01 5.02e+00
3 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 22500 4.61e-01 6.99e+00
4 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 30000 1.30e+00 1.46e+01
5 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 37500 2.59e+00 2.61e+01
6 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 45000 4.44e+00 4.19e+01
7 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 52500 6.17e+00 5.51e+01
8 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 60000 6.74e+00 6.20e+01
9 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 67500 8.22e+00 7.13e+01
10 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 75000 7.39e+00 6.57e+01
11 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 82500 8.22e+00 7.05e+01
12 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 90000 9.24e+00 7.77e+01
13 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 97500 9.48e+00 7.81e+01
14 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 105000 8.83e+00 7.62e+01
15 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 112500 8.58e+00 7.63e+01
16 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 120000 9.24e+00 8.15e+01
17 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 127500 9.01e+00 8.12e+01
18 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 135000 1.07e+01 8.75e+01
19 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 142500 1.03e+01 8.76e+01
20 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 0 150000 9.72e+00 8.49e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 7500 1.87e-01 3.98e+00
2 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 15000 2.68e-01 5.12e+00
3 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 22500 4.86e-01 7.44e+00
4 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 30000 1.29e+00 1.46e+01
5 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 37500 2.59e+00 2.59e+01
6 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 45000 5.00e+00 4.72e+01
7 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 52500 5.47e+00 5.02e+01
8 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 60000 6.22e+00 6.01e+01
9 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 67500 7.07e+00 6.21e+01
10 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 75000 7.86e+00 6.62e+01
11 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 82500 8.60e+00 7.19e+01
12 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 90000 8.38e+00 7.19e+01
13 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 97500 9.49e+00 7.99e+01
14 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 105000 9.53e+00 7.94e+01
15 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 112500 9.70e+00 8.34e+01
16 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 120000 1.01e+01 7.68e+01
17 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 127500 1.09e+01 8.10e+01
18 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 135000 9.86e+00 8.10e+01
19 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 142500 1.01e+01 8.19e+01
20 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 1 150000 1.04e+01 8.57e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 7500 1.89e-01 4.04e+00
2 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 15000 3.21e-01 5.10e+00
3 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 22500 5.29e-01 7.89e+00
4 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 30000 1.27e+00 1.44e+01
5 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 37500 2.62e+00 2.77e+01
6 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 45000 3.99e+00 4.15e+01
7 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 52500 5.78e+00 5.61e+01
8 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 60000 7.03e+00 6.23e+01
9 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 67500 8.39e+00 7.30e+01
10 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 75000 7.37e+00 6.73e+01
11 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 82500 8.46e+00 7.47e+01
12 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 90000 8.45e+00 7.39e+01
13 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 97500 8.03e+00 7.30e+01
14 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 105000 8.58e+00 8.04e+01
15 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 112500 9.38e+00 8.22e+01
16 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 120000 8.75e+00 7.78e+01
17 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 127500 9.08e+00 7.66e+01
18 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 135000 9.22e+00 8.11e+01
19 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 142500 9.24e+00 8.40e+01
20 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 2 150000 9.69e+00 8.77e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 7500 2.00e-01 4.15e+00
2 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 15000 3.13e-01 5.38e+00
3 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 22500 6.75e-01 8.44e+00
4 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 30000 1.50e+00 1.61e+01
5 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 37500 3.35e+00 3.09e+01
6 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 45000 5.32e+00 4.51e+01
7 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 52500 6.31e+00 5.26e+01
8 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 60000 7.83e+00 6.04e+01
9 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 67500 8.13e+00 6.76e+01
10 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 75000 7.88e+00 6.98e+01
11 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 82500 8.09e+00 7.09e+01
12 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 90000 8.41e+00 6.99e+01
13 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 97500 9.04e+00 7.77e+01
14 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 105000 9.03e+00 7.87e+01
15 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 112500 8.54e+00 7.72e+01
16 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 120000 9.49e+00 8.01e+01
17 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 127500 9.92e+00 8.23e+01
18 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 135000 9.63e+00 8.05e+01
19 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 142500 9.64e+00 8.09e+01
20 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 3 150000 9.43e+00 8.19e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 7500 1.68e-01 3.95e+00
2 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 15000 2.38e-01 4.54e+00
3 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 22500 4.25e-01 6.73e+00
4 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 30000 7.61e-01 1.10e+01
5 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 37500 1.76e+00 2.17e+01
6 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 45000 2.81e+00 3.32e+01
7 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 52500 5.01e+00 5.35e+01
8 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 60000 5.30e+00 5.56e+01
9 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 67500 7.20e+00 6.73e+01
10 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 75000 7.66e+00 6.52e+01
11 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 82500 8.34e+00 6.92e+01
12 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 90000 7.79e+00 7.05e+01
13 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 97500 8.20e+00 7.54e+01
14 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 105000 7.61e+00 7.42e+01
15 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 112500 8.89e+00 8.11e+01
16 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 120000 9.42e+00 8.15e+01
17 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 127500 1.03e+01 8.40e+01
18 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 135000 1.01e+01 8.51e+01
19 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 142500 9.26e+00 7.82e+01
20 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 4 150000 9.57e+00 8.45e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 7500 1.84e-01 4.08e+00
2 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 15000 2.81e-01 4.86e+00
3 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 22500 5.17e-01 7.26e+00
4 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 30000 1.18e+00 1.32e+01
5 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 37500 2.51e+00 2.62e+01
6 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 45000 3.89e+00 3.96e+01
7 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 52500 6.14e+00 5.48e+01
8 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 60000 6.67e+00 5.95e+01
9 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 67500 8.23e+00 7.28e+01
10 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 75000 7.68e+00 6.59e+01
11 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 82500 8.79e+00 7.43e+01
12 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 90000 8.53e+00 7.18e+01
13 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 97500 8.89e+00 7.46e+01
14 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 105000 9.20e+00 7.96e+01
15 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 112500 9.22e+00 7.44e+01
16 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 120000 9.84e+00 8.37e+01
17 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 127500 9.85e+00 8.41e+01
18 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 135000 9.72e+00 7.80e+01
19 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 142500 9.09e+00 8.19e+01
20 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 5 150000 9.80e+00 8.47e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 7500 2.15e-01 4.13e+00
2 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 15000 2.64e-01 5.04e+00
3 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 22500 5.03e-01 7.56e+00
4 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 30000 1.40e+00 1.52e+01
5 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 37500 2.74e+00 2.84e+01
6 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 45000 4.19e+00 4.29e+01
7 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 52500 5.80e+00 5.41e+01
8 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 60000 7.61e+00 6.70e+01
9 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 67500 7.30e+00 6.34e+01
10 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 75000 8.21e+00 7.09e+01
11 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 82500 8.80e+00 7.24e+01
12 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 90000 9.33e+00 7.61e+01
13 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 97500 8.18e+00 7.00e+01
14 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 105000 9.36e+00 7.46e+01
15 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 112500 9.48e+00 7.96e+01
16 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 120000 9.61e+00 8.21e+01
17 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 127500 1.01e+01 8.03e+01
18 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 135000 9.96e+00 7.94e+01
19 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 142500 9.91e+00 8.18e+01
20 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 6 150000 9.69e+00 8.21e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 7500 2.16e-01 4.12e+00
2 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 15000 2.55e-01 4.77e+00
3 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 22500 5.14e-01 7.15e+00
4 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 30000 9.68e-01 1.26e+01
5 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 37500 2.50e+00 2.79e+01
6 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 45000 3.33e+00 3.61e+01
7 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 52500 5.06e+00 5.17e+01
8 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 60000 6.19e+00 6.17e+01
9 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 67500 6.99e+00 6.80e+01
10 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 75000 7.21e+00 6.93e+01
11 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 82500 7.79e+00 7.40e+01
12 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 90000 8.14e+00 7.44e+01
13 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 97500 7.61e+00 7.06e+01
14 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 105000 8.55e+00 8.15e+01
15 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 112500 7.64e+00 7.02e+01
16 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 120000 8.82e+00 7.64e+01
17 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 127500 9.81e+00 8.46e+01
18 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 135000 9.03e+00 8.25e+01
19 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 142500 8.87e+00 8.63e+01
20 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 7 150000 8.68e+00 8.34e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 7500 2.03e-01 4.07e+00
2 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 15000 2.30e-01 4.59e+00
3 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 22500 4.06e-01 6.41e+00
4 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 30000 8.16e-01 1.04e+01
5 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 37500 1.96e+00 2.20e+01
6 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 45000 3.48e+00 3.63e+01
7 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 52500 4.95e+00 4.87e+01
8 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 60000 6.99e+00 6.32e+01
9 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 67500 7.34e+00 6.62e+01
10 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 75000 7.66e+00 6.84e+01
11 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 82500 7.73e+00 7.23e+01
12 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 90000 8.07e+00 7.87e+01
13 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 97500 8.81e+00 8.03e+01
14 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 105000 8.48e+00 7.83e+01
15 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 112500 8.29e+00 8.22e+01
16 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 120000 8.17e+00 7.76e+01
17 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 127500 9.21e+00 8.44e+01
18 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 135000 9.13e+00 8.15e+01
19 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 142500 9.26e+00 8.23e+01
20 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 8 150000 9.69e+00 8.57e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 7500 2.03e-01 4.24e+00
2 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 15000 3.13e-01 5.21e+00
3 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 22500 5.86e-01 7.95e+00
4 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 30000 1.33e+00 1.46e+01
5 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 37500 2.89e+00 2.75e+01
6 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 45000 5.38e+00 4.63e+01
7 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 52500 7.13e+00 5.59e+01
8 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 60000 7.10e+00 5.69e+01
9 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 67500 9.04e+00 7.19e+01
10 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 75000 8.64e+00 7.05e+01
11 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 82500 9.51e+00 7.14e+01
12 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 90000 8.83e+00 7.15e+01
13 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 97500 8.83e+00 7.53e+01
14 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 105000 9.17e+00 7.45e+01
15 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 112500 1.04e+01 7.91e+01
16 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 120000 1.01e+01 8.47e+01
17 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 127500 9.63e+00 8.43e+01
18 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 135000 9.61e+00 8.24e+01
19 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 142500 9.33e+00 7.46e+01
20 A3C 8 8 2 2 2.50e-01 False 2.50e-01 0 0 9 150000 1.04e+01 8.32e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 7500 8.48e-02 4.08e+00
2 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 15000 9.61e-02 4.44e+00
3 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 22500 1.20e-01 5.07e+00
4 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 30000 1.70e-01 6.50e+00
5 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 37500 2.64e-01 8.24e+00
6 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 45000 4.25e-01 1.18e+01
7 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 52500 7.47e-01 1.89e+01
8 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 60000 1.16e+00 2.98e+01
9 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 67500 1.33e+00 3.84e+01
10 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 75000 1.97e+00 4.93e+01
11 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 82500 2.03e+00 4.96e+01
12 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 90000 2.32e+00 6.16e+01
13 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 97500 2.40e+00 6.14e+01
14 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 105000 2.75e+00 7.02e+01
15 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 112500 2.92e+00 7.05e+01
16 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 120000 2.56e+00 7.25e+01
17 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 127500 3.10e+00 7.79e+01
18 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 135000 3.33e+00 8.22e+01
19 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 142500 3.35e+00 8.13e+01
20 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 0 150000 3.61e+00 7.89e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 7500 7.41e-02 4.01e+00
2 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 15000 9.62e-02 4.51e+00
3 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 22500 1.29e-01 5.22e+00
4 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 30000 1.77e-01 6.21e+00
5 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 37500 2.54e-01 8.58e+00
6 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 45000 4.88e-01 1.27e+01
7 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 52500 7.90e-01 2.06e+01
8 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 60000 1.32e+00 3.12e+01
9 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 67500 1.62e+00 3.95e+01
10 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 75000 2.48e+00 5.82e+01
11 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 82500 2.39e+00 5.61e+01
12 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 90000 2.72e+00 6.79e+01
13 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 97500 2.71e+00 6.57e+01
14 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 105000 2.79e+00 7.33e+01
15 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 112500 3.04e+00 7.63e+01
16 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 120000 3.05e+00 7.42e+01
17 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 127500 3.23e+00 7.80e+01
18 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 135000 3.20e+00 7.61e+01
19 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 142500 3.64e+00 8.25e+01
20 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 1 150000 3.77e+00 8.19e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 7500 7.15e-02 3.96e+00
2 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 15000 8.61e-02 4.27e+00
3 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 22500 1.10e-01 4.89e+00
4 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 30000 1.75e-01 6.08e+00
5 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 37500 2.70e-01 8.59e+00
6 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 45000 4.12e-01 1.22e+01
7 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 52500 7.09e-01 1.89e+01
8 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 60000 1.05e+00 2.63e+01
9 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 67500 1.42e+00 3.72e+01
10 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 75000 1.80e+00 4.63e+01
11 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 82500 2.14e+00 5.35e+01
12 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 90000 2.28e+00 5.71e+01
13 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 97500 2.60e+00 6.60e+01
14 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 105000 2.81e+00 6.90e+01
15 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 112500 3.02e+00 7.41e+01
16 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 120000 3.38e+00 7.93e+01
17 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 127500 3.13e+00 7.76e+01
18 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 135000 3.11e+00 7.65e+01
19 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 142500 2.99e+00 7.51e+01
20 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 2 150000 3.04e+00 7.58e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 7500 6.79e-02 4.02e+00
2 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 15000 8.46e-02 4.15e+00
3 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 22500 1.12e-01 5.02e+00
4 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 30000 1.46e-01 5.76e+00
5 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 37500 2.32e-01 7.68e+00
6 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 45000 3.32e-01 1.15e+01
7 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 52500 5.51e-01 1.46e+01
8 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 60000 9.27e-01 2.40e+01
9 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 67500 1.29e+00 3.28e+01
10 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 75000 1.70e+00 4.10e+01
11 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 82500 2.25e+00 5.38e+01
12 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 90000 2.43e+00 5.84e+01
13 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 97500 2.84e+00 6.46e+01
14 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 105000 2.95e+00 6.76e+01
15 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 112500 2.95e+00 7.45e+01
16 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 120000 3.02e+00 7.58e+01
17 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 127500 3.21e+00 7.33e+01
18 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 135000 3.42e+00 7.74e+01
19 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 142500 3.36e+00 7.44e+01
20 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 3 150000 3.35e+00 8.22e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 7500 6.20e-02 3.97e+00
2 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 15000 9.76e-02 4.44e+00
3 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 22500 1.24e-01 4.94e+00
4 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 30000 1.99e-01 6.67e+00
5 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 37500 3.06e-01 9.02e+00
6 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 45000 5.30e-01 1.42e+01
7 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 52500 8.18e-01 2.14e+01
8 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 60000 1.36e+00 3.13e+01
9 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 67500 1.88e+00 4.75e+01
10 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 75000 1.87e+00 4.95e+01
11 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 82500 2.66e+00 5.99e+01
12 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 90000 2.14e+00 6.00e+01
13 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 97500 2.77e+00 6.88e+01
14 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 105000 2.52e+00 6.57e+01
15 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 112500 3.23e+00 7.49e+01
16 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 120000 3.24e+00 7.49e+01
17 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 127500 3.44e+00 8.19e+01
18 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 135000 3.25e+00 7.54e+01
19 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 142500 3.38e+00 7.93e+01
20 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 4 150000 3.64e+00 8.64e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 7500 7.58e-02 4.10e+00
2 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 15000 1.01e-01 4.49e+00
3 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 22500 1.05e-01 4.95e+00
4 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 30000 1.72e-01 6.15e+00
5 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 37500 2.04e-01 7.44e+00
6 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 45000 3.47e-01 1.06e+01
7 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 52500 5.40e-01 1.58e+01
8 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 60000 8.40e-01 2.32e+01
9 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 67500 1.23e+00 3.10e+01
10 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 75000 1.49e+00 3.76e+01
11 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 82500 1.83e+00 5.08e+01
12 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 90000 2.30e+00 5.41e+01
13 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 97500 2.45e+00 6.66e+01
14 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 105000 2.58e+00 6.36e+01
15 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 112500 2.80e+00 6.94e+01
16 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 120000 2.99e+00 7.31e+01
17 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 127500 3.21e+00 8.09e+01
18 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 135000 3.24e+00 7.77e+01
19 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 142500 3.22e+00 7.57e+01
20 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 5 150000 3.66e+00 8.29e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 7500 6.20e-02 3.90e+00
2 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 15000 8.65e-02 4.41e+00
3 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 22500 1.06e-01 4.97e+00
4 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 30000 1.60e-01 5.91e+00
5 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 37500 2.27e-01 7.53e+00
6 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 45000 3.85e-01 1.09e+01
7 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 52500 6.45e-01 1.65e+01
8 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 60000 1.08e+00 2.47e+01
9 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 67500 1.46e+00 3.53e+01
10 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 75000 2.13e+00 5.10e+01
11 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 82500 2.39e+00 5.39e+01
12 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 90000 2.43e+00 5.85e+01
13 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 97500 2.76e+00 6.91e+01
14 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 105000 2.86e+00 6.56e+01
15 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 112500 2.94e+00 7.11e+01
16 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 120000 3.19e+00 7.71e+01
17 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 127500 3.22e+00 7.56e+01
18 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 135000 3.24e+00 7.80e+01
19 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 142500 3.29e+00 7.69e+01
20 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 6 150000 3.26e+00 7.90e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 7500 7.08e-02 4.05e+00
2 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 15000 9.85e-02 4.53e+00
3 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 22500 1.12e-01 4.80e+00
4 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 30000 1.69e-01 6.00e+00
5 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 37500 2.69e-01 7.77e+00
6 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 45000 3.90e-01 1.13e+01
7 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 52500 7.32e-01 1.85e+01
8 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 60000 9.72e-01 2.56e+01
9 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 67500 1.65e+00 3.91e+01
10 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 75000 1.68e+00 4.21e+01
11 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 82500 1.89e+00 5.09e+01
12 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 90000 2.38e+00 5.90e+01
13 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 97500 2.54e+00 6.79e+01
14 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 105000 2.65e+00 6.66e+01
15 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 112500 2.98e+00 7.23e+01
16 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 120000 2.94e+00 7.29e+01
17 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 127500 2.85e+00 7.86e+01
18 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 135000 3.08e+00 7.72e+01
19 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 142500 3.32e+00 8.38e+01
20 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 7 150000 3.55e+00 8.43e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 7500 8.18e-02 4.15e+00
2 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 15000 1.03e-01 4.53e+00
3 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 22500 1.14e-01 5.11e+00
4 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 30000 1.61e-01 5.97e+00
5 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 37500 2.44e-01 8.12e+00
6 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 45000 3.85e-01 1.08e+01
7 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 52500 6.31e-01 1.73e+01
8 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 60000 1.06e+00 2.45e+01
9 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 67500 1.73e+00 3.83e+01
10 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 75000 1.96e+00 4.78e+01
11 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 82500 2.15e+00 5.04e+01
12 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 90000 2.62e+00 6.21e+01
13 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 97500 2.81e+00 6.25e+01
14 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 105000 3.05e+00 7.27e+01
15 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 112500 3.38e+00 7.79e+01
16 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 120000 3.38e+00 7.81e+01
17 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 127500 3.40e+00 8.08e+01
18 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 135000 3.50e+00 7.67e+01
19 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 142500 3.49e+00 7.97e+01
20 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 8 150000 3.54e+00 7.87e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 7500 8.68e-02 4.07e+00
2 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 15000 8.69e-02 4.50e+00
3 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 22500 1.28e-01 5.13e+00
4 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 30000 1.65e-01 6.27e+00
5 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 37500 2.67e-01 8.26e+00
6 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 45000 4.79e-01 1.21e+01
7 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 52500 7.67e-01 1.95e+01
8 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 60000 9.90e-01 2.55e+01
9 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 67500 1.30e+00 3.71e+01
10 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 75000 1.82e+00 4.71e+01
11 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 82500 2.50e+00 5.78e+01
12 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 90000 2.51e+00 6.04e+01
13 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 97500 2.20e+00 6.23e+01
14 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 105000 2.83e+00 6.72e+01
15 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 112500 2.76e+00 7.13e+01
16 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 120000 3.44e+00 7.58e+01
17 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 127500 3.13e+00 7.78e+01
18 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 135000 3.26e+00 7.92e+01
19 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 142500 3.30e+00 8.80e+01
20 A3C 8 8 2 3 2.50e-01 False 2.50e-01 0 0 9 150000 3.86e+00 8.37e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 7500 2.02e-02 4.04e+00
2 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 15000 2.26e-02 4.14e+00
3 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 22500 2.37e-02 4.20e+00
4 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 30000 3.17e-02 4.30e+00
5 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 37500 4.26e-02 4.76e+00
6 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 45000 3.98e-02 4.81e+00
7 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 52500 3.21e-02 4.84e+00
8 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 60000 3.74e-02 5.01e+00
9 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 67500 3.63e-02 5.17e+00
10 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 75000 3.94e-02 5.08e+00
11 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 82500 4.29e-02 5.19e+00
12 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 90000 5.26e-02 5.48e+00
13 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 97500 4.77e-02 5.56e+00
14 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 105000 4.18e-02 5.49e+00
15 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 112500 4.01e-02 5.33e+00
16 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 120000 4.47e-02 5.35e+00
17 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 127500 4.98e-02 5.70e+00
18 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 135000 4.29e-02 5.35e+00
19 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 142500 5.48e-02 5.62e+00
20 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 0 150000 4.65e-02 5.49e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 7500 1.82e-02 4.10e+00
2 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 15000 2.85e-02 4.26e+00
3 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 22500 2.32e-02 4.44e+00
4 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 30000 2.22e-02 4.40e+00
5 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 37500 3.25e-02 4.61e+00
6 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 45000 3.44e-02 4.69e+00
7 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 52500 2.73e-02 4.78e+00
8 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 60000 4.19e-02 4.94e+00
9 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 67500 4.74e-02 5.24e+00
10 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 75000 4.09e-02 5.21e+00
11 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 82500 4.11e-02 5.14e+00
12 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 90000 5.45e-02 5.71e+00
13 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 97500 5.77e-02 6.05e+00
14 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 105000 5.03e-02 5.58e+00
15 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 112500 5.05e-02 5.74e+00
16 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 120000 4.32e-02 5.60e+00
17 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 127500 4.60e-02 5.51e+00
18 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 135000 5.16e-02 5.66e+00
19 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 142500 4.54e-02 5.81e+00
20 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 1 150000 4.16e-02 6.14e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 7500 2.00e-02 4.02e+00
2 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 15000 2.20e-02 4.01e+00
3 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 22500 2.66e-02 4.17e+00
4 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 30000 3.04e-02 4.29e+00
5 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 37500 2.57e-02 4.60e+00
6 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 45000 3.23e-02 4.66e+00
7 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 52500 3.54e-02 4.81e+00
8 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 60000 3.99e-02 5.04e+00
9 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 67500 3.77e-02 5.18e+00
10 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 75000 3.09e-02 5.06e+00
11 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 82500 4.64e-02 5.10e+00
12 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 90000 4.90e-02 5.27e+00
13 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 97500 4.22e-02 5.68e+00
14 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 105000 4.70e-02 5.40e+00
15 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 112500 4.06e-02 5.26e+00
16 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 120000 4.61e-02 5.46e+00
17 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 127500 3.71e-02 5.35e+00
18 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 135000 4.50e-02 5.17e+00
19 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 142500 3.92e-02 5.34e+00
20 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 2 150000 3.41e-02 5.12e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 7500 2.70e-02 4.02e+00
2 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 15000 2.48e-02 4.23e+00
3 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 22500 2.37e-02 4.33e+00
4 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 30000 3.43e-02 4.36e+00
5 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 37500 2.70e-02 4.53e+00
6 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 45000 3.41e-02 4.59e+00
7 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 52500 2.93e-02 4.88e+00
8 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 60000 3.24e-02 4.75e+00
9 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 67500 3.69e-02 5.01e+00
10 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 75000 3.66e-02 4.90e+00
11 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 82500 3.76e-02 5.10e+00
12 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 90000 3.72e-02 5.17e+00
13 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 97500 4.25e-02 5.06e+00
14 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 105000 3.67e-02 5.39e+00
15 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 112500 4.34e-02 5.27e+00
16 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 120000 4.27e-02 5.42e+00
17 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 127500 4.10e-02 5.66e+00
18 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 135000 3.65e-02 5.22e+00
19 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 142500 4.44e-02 5.12e+00
20 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 3 150000 3.77e-02 5.37e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 7500 2.26e-02 4.19e+00
2 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 15000 2.74e-02 4.20e+00
3 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 22500 3.03e-02 4.45e+00
4 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 30000 3.03e-02 4.54e+00
5 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 37500 3.28e-02 4.72e+00
6 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 45000 3.52e-02 4.63e+00
7 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 52500 3.86e-02 4.89e+00
8 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 60000 2.81e-02 4.76e+00
9 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 67500 3.30e-02 4.81e+00
10 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 75000 2.62e-02 5.09e+00
11 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 82500 4.25e-02 5.06e+00
12 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 90000 3.74e-02 4.79e+00
13 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 97500 4.19e-02 5.02e+00
14 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 105000 4.30e-02 5.18e+00
15 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 112500 3.36e-02 5.12e+00
16 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 120000 3.84e-02 5.12e+00
17 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 127500 3.92e-02 5.19e+00
18 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 135000 4.92e-02 5.44e+00
19 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 142500 3.60e-02 5.05e+00
20 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 4 150000 5.96e-02 5.71e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 7500 2.19e-02 4.08e+00
2 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 15000 2.09e-02 4.34e+00
3 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 22500 3.29e-02 4.30e+00
4 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 30000 2.82e-02 4.33e+00
5 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 37500 3.88e-02 4.62e+00
6 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 45000 3.16e-02 4.77e+00
7 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 52500 4.28e-02 4.99e+00
8 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 60000 3.90e-02 4.98e+00
9 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 67500 4.07e-02 5.05e+00
10 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 75000 5.23e-02 5.34e+00
11 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 82500 4.88e-02 5.44e+00
12 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 90000 4.57e-02 5.31e+00
13 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 97500 4.39e-02 5.53e+00
14 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 105000 6.22e-02 5.83e+00
15 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 112500 5.60e-02 5.84e+00
16 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 120000 4.81e-02 5.69e+00
17 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 127500 5.99e-02 5.79e+00
18 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 135000 7.10e-02 6.09e+00
19 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 142500 4.79e-02 6.01e+00
20 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 5 150000 5.39e-02 5.85e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 7500 2.64e-02 4.29e+00
2 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 15000 2.99e-02 4.30e+00
3 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 22500 2.93e-02 4.37e+00
4 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 30000 3.63e-02 4.48e+00
5 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 37500 3.32e-02 4.84e+00
6 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 45000 4.03e-02 4.91e+00
7 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 52500 3.85e-02 4.88e+00
8 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 60000 4.59e-02 5.17e+00
9 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 67500 3.34e-02 5.08e+00
10 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 75000 4.56e-02 5.32e+00
11 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 82500 3.73e-02 5.21e+00
12 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 90000 3.84e-02 5.14e+00
13 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 97500 3.71e-02 5.13e+00
14 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 105000 3.69e-02 5.29e+00
15 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 112500 5.14e-02 5.34e+00
16 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 120000 3.25e-02 5.18e+00
17 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 127500 4.22e-02 5.23e+00
18 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 135000 4.07e-02 5.31e+00
19 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 142500 4.21e-02 5.34e+00
20 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 6 150000 4.00e-02 5.34e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 7500 2.26e-02 3.87e+00
2 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 15000 2.67e-02 4.23e+00
3 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 22500 3.06e-02 4.34e+00
4 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 30000 3.99e-02 4.68e+00
5 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 37500 3.69e-02 4.78e+00
6 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 45000 3.71e-02 5.14e+00
7 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 52500 3.47e-02 4.80e+00
8 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 60000 3.63e-02 4.91e+00
9 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 67500 3.78e-02 4.95e+00
10 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 75000 4.01e-02 5.20e+00
11 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 82500 3.72e-02 5.33e+00
12 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 90000 4.20e-02 5.12e+00
13 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 97500 3.61e-02 5.33e+00
14 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 105000 4.29e-02 5.28e+00
15 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 112500 5.06e-02 5.68e+00
16 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 120000 4.98e-02 5.39e+00
17 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 127500 4.51e-02 5.71e+00
18 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 135000 3.02e-02 5.41e+00
19 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 142500 3.22e-02 4.84e+00
20 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 7 150000 5.47e-02 5.44e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 7500 2.68e-02 3.97e+00
2 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 15000 3.63e-02 4.13e+00
3 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 22500 2.61e-02 4.28e+00
4 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 30000 4.02e-02 4.62e+00
5 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 37500 3.78e-02 4.71e+00
6 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 45000 3.31e-02 5.01e+00
7 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 52500 4.02e-02 4.96e+00
8 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 60000 4.49e-02 4.99e+00
9 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 67500 4.05e-02 5.28e+00
10 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 75000 3.78e-02 5.22e+00
11 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 82500 4.61e-02 5.08e+00
12 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 90000 3.83e-02 5.32e+00
13 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 97500 4.35e-02 5.26e+00
14 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 105000 4.41e-02 5.28e+00
15 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 112500 4.39e-02 5.54e+00
16 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 120000 4.27e-02 5.37e+00
17 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 127500 5.70e-02 5.62e+00
18 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 135000 4.71e-02 5.70e+00
19 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 142500 4.88e-02 5.69e+00
20 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 8 150000 3.58e-02 5.38e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 7500 2.99e-02 4.11e+00
2 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 15000 2.93e-02 4.13e+00
3 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 22500 3.17e-02 4.39e+00
4 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 30000 3.15e-02 4.57e+00
5 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 37500 3.40e-02 4.75e+00
6 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 45000 4.14e-02 4.79e+00
7 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 52500 3.37e-02 4.84e+00
8 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 60000 3.63e-02 5.00e+00
9 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 67500 4.65e-02 5.17e+00
10 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 75000 3.81e-02 5.33e+00
11 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 82500 4.07e-02 5.12e+00
12 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 90000 3.79e-02 5.16e+00
13 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 97500 5.10e-02 5.09e+00
14 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 105000 4.26e-02 5.49e+00
15 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 112500 5.50e-02 5.67e+00
16 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 120000 4.81e-02 5.77e+00
17 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 127500 2.77e-02 5.26e+00
18 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 135000 4.49e-02 5.39e+00
19 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 142500 4.91e-02 5.64e+00
20 A3C 8 8 2 4 2.50e-01 False 2.50e-01 0 0 9 150000 5.46e-02 5.85e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 7500 2.31e-01 4.26e+00
2 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 15000 3.78e-01 5.26e+00
3 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 22500 7.30e-01 7.82e+00
4 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 30000 1.90e+00 1.48e+01
5 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 37500 4.76e+00 3.12e+01
6 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 45000 7.10e+00 4.27e+01
7 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 52500 1.19e+01 5.98e+01
8 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 60000 1.43e+01 6.24e+01
9 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 67500 1.59e+01 6.85e+01
10 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 75000 1.65e+01 7.17e+01
11 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 82500 1.47e+01 7.29e+01
12 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 90000 1.48e+01 7.42e+01
13 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 97500 1.24e+01 7.40e+01
14 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 105000 1.35e+01 8.19e+01
15 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 112500 1.49e+01 7.51e+01
16 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 120000 1.43e+01 7.48e+01
17 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 127500 1.75e+01 8.07e+01
18 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 135000 1.89e+01 8.22e+01
19 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 142500 2.11e+01 8.38e+01
20 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 0 150000 2.34e+01 8.35e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 7500 2.29e-01 4.15e+00
2 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 15000 3.93e-01 5.20e+00
3 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 22500 9.71e-01 8.92e+00
4 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 30000 2.66e+00 1.84e+01
5 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 37500 5.87e+00 3.58e+01
6 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 45000 1.14e+01 4.84e+01
7 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 52500 1.88e+01 5.60e+01
8 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 60000 4.22e+01 7.51e+01
9 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 67500 6.21e+01 8.47e+01
10 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 75000 7.19e+01 9.21e+01
11 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 82500 7.73e+01 9.41e+01
12 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 90000 7.44e+01 9.06e+01
13 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 97500 7.06e+01 8.66e+01
14 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 105000 7.16e+01 9.11e+01
15 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 112500 5.95e+01 8.44e+01
16 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 120000 5.99e+01 8.75e+01
17 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 127500 5.95e+01 8.96e+01
18 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 135000 5.73e+01 8.77e+01
19 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 142500 5.91e+01 9.11e+01
20 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 1 150000 5.48e+01 9.32e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 7500 2.24e-01 4.09e+00
2 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 15000 3.59e-01 5.10e+00
3 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 22500 7.88e-01 7.84e+00
4 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 30000 2.08e+00 1.51e+01
5 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 37500 4.44e+00 2.91e+01
6 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 45000 9.31e+00 4.76e+01
7 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 52500 1.24e+01 5.47e+01
8 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 60000 1.74e+01 6.65e+01
9 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 67500 2.24e+01 7.26e+01
10 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 75000 2.80e+01 7.08e+01
11 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 82500 4.70e+01 8.31e+01
12 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 90000 6.10e+01 9.09e+01
13 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 97500 6.43e+01 9.02e+01
14 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 105000 6.69e+01 9.21e+01
15 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 112500 5.78e+01 8.49e+01
16 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 120000 6.37e+01 9.06e+01
17 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 127500 6.05e+01 9.05e+01
18 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 135000 5.78e+01 9.05e+01
19 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 142500 5.93e+01 8.88e+01
20 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 2 150000 5.99e+01 9.26e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 7500 2.39e-01 4.18e+00
2 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 15000 3.30e-01 4.93e+00
3 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 22500 8.12e-01 7.73e+00
4 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 30000 2.41e+00 1.64e+01
5 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 37500 5.81e+00 3.01e+01
6 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 45000 1.27e+01 5.06e+01
7 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 52500 3.17e+01 6.48e+01
8 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 60000 5.90e+01 8.26e+01
9 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 67500 7.14e+01 8.77e+01
10 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 75000 7.78e+01 9.31e+01
11 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 82500 8.26e+01 9.68e+01
12 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 90000 8.41e+01 9.52e+01
13 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 97500 8.37e+01 9.57e+01
14 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 105000 7.88e+01 9.36e+01
15 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 112500 7.04e+01 8.82e+01
16 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 120000 6.70e+01 8.96e+01
17 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 127500 5.96e+01 8.97e+01
18 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 135000 6.19e+01 9.23e+01
19 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 142500 6.18e+01 9.25e+01
20 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 3 150000 6.06e+01 9.55e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 7500 2.28e-01 4.05e+00
2 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 15000 3.24e-01 4.77e+00
3 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 22500 7.60e-01 7.83e+00
4 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 30000 2.11e+00 1.59e+01
5 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 37500 4.90e+00 2.88e+01
6 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 45000 9.58e+00 4.36e+01
7 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 52500 1.70e+01 5.59e+01
8 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 60000 3.07e+01 7.30e+01
9 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 67500 4.64e+01 7.45e+01
10 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 75000 6.19e+01 8.34e+01
11 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 82500 7.36e+01 9.03e+01
12 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 90000 7.95e+01 9.27e+01
13 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 97500 7.86e+01 9.24e+01
14 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 105000 7.22e+01 8.85e+01
15 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 112500 6.89e+01 9.06e+01
16 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 120000 5.40e+01 8.60e+01
17 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 127500 5.80e+01 9.16e+01
18 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 135000 5.74e+01 9.29e+01
19 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 142500 5.65e+01 9.26e+01
20 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 4 150000 5.61e+01 9.17e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 7500 2.19e-01 4.02e+00
2 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 15000 2.66e-01 4.51e+00
3 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 22500 5.79e-01 6.93e+00
4 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 30000 1.43e+00 1.28e+01
5 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 37500 3.74e+00 2.60e+01
6 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 45000 7.31e+00 4.17e+01
7 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 52500 1.38e+01 5.72e+01
8 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 60000 3.32e+01 6.98e+01
9 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 67500 5.66e+01 8.39e+01
10 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 75000 7.02e+01 9.04e+01
11 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 82500 7.39e+01 9.10e+01
12 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 90000 7.23e+01 8.78e+01
13 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 97500 7.93e+01 9.30e+01
14 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 105000 7.97e+01 9.54e+01
15 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 112500 6.93e+01 8.93e+01
16 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 120000 5.87e+01 8.43e+01
17 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 127500 6.18e+01 8.95e+01
18 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 135000 5.80e+01 8.62e+01
19 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 142500 5.72e+01 8.88e+01
20 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 5 150000 5.63e+01 8.77e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 7500 2.04e-01 3.93e+00
2 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 15000 3.61e-01 5.14e+00
3 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 22500 7.71e-01 7.64e+00
4 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 30000 2.14e+00 1.53e+01
5 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 37500 5.92e+00 3.18e+01
6 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 45000 1.26e+01 5.16e+01
7 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 52500 1.99e+01 5.96e+01
8 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 60000 4.42e+01 7.91e+01
9 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 67500 5.39e+01 8.06e+01
10 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 75000 6.62e+01 8.85e+01
11 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 82500 7.01e+01 9.26e+01
12 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 90000 6.83e+01 8.86e+01
13 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 97500 6.96e+01 9.00e+01
14 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 105000 6.54e+01 8.94e+01
15 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 112500 5.86e+01 8.61e+01
16 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 120000 6.20e+01 8.82e+01
17 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 127500 6.57e+01 9.39e+01
18 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 135000 6.04e+01 8.97e+01
19 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 142500 5.97e+01 9.21e+01
20 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 6 150000 5.50e+01 8.71e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 7500 2.13e-01 4.09e+00
2 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 15000 3.49e-01 5.07e+00
3 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 22500 8.07e-01 8.18e+00
4 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 30000 1.91e+00 1.65e+01
5 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 37500 4.61e+00 3.31e+01
6 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 45000 8.17e+00 5.08e+01
7 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 52500 9.59e+00 5.54e+01
8 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 60000 1.31e+01 5.99e+01
9 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 67500 1.29e+01 6.51e+01
10 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 75000 1.35e+01 7.22e+01
11 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 82500 1.24e+01 6.57e+01
12 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 90000 1.40e+01 7.69e+01
13 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 97500 1.21e+01 7.62e+01
14 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 105000 1.23e+01 7.39e+01
15 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 112500 1.34e+01 8.45e+01
16 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 120000 1.17e+01 7.99e+01
17 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 127500 1.34e+01 8.17e+01
18 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 135000 1.52e+01 8.45e+01
19 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 142500 1.47e+01 8.16e+01
20 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 7 150000 1.21e+01 7.63e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 7500 2.23e-01 3.98e+00
2 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 15000 3.38e-01 4.99e+00
3 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 22500 6.87e-01 7.08e+00
4 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 30000 1.98e+00 1.45e+01
5 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 37500 5.00e+00 2.99e+01
6 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 45000 8.88e+00 4.75e+01
7 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 52500 9.66e+00 5.35e+01
8 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 60000 9.90e+00 6.07e+01
9 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 67500 1.12e+01 6.61e+01
10 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 75000 1.24e+01 6.94e+01
11 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 82500 1.31e+01 7.22e+01
12 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 90000 1.52e+01 7.42e+01
13 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 97500 1.38e+01 7.22e+01
14 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 105000 1.25e+01 6.95e+01
15 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 112500 1.47e+01 7.98e+01
16 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 120000 1.55e+01 7.63e+01
17 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 127500 1.83e+01 8.31e+01
18 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 135000 1.48e+01 8.06e+01
19 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 142500 1.60e+01 8.46e+01
20 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 8 150000 1.62e+01 7.83e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 7500 2.25e-01 4.07e+00
2 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 15000 3.21e-01 4.79e+00
3 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 22500 6.31e-01 7.01e+00
4 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 30000 1.74e+00 1.34e+01
5 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 37500 4.45e+00 2.72e+01
6 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 45000 9.86e+00 4.83e+01
7 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 52500 1.73e+01 5.97e+01
8 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 60000 2.92e+01 6.29e+01
9 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 67500 6.02e+01 8.46e+01
10 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 75000 6.88e+01 9.15e+01
11 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 82500 7.46e+01 9.14e+01
12 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 90000 8.06e+01 9.44e+01
13 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 97500 8.54e+01 9.76e+01
14 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 105000 8.37e+01 9.73e+01
15 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 112500 7.54e+01 9.15e+01
16 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 120000 6.67e+01 8.52e+01
17 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 127500 6.68e+01 9.16e+01
18 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 135000 6.43e+01 9.08e+01
19 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 142500 6.49e+01 9.30e+01
20 A3C 8 8 4 1 2.50e-01 False 2.50e-01 0 0 9 150000 6.22e+01 9.04e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 7500 8.82e-02 3.93e+00
2 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 15000 1.69e-01 4.67e+00
3 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 22500 2.85e-01 5.93e+00
4 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 30000 5.53e-01 9.18e+00
5 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 37500 1.49e+00 1.72e+01
6 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 45000 3.37e+00 3.36e+01
7 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 52500 4.91e+00 4.77e+01
8 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 60000 5.15e+00 5.25e+01
9 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 67500 6.30e+00 6.32e+01
10 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 75000 7.91e+00 7.25e+01
11 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 82500 7.64e+00 7.20e+01
12 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 90000 7.56e+00 7.09e+01
13 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 97500 7.92e+00 7.77e+01
14 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 105000 8.24e+00 7.78e+01
15 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 112500 8.70e+00 8.43e+01
16 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 120000 8.64e+00 7.85e+01
17 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 127500 8.95e+00 8.17e+01
18 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 135000 9.12e+00 8.49e+01
19 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 142500 8.15e+00 7.68e+01
20 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 0 150000 8.26e+00 8.12e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 7500 1.34e-01 4.30e+00
2 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 15000 1.52e-01 4.67e+00
3 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 22500 2.63e-01 5.74e+00
4 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 30000 5.33e-01 8.82e+00
5 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 37500 1.49e+00 1.82e+01
6 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 45000 3.27e+00 3.28e+01
7 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 52500 4.38e+00 4.17e+01
8 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 60000 5.53e+00 5.19e+01
9 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 67500 6.82e+00 6.43e+01
10 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 75000 8.22e+00 7.10e+01
11 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 82500 8.09e+00 7.03e+01
12 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 90000 8.58e+00 7.67e+01
13 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 97500 7.97e+00 7.39e+01
14 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 105000 8.79e+00 8.07e+01
15 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 112500 8.95e+00 8.05e+01
16 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 120000 8.81e+00 7.99e+01
17 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 127500 7.55e+00 7.58e+01
18 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 135000 8.47e+00 8.45e+01
19 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 142500 8.53e+00 8.14e+01
20 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 1 150000 8.70e+00 8.15e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 7500 1.07e-01 4.08e+00
2 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 15000 1.46e-01 4.69e+00
3 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 22500 2.36e-01 5.64e+00
4 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 30000 4.74e-01 8.60e+00
5 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 37500 1.17e+00 1.52e+01
6 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 45000 2.40e+00 2.77e+01
7 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 52500 4.10e+00 4.32e+01
8 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 60000 4.91e+00 5.02e+01
9 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 67500 5.89e+00 6.01e+01
10 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 75000 7.67e+00 7.07e+01
11 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 82500 7.47e+00 6.85e+01
12 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 90000 8.01e+00 7.46e+01
13 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 97500 8.00e+00 7.65e+01
14 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 105000 8.43e+00 7.85e+01
15 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 112500 8.08e+00 7.40e+01
16 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 120000 8.55e+00 7.77e+01
17 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 127500 8.62e+00 8.02e+01
18 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 135000 8.21e+00 8.46e+01
19 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 142500 8.21e+00 8.30e+01
20 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 2 150000 8.41e+00 8.27e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 7500 1.17e-01 4.11e+00
2 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 15000 1.72e-01 4.97e+00
3 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 22500 2.79e-01 6.42e+00
4 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 30000 6.64e-01 1.02e+01
5 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 37500 1.67e+00 2.07e+01
6 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 45000 3.33e+00 3.50e+01
7 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 52500 4.28e+00 4.44e+01
8 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 60000 5.69e+00 5.88e+01
9 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 67500 6.25e+00 6.52e+01
10 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 75000 7.55e+00 7.06e+01
11 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 82500 6.91e+00 7.15e+01
12 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 90000 7.85e+00 7.45e+01
13 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 97500 7.48e+00 7.76e+01
14 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 105000 7.26e+00 7.49e+01
15 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 112500 7.78e+00 8.15e+01
16 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 120000 8.17e+00 8.13e+01
17 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 127500 8.51e+00 8.28e+01
18 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 135000 9.18e+00 8.81e+01
19 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 142500 8.38e+00 8.65e+01
20 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 3 150000 8.24e+00 8.56e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 7500 1.04e-01 4.05e+00
2 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 15000 1.48e-01 4.70e+00
3 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 22500 2.09e-01 5.63e+00
4 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 30000 4.84e-01 8.83e+00
5 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 37500 1.28e+00 1.69e+01
6 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 45000 2.68e+00 2.93e+01
7 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 52500 4.46e+00 4.47e+01
8 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 60000 5.75e+00 5.71e+01
9 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 67500 6.14e+00 6.40e+01
10 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 75000 7.01e+00 7.10e+01
11 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 82500 7.63e+00 7.46e+01
12 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 90000 6.83e+00 6.92e+01
13 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 97500 7.92e+00 7.81e+01
14 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 105000 8.57e+00 8.08e+01
15 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 112500 8.37e+00 7.95e+01
16 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 120000 7.60e+00 7.42e+01
17 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 127500 8.52e+00 7.67e+01
18 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 135000 8.76e+00 8.36e+01
19 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 142500 8.33e+00 7.96e+01
20 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 4 150000 8.69e+00 8.32e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 7500 1.15e-01 4.19e+00
2 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 15000 1.60e-01 4.70e+00
3 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 22500 2.59e-01 6.21e+00
4 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 30000 5.61e-01 9.19e+00
5 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 37500 1.28e+00 1.72e+01
6 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 45000 2.86e+00 3.28e+01
7 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 52500 4.21e+00 4.69e+01
8 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 60000 5.70e+00 5.96e+01
9 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 67500 6.20e+00 5.98e+01
10 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 75000 7.19e+00 7.25e+01
11 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 82500 7.19e+00 7.09e+01
12 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 90000 7.61e+00 7.40e+01
13 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 97500 8.01e+00 7.24e+01
14 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 105000 7.55e+00 6.73e+01
15 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 112500 8.67e+00 7.77e+01
16 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 120000 8.64e+00 8.15e+01
17 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 127500 8.60e+00 8.15e+01
18 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 135000 8.66e+00 8.09e+01
19 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 142500 8.98e+00 8.45e+01
20 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 5 150000 9.45e+00 8.75e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 7500 1.15e-01 4.16e+00
2 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 15000 1.40e-01 4.69e+00
3 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 22500 2.25e-01 5.61e+00
4 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 30000 4.43e-01 8.29e+00
5 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 37500 9.33e-01 1.46e+01
6 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 45000 2.32e+00 2.65e+01
7 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 52500 3.69e+00 4.04e+01
8 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 60000 5.24e+00 5.15e+01
9 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 67500 6.28e+00 6.17e+01
10 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 75000 6.90e+00 6.66e+01
11 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 82500 6.94e+00 7.18e+01
12 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 90000 7.16e+00 7.01e+01
13 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 97500 7.70e+00 7.52e+01
14 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 105000 7.35e+00 7.55e+01
15 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 112500 8.40e+00 7.87e+01
16 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 120000 8.39e+00 8.14e+01
17 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 127500 7.57e+00 7.77e+01
18 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 135000 9.28e+00 8.62e+01
19 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 142500 9.32e+00 8.08e+01
20 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 6 150000 8.99e+00 8.31e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 7500 9.50e-02 4.05e+00
2 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 15000 1.43e-01 4.67e+00
3 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 22500 2.26e-01 5.58e+00
4 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 30000 5.06e-01 9.37e+00
5 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 37500 1.14e+00 1.64e+01
6 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 45000 2.41e+00 2.86e+01
7 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 52500 3.69e+00 4.25e+01
8 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 60000 5.25e+00 5.77e+01
9 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 67500 6.28e+00 6.48e+01
10 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 75000 6.24e+00 6.35e+01
11 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 82500 6.51e+00 6.92e+01
12 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 90000 7.28e+00 7.08e+01
13 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 97500 7.84e+00 7.57e+01
14 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 105000 7.51e+00 7.58e+01
15 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 112500 7.67e+00 7.45e+01
16 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 120000 7.88e+00 7.76e+01
17 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 127500 8.00e+00 8.18e+01
18 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 135000 8.48e+00 8.33e+01
19 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 142500 8.02e+00 8.27e+01
20 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 7 150000 8.28e+00 8.18e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 7500 1.18e-01 4.09e+00
2 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 15000 1.41e-01 4.53e+00
3 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 22500 2.08e-01 5.53e+00
4 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 30000 3.67e-01 7.85e+00
5 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 37500 9.64e-01 1.37e+01
6 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 45000 2.08e+00 2.50e+01
7 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 52500 3.55e+00 3.90e+01
8 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 60000 5.40e+00 5.96e+01
9 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 67500 5.67e+00 5.67e+01
10 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 75000 6.64e+00 6.91e+01
11 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 82500 6.77e+00 6.89e+01
12 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 90000 7.53e+00 7.40e+01
13 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 97500 7.84e+00 7.97e+01
14 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 105000 8.00e+00 7.70e+01
15 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 112500 7.76e+00 7.27e+01
16 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 120000 8.23e+00 7.54e+01
17 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 127500 8.51e+00 7.87e+01
18 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 135000 8.73e+00 7.84e+01
19 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 142500 8.14e+00 8.02e+01
20 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 8 150000 8.93e+00 8.75e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 7500 1.19e-01 4.11e+00
2 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 15000 1.30e-01 4.56e+00
3 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 22500 1.82e-01 5.20e+00
4 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 30000 4.53e-01 7.73e+00
5 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 37500 1.14e+00 1.43e+01
6 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 45000 2.48e+00 2.74e+01
7 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 52500 4.53e+00 4.35e+01
8 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 60000 5.90e+00 5.75e+01
9 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 67500 6.52e+00 6.41e+01
10 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 75000 6.96e+00 6.79e+01
11 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 82500 6.97e+00 6.71e+01
12 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 90000 7.62e+00 7.27e+01
13 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 97500 7.78e+00 7.62e+01
14 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 105000 7.75e+00 7.52e+01
15 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 112500 8.41e+00 8.24e+01
16 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 120000 7.73e+00 7.81e+01
17 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 127500 8.68e+00 7.93e+01
18 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 135000 9.24e+00 8.15e+01
19 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 142500 9.89e+00 8.39e+01
20 A3C 8 8 4 2 2.50e-01 False 2.50e-01 0 0 9 150000 9.56e+00 8.36e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 7500 3.59e-02 3.86e+00
2 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 15000 5.08e-02 4.37e+00
3 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 22500 5.75e-02 4.43e+00
4 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 30000 8.01e-02 4.95e+00
5 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 37500 6.82e-02 5.15e+00
6 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 45000 1.13e-01 6.10e+00
7 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 52500 1.62e-01 7.26e+00
8 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 60000 2.13e-01 8.94e+00
9 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 67500 3.56e-01 1.21e+01
10 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 75000 6.10e-01 1.82e+01
11 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 82500 1.05e+00 2.82e+01
12 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 90000 1.49e+00 4.09e+01
13 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 97500 2.05e+00 4.74e+01
14 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 105000 2.18e+00 5.22e+01
15 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 112500 2.66e+00 6.25e+01
16 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 120000 2.68e+00 6.93e+01
17 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 127500 2.92e+00 6.90e+01
18 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 135000 3.23e+00 7.33e+01
19 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 142500 3.11e+00 7.96e+01
20 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 0 150000 3.40e+00 7.62e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 7500 4.87e-02 4.09e+00
2 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 15000 6.17e-02 4.43e+00
3 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 22500 7.96e-02 4.85e+00
4 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 30000 8.14e-02 5.19e+00
5 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 37500 1.00e-01 5.93e+00
6 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 45000 1.48e-01 7.20e+00
7 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 52500 1.91e-01 7.86e+00
8 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 60000 3.74e-01 1.27e+01
9 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 67500 5.44e-01 1.74e+01
10 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 75000 8.68e-01 2.54e+01
11 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 82500 1.48e+00 3.70e+01
12 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 90000 1.78e+00 4.56e+01
13 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 97500 2.09e+00 5.72e+01
14 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 105000 2.56e+00 6.33e+01
15 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 112500 2.77e+00 6.45e+01
16 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 120000 2.83e+00 7.04e+01
17 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 127500 2.94e+00 7.09e+01
18 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 135000 3.29e+00 7.57e+01
19 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 142500 3.27e+00 8.05e+01
20 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 1 150000 3.11e+00 7.64e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 7500 3.87e-02 4.01e+00
2 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 15000 5.35e-02 4.36e+00
3 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 22500 6.17e-02 4.77e+00
4 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 30000 7.69e-02 5.06e+00
5 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 37500 1.10e-01 5.82e+00
6 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 45000 1.19e-01 6.50e+00
7 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 52500 1.62e-01 7.62e+00
8 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 60000 2.62e-01 1.00e+01
9 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 67500 3.96e-01 1.24e+01
10 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 75000 6.70e-01 1.99e+01
11 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 82500 1.10e+00 2.88e+01
12 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 90000 1.90e+00 4.58e+01
13 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 97500 1.96e+00 4.89e+01
14 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 105000 2.27e+00 5.36e+01
15 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 112500 2.59e+00 6.29e+01
16 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 120000 2.57e+00 6.75e+01
17 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 127500 2.70e+00 6.98e+01
18 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 135000 2.78e+00 7.22e+01
19 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 142500 3.06e+00 7.64e+01
20 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 2 150000 3.19e+00 8.12e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 7500 4.35e-02 4.09e+00
2 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 15000 4.81e-02 4.14e+00
3 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 22500 4.52e-02 4.46e+00
4 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 30000 7.24e-02 4.79e+00
5 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 37500 8.65e-02 5.30e+00
6 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 45000 9.60e-02 5.70e+00
7 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 52500 1.45e-01 6.56e+00
8 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 60000 2.36e-01 8.73e+00
9 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 67500 3.19e-01 1.17e+01
10 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 75000 4.91e-01 1.63e+01
11 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 82500 1.00e+00 2.53e+01
12 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 90000 1.42e+00 3.59e+01
13 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 97500 2.09e+00 4.73e+01
14 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 105000 2.53e+00 5.78e+01
15 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 112500 2.15e+00 6.20e+01
16 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 120000 2.64e+00 6.45e+01
17 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 127500 3.08e+00 7.60e+01
18 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 135000 3.36e+00 7.85e+01
19 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 142500 3.11e+00 7.68e+01
20 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 3 150000 3.68e+00 7.69e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 7500 5.51e-02 4.18e+00
2 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 15000 4.33e-02 4.22e+00
3 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 22500 5.75e-02 4.41e+00
4 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 30000 8.53e-02 5.08e+00
5 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 37500 9.99e-02 5.89e+00
6 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 45000 1.38e-01 6.51e+00
7 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 52500 1.78e-01 7.66e+00
8 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 60000 2.41e-01 9.37e+00
9 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 67500 4.77e-01 1.43e+01
10 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 75000 8.74e-01 2.29e+01
11 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 82500 1.12e+00 2.89e+01
12 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 90000 1.82e+00 4.44e+01
13 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 97500 2.22e+00 5.06e+01
14 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 105000 2.26e+00 5.86e+01
15 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 112500 2.55e+00 6.01e+01
16 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 120000 3.14e+00 7.04e+01
17 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 127500 2.89e+00 7.16e+01
18 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 135000 3.67e+00 7.93e+01
19 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 142500 3.45e+00 8.33e+01
20 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 4 150000 3.46e+00 8.23e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 7500 4.58e-02 4.08e+00
2 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 15000 4.85e-02 4.27e+00
3 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 22500 6.61e-02 4.64e+00
4 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 30000 8.46e-02 5.09e+00
5 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 37500 7.98e-02 5.56e+00
6 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 45000 1.40e-01 6.31e+00
7 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 52500 1.54e-01 7.88e+00
8 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 60000 2.68e-01 9.68e+00
9 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 67500 4.58e-01 1.40e+01
10 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 75000 7.82e-01 2.36e+01
11 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 82500 1.06e+00 2.94e+01
12 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 90000 1.58e+00 4.24e+01
13 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 97500 2.40e+00 5.35e+01
14 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 105000 2.61e+00 5.71e+01
15 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 112500 2.33e+00 5.75e+01
16 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 120000 2.98e+00 7.23e+01
17 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 127500 3.63e+00 8.13e+01
18 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 135000 3.19e+00 7.50e+01
19 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 142500 3.31e+00 7.72e+01
20 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 5 150000 3.67e+00 8.51e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 7500 4.65e-02 3.92e+00
2 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 15000 4.14e-02 4.15e+00
3 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 22500 6.32e-02 4.49e+00
4 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 30000 7.02e-02 4.93e+00
5 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 37500 8.34e-02 5.36e+00
6 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 45000 1.16e-01 6.10e+00
7 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 52500 1.72e-01 7.56e+00
8 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 60000 2.52e-01 1.01e+01
9 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 67500 3.58e-01 1.26e+01
10 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 75000 6.14e-01 1.82e+01
11 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 82500 1.03e+00 2.69e+01
12 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 90000 1.32e+00 3.77e+01
13 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 97500 1.78e+00 4.67e+01
14 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 105000 2.21e+00 5.72e+01
15 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 112500 2.48e+00 6.18e+01
16 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 120000 2.53e+00 5.94e+01
17 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 127500 2.94e+00 7.51e+01
18 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 135000 3.02e+00 7.23e+01
19 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 142500 3.21e+00 7.57e+01
20 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 6 150000 3.34e+00 8.06e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 7500 4.70e-02 4.05e+00
2 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 15000 4.46e-02 4.23e+00
3 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 22500 6.03e-02 4.39e+00
4 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 30000 6.94e-02 5.15e+00
5 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 37500 1.10e-01 5.75e+00
6 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 45000 1.45e-01 6.82e+00
7 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 52500 2.10e-01 8.43e+00
8 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 60000 3.67e-01 1.26e+01
9 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 67500 6.49e-01 1.81e+01
10 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 75000 1.01e+00 2.73e+01
11 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 82500 1.52e+00 3.89e+01
12 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 90000 1.97e+00 4.73e+01
13 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 97500 2.59e+00 5.92e+01
14 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 105000 2.43e+00 5.88e+01
15 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 112500 3.09e+00 6.70e+01
16 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 120000 3.06e+00 6.91e+01
17 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 127500 2.80e+00 6.96e+01
18 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 135000 3.39e+00 7.64e+01
19 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 142500 3.55e+00 8.03e+01
20 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 7 150000 3.26e+00 8.03e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 7500 4.63e-02 4.05e+00
2 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 15000 4.66e-02 4.27e+00
3 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 22500 4.20e-02 4.39e+00
4 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 30000 6.16e-02 4.51e+00
5 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 37500 9.29e-02 5.27e+00
6 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 45000 1.19e-01 6.23e+00
7 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 52500 1.90e-01 7.77e+00
8 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 60000 3.23e-01 1.07e+01
9 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 67500 5.09e-01 1.54e+01
10 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 75000 8.54e-01 2.51e+01
11 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 82500 1.28e+00 3.49e+01
12 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 90000 2.01e+00 4.66e+01
13 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 97500 1.99e+00 5.14e+01
14 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 105000 2.55e+00 5.91e+01
15 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 112500 2.34e+00 6.51e+01
16 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 120000 2.84e+00 6.51e+01
17 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 127500 2.61e+00 7.13e+01
18 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 135000 2.83e+00 6.95e+01
19 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 142500 3.13e+00 7.78e+01
20 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 8 150000 3.15e+00 8.04e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 7500 3.91e-02 3.98e+00
2 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 15000 5.35e-02 4.00e+00
3 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 22500 4.62e-02 4.30e+00
4 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 30000 5.48e-02 4.56e+00
5 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 37500 6.48e-02 4.91e+00
6 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 45000 8.95e-02 5.49e+00
7 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 52500 1.09e-01 6.04e+00
8 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 60000 1.68e-01 7.45e+00
9 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 67500 2.08e-01 8.98e+00
10 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 75000 4.05e-01 1.29e+01
11 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 82500 6.61e-01 1.93e+01
12 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 90000 1.03e+00 2.88e+01
13 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 97500 1.67e+00 3.93e+01
14 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 105000 2.35e+00 5.30e+01
15 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 112500 2.44e+00 6.13e+01
16 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 120000 2.62e+00 6.67e+01
17 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 127500 2.84e+00 6.67e+01
18 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 135000 3.26e+00 7.48e+01
19 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 142500 3.16e+00 7.07e+01
20 A3C 8 8 4 3 2.50e-01 False 2.50e-01 0 0 9 150000 3.34e+00 7.73e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 7500 1.33e-02 4.05e+00
2 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 15000 1.61e-02 4.19e+00
3 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 22500 1.76e-02 4.24e+00
4 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 30000 2.51e-02 4.38e+00
5 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 37500 2.21e-02 4.38e+00
6 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 45000 1.96e-02 4.42e+00
7 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 52500 1.92e-02 4.68e+00
8 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 60000 1.71e-02 4.54e+00
9 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 67500 1.97e-02 4.60e+00
10 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 75000 1.92e-02 4.53e+00
11 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 82500 2.18e-02 4.52e+00
12 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 90000 1.62e-02 4.64e+00
13 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 97500 2.36e-02 4.80e+00
14 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 105000 2.27e-02 4.61e+00
15 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 112500 1.48e-02 4.43e+00
16 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 120000 2.46e-02 4.71e+00
17 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 127500 1.49e-02 4.52e+00
18 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 135000 1.93e-02 4.65e+00
19 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 142500 2.04e-02 4.64e+00
20 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 0 150000 2.14e-02 4.70e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 7500 1.37e-02 4.02e+00
2 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 15000 1.35e-02 4.26e+00
3 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 22500 1.76e-02 4.36e+00
4 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 30000 1.45e-02 4.21e+00
5 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 37500 1.31e-02 4.23e+00
6 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 45000 2.30e-02 4.45e+00
7 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 52500 2.86e-02 4.62e+00
8 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 60000 1.75e-02 4.70e+00
9 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 67500 2.00e-02 4.67e+00
10 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 75000 1.72e-02 4.67e+00
11 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 82500 1.73e-02 4.46e+00
12 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 90000 1.18e-02 4.66e+00
13 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 97500 1.48e-02 4.61e+00
14 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 105000 1.84e-02 4.49e+00
15 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 112500 1.78e-02 4.56e+00
16 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 120000 2.06e-02 4.46e+00
17 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 127500 2.09e-02 4.76e+00
18 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 135000 1.66e-02 4.57e+00
19 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 142500 1.73e-02 4.46e+00
20 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 1 150000 2.16e-02 4.54e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 7500 1.45e-02 3.95e+00
2 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 15000 1.22e-02 4.40e+00
3 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 22500 2.32e-02 4.28e+00
4 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 30000 2.44e-02 4.39e+00
5 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 37500 1.64e-02 4.37e+00
6 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 45000 1.84e-02 4.53e+00
7 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 52500 1.33e-02 4.42e+00
8 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 60000 2.25e-02 4.50e+00
9 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 67500 2.63e-02 4.45e+00
10 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 75000 2.56e-02 4.72e+00
11 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 82500 2.25e-02 4.54e+00
12 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 90000 2.30e-02 4.44e+00
13 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 97500 1.76e-02 4.53e+00
14 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 105000 2.81e-02 4.85e+00
15 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 112500 2.12e-02 4.67e+00
16 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 120000 1.68e-02 4.49e+00
17 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 127500 2.26e-02 4.59e+00
18 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 135000 2.30e-02 4.53e+00
19 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 142500 2.27e-02 4.48e+00
20 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 2 150000 1.71e-02 4.60e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 7500 1.34e-02 4.10e+00
2 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 15000 1.12e-02 4.20e+00
3 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 22500 8.43e-03 3.96e+00
4 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 30000 1.27e-02 3.97e+00
5 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 37500 2.04e-02 4.25e+00
6 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 45000 1.54e-02 4.43e+00
7 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 52500 9.55e-03 4.22e+00
8 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 60000 1.43e-02 4.28e+00
9 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 67500 1.65e-02 4.43e+00
10 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 75000 1.56e-02 4.37e+00
11 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 82500 1.90e-02 4.44e+00
12 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 90000 1.71e-02 4.45e+00
13 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 97500 2.01e-02 4.68e+00
14 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 105000 2.08e-02 4.61e+00
15 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 112500 2.44e-02 4.73e+00
16 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 120000 2.04e-02 4.51e+00
17 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 127500 1.68e-02 4.57e+00
18 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 135000 2.11e-02 4.61e+00
19 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 142500 1.70e-02 4.52e+00
20 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 3 150000 1.62e-02 4.46e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 7500 1.40e-02 4.14e+00
2 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 15000 1.65e-02 4.18e+00
3 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 22500 1.29e-02 4.07e+00
4 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 30000 1.73e-02 4.35e+00
5 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 37500 2.09e-02 4.41e+00
6 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 45000 1.80e-02 4.33e+00
7 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 52500 1.86e-02 4.50e+00
8 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 60000 2.44e-02 4.61e+00
9 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 67500 1.72e-02 4.53e+00
10 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 75000 2.18e-02 4.65e+00
11 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 82500 1.80e-02 4.60e+00
12 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 90000 1.51e-02 4.50e+00
13 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 97500 1.95e-02 4.75e+00
14 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 105000 2.35e-02 4.65e+00
15 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 112500 1.55e-02 4.47e+00
16 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 120000 1.78e-02 4.45e+00
17 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 127500 1.55e-02 4.49e+00
18 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 135000 1.84e-02 4.58e+00
19 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 142500 1.28e-02 4.55e+00
20 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 4 150000 2.47e-02 4.56e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 7500 1.53e-02 4.05e+00
2 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 15000 1.60e-02 4.23e+00
3 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 22500 1.31e-02 4.27e+00
4 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 30000 1.74e-02 4.22e+00
5 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 37500 1.84e-02 4.34e+00
6 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 45000 1.99e-02 4.50e+00
7 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 52500 1.86e-02 4.44e+00
8 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 60000 1.67e-02 4.51e+00
9 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 67500 2.10e-02 4.51e+00
10 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 75000 2.12e-02 4.54e+00
11 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 82500 2.02e-02 4.61e+00
12 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 90000 2.12e-02 4.54e+00
13 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 97500 1.55e-02 4.48e+00
14 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 105000 1.45e-02 4.32e+00
15 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 112500 2.39e-02 4.87e+00
16 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 120000 1.51e-02 4.56e+00
17 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 127500 2.47e-02 4.66e+00
18 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 135000 2.02e-02 4.59e+00
19 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 142500 1.96e-02 4.53e+00
20 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 5 150000 1.36e-02 4.48e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 7500 1.09e-02 3.96e+00
2 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 15000 2.03e-02 4.12e+00
3 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 22500 1.84e-02 4.26e+00
4 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 30000 1.77e-02 4.21e+00
5 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 37500 1.61e-02 4.44e+00
6 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 45000 1.33e-02 4.36e+00
7 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 52500 1.70e-02 4.39e+00
8 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 60000 1.34e-02 4.39e+00
9 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 67500 1.98e-02 4.50e+00
10 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 75000 1.96e-02 4.46e+00
11 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 82500 1.70e-02 4.71e+00
12 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 90000 2.15e-02 4.64e+00
13 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 97500 1.61e-02 4.45e+00
14 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 105000 2.11e-02 4.54e+00
15 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 112500 1.86e-02 4.50e+00
16 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 120000 1.51e-02 4.70e+00
17 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 127500 1.84e-02 4.48e+00
18 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 135000 2.45e-02 4.76e+00
19 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 142500 2.90e-02 4.82e+00
20 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 6 150000 2.36e-02 4.67e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 7500 1.54e-02 4.06e+00
2 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 15000 1.75e-02 4.25e+00
3 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 22500 1.76e-02 4.27e+00
4 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 30000 2.19e-02 4.31e+00
5 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 37500 1.26e-02 4.27e+00
6 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 45000 1.33e-02 4.33e+00
7 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 52500 2.29e-02 4.47e+00
8 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 60000 1.46e-02 4.34e+00
9 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 67500 2.50e-02 4.66e+00
10 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 75000 1.88e-02 4.53e+00
11 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 82500 2.10e-02 4.35e+00
12 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 90000 2.14e-02 4.61e+00
13 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 97500 2.04e-02 4.54e+00
14 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 105000 2.12e-02 4.66e+00
15 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 112500 1.78e-02 4.64e+00
16 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 120000 1.55e-02 4.42e+00
17 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 127500 1.92e-02 4.64e+00
18 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 135000 2.79e-02 4.57e+00
19 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 142500 2.74e-02 4.79e+00
20 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 7 150000 1.38e-02 4.66e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 7500 1.62e-02 4.09e+00
2 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 15000 1.61e-02 4.03e+00
3 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 22500 2.06e-02 4.31e+00
4 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 30000 1.38e-02 4.28e+00
5 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 37500 1.88e-02 4.55e+00
6 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 45000 1.61e-02 4.47e+00
7 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 52500 1.89e-02 4.58e+00
8 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 60000 1.76e-02 4.46e+00
9 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 67500 1.94e-02 4.50e+00
10 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 75000 2.54e-02 4.53e+00
11 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 82500 2.42e-02 4.54e+00
12 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 90000 1.66e-02 4.44e+00
13 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 97500 2.19e-02 4.39e+00
14 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 105000 1.69e-02 4.55e+00
15 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 112500 2.02e-02 4.47e+00
16 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 120000 1.92e-02 4.66e+00
17 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 127500 2.38e-02 4.59e+00
18 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 135000 2.21e-02 4.59e+00
19 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 142500 2.22e-02 4.64e+00
20 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 8 150000 2.01e-02 4.66e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 7500 1.26e-02 4.01e+00
2 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 15000 1.29e-02 4.01e+00
3 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 22500 1.09e-02 4.11e+00
4 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 30000 1.30e-02 4.03e+00
5 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 37500 1.43e-02 4.19e+00
6 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 45000 1.30e-02 4.20e+00
7 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 52500 1.95e-02 4.24e+00
8 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 60000 1.85e-02 4.43e+00
9 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 67500 1.64e-02 4.30e+00
10 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 75000 1.95e-02 4.37e+00
11 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 82500 1.25e-02 4.49e+00
12 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 90000 1.35e-02 4.57e+00
13 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 97500 1.70e-02 4.39e+00
14 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 105000 1.37e-02 4.49e+00
15 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 112500 1.85e-02 4.44e+00
16 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 120000 1.63e-02 4.44e+00
17 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 127500 2.33e-02 4.55e+00
18 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 135000 2.24e-02 4.70e+00
19 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 142500 2.56e-02 4.74e+00
20 A3C 8 8 4 4 2.50e-01 False 2.50e-01 0 0 9 150000 2.02e-02 4.50e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 7500 6.65e-02 3.93e+00
2 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 15000 1.22e-01 4.60e+00
3 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 22500 1.64e-01 5.36e+00
4 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 30000 3.60e-01 6.90e+00
5 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 37500 1.37e+00 1.30e+01
6 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 45000 4.34e+00 2.93e+01
7 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 52500 8.59e+00 4.72e+01
8 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 60000 1.25e+01 5.95e+01
9 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 67500 1.54e+01 6.52e+01
10 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 75000 2.15e+01 6.60e+01
11 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 82500 3.18e+01 7.84e+01
12 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 90000 2.75e+01 7.05e+01
13 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 97500 2.55e+01 7.21e+01
14 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 105000 2.57e+01 7.91e+01
15 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 112500 1.62e+01 7.30e+01
16 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 120000 1.50e+01 7.75e+01
17 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 127500 1.19e+01 7.79e+01
18 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 135000 1.43e+01 8.46e+01
19 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 142500 1.38e+01 8.27e+01
20 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 0 150000 1.14e+01 8.32e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 7500 6.56e-02 4.01e+00
2 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 15000 1.16e-01 4.59e+00
3 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 22500 1.29e-01 5.08e+00
4 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 30000 3.13e-01 6.64e+00
5 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 37500 1.04e+00 1.13e+01
6 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 45000 3.48e+00 2.37e+01
7 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 52500 9.60e+00 4.13e+01
8 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 60000 2.10e+01 5.59e+01
9 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 67500 3.96e+01 7.31e+01
10 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 75000 5.35e+01 8.33e+01
11 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 82500 5.81e+01 8.54e+01
12 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 90000 6.31e+01 8.58e+01
13 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 97500 6.61e+01 8.86e+01
14 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 105000 6.68e+01 9.03e+01
15 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 112500 6.77e+01 9.17e+01
16 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 120000 5.66e+01 8.81e+01
17 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 127500 5.19e+01 8.83e+01
18 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 135000 4.62e+01 8.76e+01
19 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 142500 4.48e+01 9.04e+01
20 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 1 150000 5.02e+01 9.27e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 7500 5.45e-02 3.85e+00
2 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 15000 9.69e-02 4.56e+00
3 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 22500 1.40e-01 4.98e+00
4 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 30000 3.28e-01 7.07e+00
5 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 37500 1.23e+00 1.24e+01
6 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 45000 3.79e+00 2.64e+01
7 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 52500 7.92e+00 4.57e+01
8 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 60000 1.04e+01 5.75e+01
9 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 67500 1.16e+01 6.14e+01
10 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 75000 1.28e+01 6.37e+01
11 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 82500 1.30e+01 7.27e+01
12 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 90000 1.08e+01 7.09e+01
13 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 97500 1.20e+01 7.35e+01
14 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 105000 1.38e+01 7.60e+01
15 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 112500 1.29e+01 7.05e+01
16 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 120000 1.74e+01 7.97e+01
17 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 127500 1.86e+01 8.40e+01
18 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 135000 1.39e+01 7.14e+01
19 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 142500 1.56e+01 8.30e+01
20 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 2 150000 1.52e+01 7.78e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 7500 5.82e-02 4.05e+00
2 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 15000 8.84e-02 4.26e+00
3 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 22500 1.71e-01 5.04e+00
4 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 30000 3.74e-01 7.07e+00
5 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 37500 1.22e+00 1.20e+01
6 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 45000 5.00e+00 3.07e+01
7 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 52500 7.93e+00 4.50e+01
8 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 60000 9.89e+00 5.25e+01
9 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 67500 1.38e+01 6.95e+01
10 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 75000 1.47e+01 6.88e+01
11 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 82500 1.36e+01 6.65e+01
12 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 90000 1.30e+01 6.93e+01
13 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 97500 1.50e+01 7.33e+01
14 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 105000 1.42e+01 7.85e+01
15 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 112500 1.19e+01 7.47e+01
16 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 120000 1.30e+01 7.93e+01
17 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 127500 1.38e+01 7.67e+01
18 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 135000 1.69e+01 7.88e+01
19 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 142500 1.76e+01 7.52e+01
20 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 3 150000 1.64e+01 8.03e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 7500 8.06e-02 4.06e+00
2 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 15000 8.10e-02 4.43e+00
3 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 22500 1.63e-01 5.00e+00
4 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 30000 2.55e-01 6.41e+00
5 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 37500 9.01e-01 1.07e+01
6 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 45000 3.30e+00 2.39e+01
7 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 52500 7.10e+00 4.24e+01
8 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 60000 1.19e+01 5.60e+01
9 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 67500 1.97e+01 6.66e+01
10 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 75000 2.49e+01 6.93e+01
11 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 82500 3.41e+01 6.92e+01
12 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 90000 4.82e+01 7.98e+01
13 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 97500 5.77e+01 8.69e+01
14 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 105000 5.65e+01 8.71e+01
15 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 112500 5.71e+01 8.45e+01
16 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 120000 5.42e+01 8.25e+01
17 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 127500 5.63e+01 8.89e+01
18 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 135000 5.23e+01 8.89e+01
19 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 142500 4.25e+01 8.26e+01
20 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 4 150000 4.70e+01 8.99e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 7500 7.65e-02 4.00e+00
2 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 15000 6.97e-02 4.24e+00
3 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 22500 1.42e-01 5.00e+00
4 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 30000 3.34e-01 6.82e+00
5 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 37500 1.31e+00 1.34e+01
6 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 45000 3.78e+00 2.72e+01
7 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 52500 7.46e+00 4.20e+01
8 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 60000 1.06e+01 5.75e+01
9 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 67500 1.62e+01 6.48e+01
10 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 75000 1.59e+01 5.94e+01
11 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 82500 1.39e+01 6.58e+01
12 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 90000 1.22e+01 7.42e+01
13 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 97500 1.29e+01 7.41e+01
14 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 105000 1.45e+01 7.62e+01
15 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 112500 1.33e+01 8.10e+01
16 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 120000 1.32e+01 7.59e+01
17 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 127500 1.51e+01 8.00e+01
18 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 135000 1.39e+01 7.66e+01
19 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 142500 1.30e+01 7.77e+01
20 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 5 150000 1.36e+01 8.65e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 7500 6.55e-02 4.08e+00
2 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 15000 9.20e-02 4.48e+00
3 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 22500 1.76e-01 5.12e+00
4 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 30000 4.32e-01 7.23e+00
5 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 37500 1.43e+00 1.39e+01
6 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 45000 5.18e+00 3.26e+01
7 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 52500 8.22e+00 4.48e+01
8 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 60000 1.14e+01 5.70e+01
9 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 67500 1.30e+01 6.47e+01
10 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 75000 1.05e+01 6.29e+01
11 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 82500 1.18e+01 7.19e+01
12 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 90000 1.34e+01 7.40e+01
13 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 97500 1.31e+01 8.05e+01
14 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 105000 1.45e+01 7.49e+01
15 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 112500 1.26e+01 7.60e+01
16 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 120000 1.33e+01 7.76e+01
17 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 127500 1.48e+01 8.09e+01
18 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 135000 1.61e+01 8.18e+01
19 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 142500 1.52e+01 8.15e+01
20 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 6 150000 1.44e+01 7.36e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 7500 6.99e-02 4.09e+00
2 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 15000 9.13e-02 4.40e+00
3 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 22500 1.46e-01 4.97e+00
4 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 30000 2.64e-01 6.37e+00
5 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 37500 9.24e-01 1.17e+01
6 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 45000 2.85e+00 2.40e+01
7 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 52500 6.25e+00 4.29e+01
8 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 60000 8.32e+00 5.17e+01
9 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 67500 9.93e+00 6.09e+01
10 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 75000 1.10e+01 6.84e+01
11 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 82500 1.28e+01 7.11e+01
12 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 90000 1.38e+01 6.81e+01
13 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 97500 1.33e+01 7.20e+01
14 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 105000 1.62e+01 8.00e+01
15 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 112500 1.30e+01 7.47e+01
16 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 120000 1.51e+01 7.57e+01
17 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 127500 1.71e+01 7.59e+01
18 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 135000 1.84e+01 7.87e+01
19 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 142500 1.76e+01 7.92e+01
20 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 7 150000 1.95e+01 8.12e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 7500 7.62e-02 4.23e+00
2 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 15000 1.01e-01 4.48e+00
3 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 22500 9.92e-02 4.77e+00
4 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 30000 2.36e-01 6.03e+00
5 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 37500 6.94e-01 9.77e+00
6 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 45000 2.13e+00 1.91e+01
7 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 52500 6.20e+00 4.05e+01
8 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 60000 9.86e+00 5.69e+01
9 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 67500 1.02e+01 5.96e+01
10 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 75000 1.22e+01 6.70e+01
11 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 82500 1.30e+01 6.99e+01
12 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 90000 1.15e+01 6.95e+01
13 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 97500 1.27e+01 7.65e+01
14 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 105000 1.04e+01 7.17e+01
15 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 112500 1.14e+01 7.81e+01
16 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 120000 1.15e+01 7.78e+01
17 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 127500 1.28e+01 8.01e+01
18 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 135000 1.38e+01 8.22e+01
19 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 142500 1.27e+01 7.94e+01
20 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 8 150000 1.40e+01 8.02e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 7500 8.48e-02 4.20e+00
2 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 15000 8.83e-02 4.37e+00
3 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 22500 1.89e-01 5.25e+00
4 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 30000 3.93e-01 7.40e+00
5 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 37500 1.45e+00 1.42e+01
6 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 45000 3.96e+00 2.95e+01
7 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 52500 5.90e+00 3.74e+01
8 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 60000 9.76e+00 5.83e+01
9 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 67500 1.11e+01 6.52e+01
10 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 75000 1.35e+01 7.40e+01
11 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 82500 1.34e+01 6.81e+01
12 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 90000 1.43e+01 7.27e+01
13 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 97500 1.20e+01 6.84e+01
14 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 105000 1.42e+01 7.71e+01
15 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 112500 1.42e+01 7.39e+01
16 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 120000 1.35e+01 7.71e+01
17 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 127500 1.40e+01 8.18e+01
18 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 135000 1.28e+01 7.63e+01
19 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 142500 1.27e+01 7.85e+01
20 A3C 8 8 8 1 2.50e-01 False 2.50e-01 0 0 9 150000 1.28e+01 7.94e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 7500 3.93e-02 3.99e+00
2 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 15000 4.33e-02 4.21e+00
3 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 22500 4.12e-02 4.43e+00
4 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 30000 4.93e-02 4.56e+00
5 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 37500 6.17e-02 4.98e+00
6 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 45000 9.03e-02 5.54e+00
7 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 52500 1.63e-01 6.51e+00
8 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 60000 3.49e-01 8.97e+00
9 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 67500 7.97e-01 1.53e+01
10 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 75000 2.18e+00 2.74e+01
11 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 82500 4.48e+00 4.35e+01
12 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 90000 6.05e+00 5.68e+01
13 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 97500 7.62e+00 6.77e+01
14 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 105000 7.35e+00 7.04e+01
15 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 112500 8.15e+00 7.51e+01
16 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 120000 8.55e+00 7.85e+01
17 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 127500 7.85e+00 7.51e+01
18 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 135000 7.70e+00 8.00e+01
19 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 142500 7.61e+00 7.28e+01
20 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 0 150000 8.02e+00 8.04e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 7500 3.33e-02 4.08e+00
2 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 15000 3.99e-02 4.25e+00
3 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 22500 5.44e-02 4.65e+00
4 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 30000 7.15e-02 5.24e+00
5 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 37500 1.07e-01 5.71e+00
6 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 45000 1.77e-01 6.82e+00
7 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 52500 3.92e-01 1.00e+01
8 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 60000 1.28e+00 1.86e+01
9 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 67500 2.41e+00 3.28e+01
10 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 75000 4.04e+00 4.58e+01
11 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 82500 6.31e+00 6.30e+01
12 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 90000 6.88e+00 6.55e+01
13 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 97500 7.32e+00 7.11e+01
14 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 105000 7.26e+00 7.26e+01
15 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 112500 7.07e+00 7.26e+01
16 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 120000 8.25e+00 7.97e+01
17 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 127500 8.46e+00 8.07e+01
18 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 135000 8.26e+00 7.86e+01
19 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 142500 7.79e+00 7.90e+01
20 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 1 150000 8.57e+00 8.29e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 7500 4.16e-02 4.11e+00
2 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 15000 4.07e-02 4.07e+00
3 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 22500 5.37e-02 4.53e+00
4 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 30000 6.71e-02 4.89e+00
5 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 37500 8.41e-02 5.19e+00
6 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 45000 1.08e-01 5.98e+00
7 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 52500 1.93e-01 7.32e+00
8 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 60000 4.80e-01 1.09e+01
9 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 67500 1.41e+00 2.06e+01
10 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 75000 2.82e+00 3.53e+01
11 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 82500 4.37e+00 4.91e+01
12 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 90000 5.73e+00 5.88e+01
13 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 97500 6.45e+00 6.49e+01
14 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 105000 7.49e+00 7.34e+01
15 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 112500 8.29e+00 7.80e+01
16 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 120000 8.54e+00 7.90e+01
17 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 127500 7.53e+00 7.48e+01
18 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 135000 8.46e+00 8.24e+01
19 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 142500 8.44e+00 7.95e+01
20 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 2 150000 7.97e+00 7.82e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 7500 3.08e-02 4.03e+00
2 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 15000 3.55e-02 4.22e+00
3 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 22500 4.29e-02 4.44e+00
4 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 30000 4.62e-02 4.49e+00
5 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 37500 6.37e-02 4.85e+00
6 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 45000 8.32e-02 5.41e+00
7 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 52500 1.87e-01 6.59e+00
8 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 60000 5.06e-01 1.08e+01
9 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 67500 1.39e+00 2.08e+01
10 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 75000 3.04e+00 3.82e+01
11 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 82500 3.59e+00 4.51e+01
12 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 90000 6.29e+00 6.90e+01
13 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 97500 6.46e+00 6.78e+01
14 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 105000 5.93e+00 6.95e+01
15 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 112500 6.75e+00 7.45e+01
16 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 120000 7.29e+00 8.41e+01
17 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 127500 7.81e+00 8.05e+01
18 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 135000 7.82e+00 8.23e+01
19 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 142500 7.98e+00 8.20e+01
20 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 3 150000 8.19e+00 8.35e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 7500 3.44e-02 4.00e+00
2 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 15000 3.73e-02 4.25e+00
3 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 22500 4.91e-02 4.64e+00
4 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 30000 5.46e-02 4.77e+00
5 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 37500 6.17e-02 4.84e+00
6 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 45000 9.72e-02 5.43e+00
7 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 52500 1.77e-01 7.11e+00
8 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 60000 3.77e-01 9.67e+00
9 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 67500 1.02e+00 1.75e+01
10 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 75000 2.80e+00 3.54e+01
11 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 82500 4.33e+00 4.79e+01
12 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 90000 5.77e+00 6.19e+01
13 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 97500 6.11e+00 6.62e+01
14 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 105000 7.28e+00 7.17e+01
15 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 112500 6.97e+00 7.22e+01
16 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 120000 7.77e+00 7.44e+01
17 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 127500 8.36e+00 7.68e+01
18 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 135000 8.17e+00 8.02e+01
19 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 142500 8.16e+00 8.09e+01
20 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 4 150000 6.86e+00 7.34e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 7500 2.33e-02 3.99e+00
2 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 15000 3.98e-02 4.06e+00
3 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 22500 5.15e-02 4.44e+00
4 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 30000 6.30e-02 4.58e+00
5 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 37500 6.69e-02 5.11e+00
6 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 45000 1.41e-01 6.03e+00
7 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 52500 2.36e-01 7.51e+00
8 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 60000 6.81e-01 1.33e+01
9 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 67500 1.76e+00 2.43e+01
10 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 75000 3.71e+00 4.39e+01
11 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 82500 4.94e+00 5.20e+01
12 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 90000 6.26e+00 6.46e+01
13 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 97500 6.15e+00 6.69e+01
14 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 105000 6.94e+00 7.11e+01
15 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 112500 7.67e+00 7.40e+01
16 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 120000 7.24e+00 7.54e+01
17 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 127500 7.95e+00 7.94e+01
18 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 135000 7.20e+00 7.37e+01
19 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 142500 7.51e+00 7.80e+01
20 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 5 150000 7.81e+00 7.94e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 7500 3.19e-02 3.98e+00
2 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 15000 4.27e-02 4.20e+00
3 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 22500 4.54e-02 4.35e+00
4 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 30000 6.41e-02 4.80e+00
5 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 37500 9.10e-02 5.27e+00
6 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 45000 1.16e-01 6.05e+00
7 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 52500 2.18e-01 7.49e+00
8 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 60000 5.31e-01 1.17e+01
9 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 67500 1.73e+00 2.25e+01
10 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 75000 3.41e+00 3.96e+01
11 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 82500 4.39e+00 5.02e+01
12 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 90000 6.31e+00 6.67e+01
13 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 97500 5.98e+00 6.87e+01
14 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 105000 7.05e+00 7.02e+01
15 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 112500 7.12e+00 7.05e+01
16 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 120000 8.24e+00 8.01e+01
17 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 127500 7.56e+00 7.75e+01
18 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 135000 8.10e+00 7.92e+01
19 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 142500 8.74e+00 8.26e+01
20 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 6 150000 7.43e+00 7.74e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 7500 2.99e-02 3.89e+00
2 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 15000 4.36e-02 4.33e+00
3 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 22500 3.60e-02 4.40e+00
4 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 30000 6.83e-02 4.92e+00
5 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 37500 8.02e-02 5.35e+00
6 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 45000 1.79e-01 6.77e+00
7 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 52500 4.43e-01 1.05e+01
8 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 60000 9.53e-01 1.67e+01
9 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 67500 2.64e+00 3.34e+01
10 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 75000 4.27e+00 4.70e+01
11 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 82500 5.46e+00 6.25e+01
12 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 90000 5.11e+00 5.84e+01
13 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 97500 6.74e+00 7.03e+01
14 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 105000 6.57e+00 7.13e+01
15 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 112500 7.70e+00 7.77e+01
16 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 120000 7.45e+00 7.35e+01
17 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 127500 7.51e+00 7.85e+01
18 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 135000 7.60e+00 7.91e+01
19 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 142500 6.71e+00 7.68e+01
20 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 7 150000 8.03e+00 8.29e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 7500 3.12e-02 3.98e+00
2 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 15000 4.34e-02 4.26e+00
3 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 22500 5.27e-02 4.48e+00
4 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 30000 6.36e-02 4.71e+00
5 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 37500 8.15e-02 5.06e+00
6 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 45000 1.01e-01 5.74e+00
7 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 52500 1.76e-01 7.08e+00
8 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 60000 3.75e-01 9.35e+00
9 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 67500 8.97e-01 1.61e+01
10 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 75000 2.36e+00 3.00e+01
11 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 82500 3.55e+00 4.34e+01
12 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 90000 5.54e+00 6.01e+01
13 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 97500 6.26e+00 6.26e+01
14 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 105000 6.67e+00 6.63e+01
15 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 112500 8.33e+00 7.54e+01
16 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 120000 8.02e+00 7.78e+01
17 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 127500 8.75e+00 8.05e+01
18 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 135000 9.02e+00 8.23e+01
19 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 142500 7.26e+00 7.22e+01
20 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 8 150000 8.39e+00 7.87e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 7500 4.40e-02 4.08e+00
2 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 15000 4.74e-02 4.40e+00
3 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 22500 3.65e-02 4.39e+00
4 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 30000 5.73e-02 4.82e+00
5 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 37500 6.32e-02 4.86e+00
6 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 45000 8.97e-02 5.71e+00
7 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 52500 1.42e-01 6.36e+00
8 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 60000 2.83e-01 8.19e+00
9 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 67500 5.79e-01 1.29e+01
10 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 75000 1.69e+00 2.39e+01
11 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 82500 3.77e+00 4.29e+01
12 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 90000 4.55e+00 5.12e+01
13 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 97500 6.10e+00 6.29e+01
14 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 105000 6.71e+00 6.84e+01
15 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 112500 6.79e+00 6.85e+01
16 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 120000 7.27e+00 7.47e+01
17 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 127500 7.62e+00 7.88e+01
18 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 135000 6.85e+00 7.20e+01
19 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 142500 7.85e+00 8.18e+01
20 A3C 8 8 8 2 2.50e-01 False 2.50e-01 0 0 9 150000 7.99e+00 8.42e+01
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 7500 1.25e-02 4.14e+00
2 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 15000 1.54e-02 4.14e+00
3 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 22500 2.27e-02 4.14e+00
4 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 30000 1.73e-02 4.35e+00
5 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 37500 1.89e-02 4.26e+00
6 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 45000 2.45e-02 4.55e+00
7 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 52500 1.94e-02 4.54e+00
8 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 60000 2.01e-02 4.52e+00
9 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 67500 2.03e-02 4.49e+00
10 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 75000 2.16e-02 4.66e+00
11 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 82500 1.82e-02 4.56e+00
12 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 90000 3.01e-02 4.77e+00
13 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 97500 1.79e-02 4.64e+00
14 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 105000 2.76e-02 4.62e+00
15 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 112500 2.69e-02 4.78e+00
16 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 120000 2.23e-02 4.79e+00
17 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 127500 2.46e-02 4.62e+00
18 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 135000 1.80e-02 4.60e+00
19 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 142500 2.41e-02 4.48e+00
20 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 0 150000 2.41e-02 4.61e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 7500 1.34e-02 3.92e+00
2 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 15000 1.39e-02 4.05e+00
3 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 22500 1.83e-02 4.11e+00
4 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 30000 1.44e-02 4.18e+00
5 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 37500 1.35e-02 4.04e+00
6 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 45000 1.60e-02 4.24e+00
7 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 52500 1.38e-02 4.34e+00
8 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 60000 1.70e-02 4.25e+00
9 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 67500 1.76e-02 4.39e+00
10 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 75000 1.74e-02 4.34e+00
11 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 82500 2.50e-02 4.85e+00
12 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 90000 2.91e-02 4.62e+00
13 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 97500 2.72e-02 4.74e+00
14 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 105000 3.14e-02 4.88e+00
15 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 112500 2.76e-02 4.95e+00
16 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 120000 2.19e-02 4.66e+00
17 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 127500 2.67e-02 4.70e+00
18 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 135000 2.89e-02 4.82e+00
19 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 142500 2.48e-02 4.84e+00
20 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 1 150000 3.04e-02 5.01e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 7500 1.62e-02 4.11e+00
2 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 15000 2.19e-02 4.32e+00
3 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 22500 1.80e-02 4.33e+00
4 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 30000 1.46e-02 4.39e+00
5 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 37500 1.80e-02 4.67e+00
6 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 45000 2.19e-02 4.37e+00
7 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 52500 2.56e-02 4.48e+00
8 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 60000 2.05e-02 4.58e+00
9 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 67500 1.78e-02 4.55e+00
10 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 75000 1.39e-02 4.34e+00
11 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 82500 2.01e-02 4.62e+00
12 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 90000 2.04e-02 4.48e+00
13 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 97500 1.76e-02 4.51e+00
14 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 105000 1.56e-02 4.58e+00
15 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 112500 2.67e-02 4.80e+00
16 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 120000 2.03e-02 4.40e+00
17 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 127500 2.57e-02 4.80e+00
18 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 135000 2.20e-02 4.58e+00
19 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 142500 2.15e-02 4.49e+00
20 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 2 150000 1.70e-02 4.39e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 7500 7.80e-03 3.96e+00
2 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 15000 9.97e-03 3.93e+00
3 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 22500 1.66e-02 4.03e+00
4 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 30000 1.83e-02 4.16e+00
5 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 37500 2.40e-02 4.49e+00
6 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 45000 1.14e-02 4.27e+00
7 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 52500 1.15e-02 4.27e+00
8 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 60000 2.30e-02 4.45e+00
9 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 67500 1.92e-02 4.49e+00
10 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 75000 2.57e-02 4.64e+00
11 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 82500 2.47e-02 4.71e+00
12 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 90000 3.59e-02 4.72e+00
13 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 97500 3.36e-02 4.89e+00
14 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 105000 2.04e-02 4.74e+00
15 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 112500 2.86e-02 4.80e+00
16 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 120000 2.27e-02 4.71e+00
17 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 127500 2.61e-02 4.63e+00
18 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 135000 2.01e-02 4.46e+00
19 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 142500 2.37e-02 4.69e+00
20 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 3 150000 2.84e-02 4.76e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 7500 1.08e-02 3.93e+00
2 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 15000 1.30e-02 4.06e+00
3 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 22500 2.31e-02 4.24e+00
4 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 30000 1.75e-02 4.23e+00
5 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 37500 1.02e-02 4.21e+00
6 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 45000 1.47e-02 4.27e+00
7 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 52500 1.73e-02 4.35e+00
8 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 60000 1.79e-02 4.42e+00
9 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 67500 2.42e-02 4.45e+00
10 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 75000 1.87e-02 4.49e+00
11 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 82500 2.64e-02 4.60e+00
12 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 90000 2.18e-02 4.59e+00
13 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 97500 1.97e-02 4.43e+00
14 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 105000 2.23e-02 4.81e+00
15 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 112500 1.73e-02 4.60e+00
16 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 120000 3.00e-02 4.59e+00
17 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 127500 1.79e-02 4.45e+00
18 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 135000 1.64e-02 4.59e+00
19 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 142500 2.31e-02 4.66e+00
20 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 4 150000 2.14e-02 4.61e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 7500 1.15e-02 4.03e+00
2 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 15000 1.20e-02 3.96e+00
3 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 22500 1.38e-02 4.21e+00
4 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 30000 1.52e-02 4.22e+00
5 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 37500 2.42e-02 4.44e+00
6 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 45000 1.49e-02 4.27e+00
7 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 52500 1.57e-02 4.54e+00
8 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 60000 2.53e-02 4.53e+00
9 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 67500 1.54e-02 4.42e+00
10 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 75000 1.99e-02 4.40e+00
11 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 82500 2.22e-02 4.55e+00
12 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 90000 1.86e-02 4.50e+00
13 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 97500 2.44e-02 4.54e+00
14 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 105000 2.22e-02 4.48e+00
15 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 112500 2.35e-02 4.63e+00
16 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 120000 3.20e-02 4.82e+00
17 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 127500 2.19e-02 4.56e+00
18 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 135000 2.16e-02 4.89e+00
19 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 142500 2.05e-02 4.66e+00
20 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 5 150000 1.62e-02 4.50e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 7500 1.60e-02 4.08e+00
2 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 15000 2.13e-02 4.11e+00
3 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 22500 1.35e-02 4.20e+00
4 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 30000 2.10e-02 4.50e+00
5 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 37500 2.84e-02 4.52e+00
6 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 45000 2.85e-02 4.64e+00
7 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 52500 3.77e-02 5.05e+00
8 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 60000 3.55e-02 5.08e+00
9 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 67500 3.05e-02 4.94e+00
10 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 75000 2.66e-02 4.84e+00
11 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 82500 4.46e-02 5.08e+00
12 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 90000 2.29e-02 5.00e+00
13 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 97500 3.50e-02 5.18e+00
14 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 105000 1.78e-02 4.80e+00
15 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 112500 2.57e-02 4.89e+00
16 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 120000 2.09e-02 4.60e+00
17 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 127500 2.82e-02 4.69e+00
18 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 135000 3.00e-02 4.92e+00
19 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 142500 2.51e-02 4.86e+00
20 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 6 150000 2.60e-02 4.84e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 7500 1.86e-02 4.04e+00
2 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 15000 9.68e-03 4.03e+00
3 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 22500 1.45e-02 4.05e+00
4 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 30000 1.08e-02 4.22e+00
5 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 37500 1.79e-02 4.18e+00
6 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 45000 1.26e-02 4.28e+00
7 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 52500 1.57e-02 4.38e+00
8 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 60000 2.39e-02 4.47e+00
9 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 67500 2.19e-02 4.67e+00
10 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 75000 1.24e-02 4.47e+00
11 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 82500 1.40e-02 4.44e+00
12 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 90000 1.72e-02 4.40e+00
13 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 97500 1.83e-02 4.38e+00
14 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 105000 1.87e-02 4.42e+00
15 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 112500 2.19e-02 4.46e+00
16 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 120000 2.64e-02 4.46e+00
17 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 127500 2.24e-02 4.82e+00
18 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 135000 1.76e-02 4.56e+00
19 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 142500 1.92e-02 4.51e+00
20 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 7 150000 2.37e-02 4.66e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 7500 2.10e-02 3.96e+00
2 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 15000 1.09e-02 4.25e+00
3 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 22500 1.76e-02 4.25e+00
4 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 30000 1.36e-02 4.10e+00
5 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 37500 2.44e-02 4.44e+00
6 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 45000 1.65e-02 4.43e+00
7 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 52500 2.49e-02 4.52e+00
8 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 60000 1.82e-02 4.55e+00
9 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 67500 2.12e-02 4.64e+00
10 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 75000 2.18e-02 4.60e+00
11 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 82500 2.13e-02 4.67e+00
12 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 90000 1.95e-02 4.59e+00
13 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 97500 2.02e-02 4.57e+00
14 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 105000 1.95e-02 4.56e+00
15 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 112500 2.76e-02 4.71e+00
16 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 120000 3.32e-02 4.87e+00
17 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 127500 3.27e-02 5.16e+00
18 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 135000 2.88e-02 4.90e+00
19 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 142500 2.83e-02 4.68e+00
20 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 8 150000 2.37e-02 4.57e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 7500 1.02e-02 3.94e+00
2 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 15000 1.52e-02 3.89e+00
3 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 22500 1.06e-02 4.16e+00
4 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 30000 1.42e-02 4.32e+00
5 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 37500 1.66e-02 4.42e+00
6 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 45000 1.23e-02 4.25e+00
7 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 52500 1.37e-02 4.41e+00
8 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 60000 1.71e-02 4.44e+00
9 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 67500 2.80e-02 4.40e+00
10 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 75000 1.77e-02 4.44e+00
11 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 82500 3.10e-02 4.61e+00
12 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 90000 2.04e-02 4.55e+00
13 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 97500 3.01e-02 4.88e+00
14 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 105000 2.37e-02 4.67e+00
15 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 112500 2.17e-02 4.78e+00
16 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 120000 1.79e-02 4.68e+00
17 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 127500 1.66e-02 4.54e+00
18 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 135000 2.04e-02 4.55e+00
19 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 142500 2.75e-02 4.74e+00
20 A3C 8 8 8 3 2.50e-01 False 2.50e-01 0 0 9 150000 2.88e-02 4.72e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 7500 4.26e-03 4.04e+00
2 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 15000 6.13e-03 4.19e+00
3 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 22500 4.36e-03 4.07e+00
4 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 30000 4.95e-03 4.13e+00
5 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 37500 3.85e-03 4.09e+00
6 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 45000 5.43e-03 4.10e+00
7 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 52500 5.34e-03 4.03e+00
8 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 60000 7.07e-03 4.08e+00
9 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 67500 5.15e-03 4.28e+00
10 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 75000 6.66e-03 4.19e+00
11 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 82500 4.79e-03 3.97e+00
12 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 90000 5.48e-03 4.11e+00
13 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 97500 4.46e-03 4.16e+00
14 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 105000 4.34e-03 4.09e+00
15 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 112500 8.32e-03 4.15e+00
16 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 120000 6.24e-03 4.21e+00
17 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 127500 4.99e-03 4.22e+00
18 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 135000 8.45e-03 4.26e+00
19 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 142500 4.11e-03 4.35e+00
20 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 0 150000 4.97e-03 4.14e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 7500 4.47e-03 3.81e+00
2 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 15000 3.27e-03 4.04e+00
3 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 22500 5.86e-03 3.99e+00
4 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 30000 3.80e-03 4.08e+00
5 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 37500 4.79e-03 3.96e+00
6 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 45000 7.14e-03 4.15e+00
7 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 52500 2.17e-03 4.02e+00
8 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 60000 3.85e-03 4.15e+00
9 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 67500 3.85e-03 4.12e+00
10 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 75000 5.40e-03 4.11e+00
11 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 82500 4.61e-03 4.26e+00
12 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 90000 4.46e-03 4.22e+00
13 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 97500 4.49e-03 4.15e+00
14 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 105000 3.16e-03 4.00e+00
15 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 112500 3.24e-03 4.04e+00
16 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 120000 7.94e-03 4.29e+00
17 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 127500 5.96e-03 4.01e+00
18 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 135000 6.16e-03 4.20e+00
19 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 142500 7.34e-03 4.27e+00
20 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 1 150000 5.36e-03 4.00e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 7500 4.09e-03 3.88e+00
2 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 15000 4.29e-03 4.01e+00
3 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 22500 3.79e-03 4.10e+00
4 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 30000 3.62e-03 3.88e+00
5 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 37500 3.45e-03 4.27e+00
6 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 45000 4.96e-03 4.17e+00
7 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 52500 5.54e-03 4.16e+00
8 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 60000 2.13e-03 4.02e+00
9 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 67500 2.19e-03 4.08e+00
10 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 75000 2.74e-03 4.11e+00
11 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 82500 5.05e-03 4.20e+00
12 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 90000 1.63e-03 4.10e+00
13 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 97500 4.87e-03 4.07e+00
14 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 105000 3.90e-03 4.17e+00
15 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 112500 2.16e-03 4.06e+00
16 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 120000 2.71e-03 4.05e+00
17 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 127500 2.72e-03 4.12e+00
18 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 135000 6.22e-03 4.22e+00
19 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 142500 7.14e-03 4.09e+00
20 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 2 150000 5.63e-03 4.26e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 7500 6.42e-03 4.08e+00
2 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 15000 7.27e-03 4.19e+00
3 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 22500 3.88e-03 4.19e+00
4 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 30000 4.86e-03 4.04e+00
5 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 37500 5.42e-03 4.07e+00
6 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 45000 3.47e-03 4.30e+00
7 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 52500 2.75e-03 4.13e+00
8 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 60000 8.32e-03 4.17e+00
9 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 67500 7.86e-03 4.25e+00
10 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 75000 4.57e-03 4.25e+00
11 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 82500 3.27e-03 4.06e+00
12 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 90000 5.44e-03 4.13e+00
13 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 97500 6.48e-03 4.01e+00
14 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 105000 4.49e-03 4.21e+00
15 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 112500 4.31e-03 4.05e+00
16 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 120000 3.76e-03 4.08e+00
17 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 127500 4.44e-03 4.10e+00
18 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 135000 5.97e-03 4.07e+00
19 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 142500 4.35e-03 4.08e+00
20 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 3 150000 6.09e-03 4.19e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 7500 4.68e-03 3.93e+00
2 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 15000 3.78e-03 4.07e+00
3 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 22500 3.23e-03 4.08e+00
4 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 30000 5.52e-03 4.14e+00
5 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 37500 7.32e-03 4.17e+00
6 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 45000 4.89e-03 4.07e+00
7 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 52500 4.84e-03 4.02e+00
8 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 60000 5.46e-03 4.14e+00
9 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 67500 4.38e-03 4.10e+00
10 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 75000 4.25e-03 4.00e+00
11 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 82500 3.77e-03 4.04e+00
12 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 90000 5.05e-03 4.18e+00
13 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 97500 4.55e-03 4.28e+00
14 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 105000 5.56e-03 4.13e+00
15 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 112500 3.83e-03 4.14e+00
16 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 120000 8.86e-03 4.13e+00
17 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 127500 3.29e-03 4.11e+00
18 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 135000 2.26e-03 4.25e+00
19 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 142500 3.80e-03 4.07e+00
20 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 4 150000 6.46e-03 4.07e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 7500 3.20e-03 4.04e+00
2 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 15000 1.64e-03 4.14e+00
3 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 22500 7.20e-03 4.15e+00
4 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 30000 2.72e-03 4.06e+00
5 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 37500 7.45e-03 4.01e+00
6 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 45000 3.88e-03 4.14e+00
7 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 52500 4.89e-03 4.08e+00
8 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 60000 5.40e-03 4.07e+00
9 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 67500 4.85e-03 4.06e+00
10 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 75000 3.85e-03 4.10e+00
11 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 82500 5.59e-03 4.19e+00
12 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 90000 1.69e-03 4.20e+00
13 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 97500 3.43e-03 4.30e+00
14 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 105000 5.60e-03 4.20e+00
15 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 112500 3.31e-03 4.14e+00
16 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 120000 3.39e-03 4.22e+00
17 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 127500 6.64e-03 4.16e+00
18 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 135000 3.20e-03 4.02e+00
19 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 142500 3.36e-03 4.18e+00
20 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 5 150000 2.75e-03 4.14e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 7500 4.31e-03 4.10e+00
2 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 15000 4.32e-03 4.09e+00
3 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 22500 3.29e-03 4.05e+00
4 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 30000 6.16e-03 4.26e+00
5 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 37500 6.76e-03 4.18e+00
6 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 45000 4.39e-03 4.13e+00
7 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 52500 5.56e-03 4.19e+00
8 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 60000 3.81e-03 4.04e+00
9 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 67500 3.34e-03 4.16e+00
10 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 75000 4.29e-03 4.05e+00
11 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 82500 7.20e-03 4.13e+00
12 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 90000 4.41e-03 4.14e+00
13 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 97500 4.20e-03 3.94e+00
14 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 105000 7.92e-03 4.21e+00
15 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 112500 6.12e-03 4.21e+00
16 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 120000 2.20e-03 4.12e+00
17 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 127500 6.85e-03 4.29e+00
18 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 135000 4.47e-03 4.16e+00
19 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 142500 3.33e-03 4.20e+00
20 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 6 150000 2.77e-03 4.13e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 7500 6.29e-03 3.99e+00
2 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 15000 2.08e-03 3.90e+00
3 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 22500 5.72e-03 4.27e+00
4 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 30000 2.66e-03 3.99e+00
5 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 37500 5.85e-03 4.04e+00
6 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 45000 4.52e-03 4.17e+00
7 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 52500 3.20e-03 4.01e+00
8 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 60000 2.77e-03 4.13e+00
9 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 67500 7.85e-03 4.22e+00
10 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 75000 3.88e-03 4.15e+00
11 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 82500 6.02e-03 4.13e+00
12 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 90000 5.31e-03 3.99e+00
13 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 97500 4.37e-03 4.10e+00
14 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 105000 6.84e-03 4.24e+00
15 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 112500 2.74e-03 4.09e+00
16 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 120000 6.70e-03 4.24e+00
17 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 127500 6.04e-03 4.11e+00
18 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 135000 2.15e-03 4.03e+00
19 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 142500 3.86e-03 4.11e+00
20 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 7 150000 5.44e-03 4.11e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 7500 2.61e-03 3.97e+00
2 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 15000 5.45e-03 4.06e+00
3 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 22500 4.92e-03 4.11e+00
4 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 30000 4.00e-03 4.32e+00
5 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 37500 2.81e-03 4.18e+00
6 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 45000 5.62e-03 4.23e+00
7 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 52500 5.04e-03 4.24e+00
8 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 60000 3.38e-03 4.17e+00
9 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 67500 6.06e-03 4.17e+00
10 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 75000 6.39e-03 4.33e+00
11 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 82500 2.68e-03 4.07e+00
12 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 90000 3.35e-03 4.17e+00
13 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 97500 1.70e-03 4.23e+00
14 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 105000 3.21e-03 4.01e+00
15 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 112500 6.10e-03 4.15e+00
16 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 120000 3.23e-03 4.10e+00
17 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 127500 7.32e-03 4.21e+00
18 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 135000 2.25e-03 4.17e+00
19 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 142500 3.89e-03 4.17e+00
20 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 8 150000 3.69e-03 3.98e+00
# training_iteration, algorithm, state_space_size, action_space_size, delay, sequence_length, reward_density, make_denser, terminal_state_density, transition_noise, reward_noise, dummy_seed, timesteps_total, episode_reward_mean, episode_len_mean
1 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 7500 4.21e-03 3.99e+00
2 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 15000 4.82e-03 4.01e+00
3 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 22500 4.25e-03 3.97e+00
4 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 30000 5.90e-03 4.04e+00
5 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 37500 3.24e-03 4.06e+00
6 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 45000 5.62e-03 4.21e+00
7 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 52500 4.77e-03 4.03e+00
8 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 60000 7.99e-03 4.22e+00
9 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 67500 5.95e-03 4.07e+00
10 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 75000 3.83e-03 4.10e+00
11 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 82500 4.93e-03 4.11e+00
12 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 90000 7.99e-03 4.27e+00
13 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 97500 5.01e-03 4.18e+00
14 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 105000 7.68e-03 4.15e+00
15 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 112500 8.04e-03 4.31e+00
16 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 120000 4.60e-03 4.25e+00
17 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 127500 2.67e-03 4.01e+00
18 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 135000 2.77e-03 4.20e+00
19 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 142500 3.20e-03 3.97e+00
20 A3C 8 8 8 4 2.50e-01 False 2.50e-01 0 0 9 150000 4.75e-03 4.01e+00
