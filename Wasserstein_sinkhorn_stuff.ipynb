{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1) (3, 2) (3, 1) (3, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import grad\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "dtype    = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "\n",
    "from geomloss import SamplesLoss\n",
    "# from pykeops.torch.cluster import grid_cluster, cluster_ranges_centroids\n",
    "\n",
    "num_points = 3\n",
    "num_dims = 2\n",
    "A_i = np.random.rand(num_points, 1)\n",
    "A_i = A_i / np.sum(A_i)\n",
    "X_i = np.random.rand(num_points, num_dims) - np.ones((num_points, num_dims))/2\n",
    "B_j = np.random.rand(num_points, 1)\n",
    "B_j = B_j / np.sum(B_j)\n",
    "Y_j = np.random.rand(num_points, num_dims) - np.ones((num_points, num_dims))/2\n",
    "\n",
    "print(A_i.shape, X_i.shape, B_j.shape, Y_j.shape)\n",
    "\n",
    "#plot variations across num_points, num_dims, p = 1 or 2, blur, diameter,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sinkhorn divergences over coarse clusters. blur, cluster_scale = 0.125 0.1\n",
      "3x3 clusters, computed at scale = 0.100\n",
      "Successive scales :  1.000, 1.000, 0.500, 0.250, 0.125\n",
      "Extrapolate from coarse to fine after the last iteration.\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) None None None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) None None None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) None None None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) None None None\n",
      "loss_p1 = tensor(0.4851, grad_fn=<AddBackward0>) loss_p2 = tensor(0.0697)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAKACAYAAACBhdleAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de5TfZWHn8c+ThNyJikS5lnihUsALzaBgQbtbbKVbxd1qlXULBY66smzdpbbS2nV3tbQqKnrU461uF209FbC2HLGlgor1cKkToO4CBQLLTVFiRQmZ3PPsH9+hDXGSTDLP7zK/vF7nzJn5zfc7z/McvidD3vlefqXWGgAAAGZuzqAXAAAAMCoEFgAAQCMCCwAAoBGBBQAA0IjAAgAAaGTeoBewMwceeGBdsWLFoJcBAADwBKtWrfpBrXX5VNuGNrBWrFiR8fHxQS8DAADgCUop9+1sm0sEAQAAGhFYAAAAjQgsAACARgQWAABAIwILAACgEYEFAADQiMACAABoRGABAAA0IrAAAAAaEVgAAACNCCwAAIBGBBYAAEAjAgsAAKARgQUAANCIwAIAAGhEYAEAADQisAAAABoRWAAAAI0ILAAAgEYEFgAAQCMCCwAAoBGBBQAA0Mi8QS8A6LF7702+9KXkG99I7rgj2bIlefKTk5NOSl7ykuSXfimZ51cBAEAL/lYFo+rb307e8pbkhhu61xs2PHH7DTckH/tYF1dvfWvy27+d7Ldf/9cJADBCXCIIo2bbtuS///fkhBOSa6/twmrHuHp8v7Vrk0ceSS68MDnmmOS22/q/XgCAESKwYJRs25acfnryvvcl69cntU7v5yYmktWruygbH+/tGgEARpjAglHyu7/b3W81MbHnP1trd0brlFOShx5qvzYAgH2AwIJR8a1vJR/+8N7F1fYmJpIzzpj+2S8AAP6ZwIJR8aY3dZcFztTmzcn11ydf//rMxwIA2McILBgF//f/Jv/4j+3GW7cuueiiduMBAOwjBBaMgs9/vjvz1NLVVycbN7YdEwBgxAksGAXf+Eb3BsItLVzYnRkDAGDaBBaMgjvv7M24d9zRm3EBAEaUwIJR0PrywKR7Ty2XCAIA7BGBBaNgyZL2Y86dmyxb1n5cAIARJrBgFBx3XPsxt2xJnv/89uMCAIwwgQWj4JRTkkWL2o45Z07yrGe1HRMAYMQJLBgFr3tdUmu78fbbLznrrKSUdmMCAOwDBBaMggMPTP7tv03mz28z3rx5yVve0mYsAIB9iMCCUfGhD7W5THDx4uS3fsvlgQAAe0FgwahYvjz5sz+bWWQtWJA85znJO97Rbl0AAPsQgQWj5N/8m+TTn967yFq0KDnqqORrX+vuwQIAYI8JLBg1p5+eXHttcsQR03t/rLlzu7h685uTG25InvSk3q8RAGBECSwYRccfn9xxR/KBDyTPfGYXUMuWdQ+vmDPnX14vXNgF2Y03Ju9/f/caAIC9Nm/QCwB6ZMGC5I1vTN7whuT++5NVq5K77+7eQPjJT+7enPj5z2///lkAAPswgQWjrpTucsEjjhj0SgAARp5LBAEAABoRWAAAAI0ILAAAgEaaBFYp5eWllDtKKatLKRfsYr9Xl1JqKWWsxbwAAADDZMaBVUqZm+SjSU5NcnSS00spR0+x3/5JfjPJjTOdEwAAYBi1OIP1wiSra6331Fo3JfnzJKdNsd+7krw3yYYGcwIAAAydFoF1aJIHtnv94OT3/lkp5bgkh9dav9RgPgAAgKHUIrDKFN+r/7yxlDlJLk7yW7sdqJQ3llLGSynja9asabA0AACA/mkRWA8mOXy714cl+e52r/dPcmySr5dS7k1yQpIrpnrQRa31k7XWsVrr2PLlyxssDQAAoH9aBNa3khxZSnlGKWV+ktclueLxjbXWH9daD6y1rqi1rkhyQ5JX1lrHG8wNAAAwNGYcWLXWLUnOS3JVktuTXFprvbWU8s5SyitnOj4AAMBsMa/FILXWLyf58g7fe8dO9v35FnMCAAAMmyZvNAwAAIDAAgAAaEZgAQAANCKwAAAAGhFYAAAAjQgsAACARgQWAABAIwILAACgEYEFAADQiMACAABoRGABAAA0IrAAAAAaEVgAAACNCCwAAIBGBBYAAEAjAgsAAKARgQUAANCIwAIAAGhEYAEAADQisAAAABoRWAAAAI0ILAAAgEYEFgAAQCMCCwAAoBGBBQAA0IjAAgAAaERgAQAANCKwAAAAGhFYAAAAjQgsAACARgQWAABAIwILAACgEYEFAADQiMACAABoRGABAAA0IrAAAAAaEVgAAACNCCwAAIBGBBYAAEAjAgsAAKARgQUAANCIwAIAAGhEYAEAADQisAAAABoRWAAAAI0ILAAAgEYEFgAAQCMCCwAAoBGBBQAA0IjAAgAAaERgAQAANCKwAAAAGhFYAAAAjQgsAACARgQWAABAIwILAACgEYEFAADQiMACAABoRGABAAA0IrAAAAAaEVgAAACNCCwAAIBGBBYAAEAjAgsAAKARgQUAANCIwAIAAGhEYAEAADQisAAAABoRWAAAAI0ILAAAgEYEFgAAQCMCCwAAoBGBBQAA0IjAAgAAaERgAQAANCKwAAAAGhFYAAAAjQgsAACARgQWAABAIwILAACgEYEFAADQiMACAABoRGABAAA0IrAAAAAaEVgAAACNCCwAAIBGBBYAAEAjAgsAAKARgQUAANCIwAIAAGhEYAEAADQisAAAABoRWAAAAI0ILAAAgEYEFgAAQCMCCwAAoBGBBQAA0IjAAgAAaERgAQAANCKwAAAAGhFYAAAAjQgsAACARgQWAABAIwILAACgEYEFAADQiMACAABoRGABAAA0IrAAAAAaEVgAAACNCCwAAIBGBBYAAEAjTQKrlPLyUsodpZTVpZQLpth+finltlLKt0sp15RSjmgxLwAAwDCZcWCVUuYm+WiSU5McneT0UsrRO+x2c5KxWuvzklye5L0znRcAAGDYtDiD9cIkq2ut99RaNyX58ySnbb9DrfVrtdaJyZc3JDmswbwAAABDpUVgHZrkge1ePzj5vZ05J8lfT7WhlPLGUsp4KWV8zZo1DZYGAADQPy0Cq0zxvTrljqX8hyRjSS6aanut9ZO11rFa69jy5csbLA0AAKB/5jUY48Ekh2/3+rAk391xp1LKKUnenuSltdaNDeYFAAAYKi3OYH0ryZGllGeUUuYneV2SK7bfoZRyXJJPJHllrfXhBnMCAAAMnRkHVq11S5LzklyV5PYkl9Zaby2lvLOU8srJ3S5KsjTJZaWUW0opV+xkOAAAgFmrxSWCqbV+OcmXd/jeO7b7+pQW8wAAAAyzJm80DAAAgMACAABoRmABAAA0IrAAAAAaEVgAAACNCCwAAIBGBBYAAEAjAgsAAKARgQUAANCIwAIAAGhEYAEAADQisAAAABoRWAAAAI0ILAAAgEYEFgAAQCMCCwAAoBGBBQAA0IjAAgAAaERgAQAANCKwAAAAGhFYAAAAjQgsAACARgQWAABAI/MGvQAApmfTpuSLX+w+fvCDZP785Mgjkze8ITn22EGvDgBIBBbA0Fu3LvmDP0g+9rFk27Zk7dp/2fa3f5t86lPJUUd1+/zyLw9unQCASwQBhtqaNckLX5h88IPJj3/8xLhKkq1bk/Xrk5tvTl7zmuTCCwezTgCgI7AAhtS6dcnP/3xy113Jhg27339iIvnDP0w+/OGeLw0A2AmBBTCk3vOe5J57ks2bp/8zExPJ7/xO8t3v9m5dAMDOCSyAIbR5c3cmajpnrnZUa/Lxj7dfEwCwewILYAhdcUV3f9Xe2Lgx+chH9uzMFwDQhsACGEJXXvmTD7TYE5s3J//4j+3WAwBMj8ACGEIPPzyzn587N/nRj9qsBQCYPoEFMIQWLZr5GAsWzHwMAGDPCCyAIfTTP53st9/e//zGjcnhh7dbDwAwPQILYAidfXZ3md/eOv745OCD260HAJgegQUwhJ71rC6S9sb++3fvhQUA9J/AAhhS73rXnt+LNXductBByamn9mZNAMCuCSyAIfXSlybve9/0I2vevOSAA5KvfnVmlxcCAHtPYAEMsXPPTT7+8S6ydhVa++/fXVZ4883JYYf1b30AwBMJLIAhd8YZyQMPJP/zf3aX/y1enCxb1n0sWJD863+dXHZZctttyaGHDnq1ALBvK7XWQa9hSmNjY3V8fHzQywAYKtu2Jffc072J8Pz5ySGHJAceOOhVAcC+pZSyqtY6NtW2ef1eDAB7b86c5NnPHvQqAICdcYkgAABAIwILAACgEYEFAADQiMACAABoRGABAAA0IrAAAAAaEVgAAACNCCwAAIBGBBYAAEAjAgsAAKARgQUAANCIwAIAAGhEYAEAADQisAAAABoRWAAAAI0ILAAAgEYEFgAAQCMCCwAAoBGBBQAA0IjAAgAAaERgAQAANCKwAAAAGhFYAAAAjQgsAACARgQWAABAIwILAACgEYEFAADQiMACAABoRGABAAA0IrAAAAAaEVgAAACNCCwAAIBGBBYAAEAjAgsAAKARgQUAANCIwAIAAGhEYAEAADQisAAAABoRWAAAAI0ILAAAgEYEFgAAQCMCCwAAoBGBBQAA0IjAAgAAaERgAQAANCKwAAAAGhFYAAAAjQgsAACARgQWAABAIwILAACgEYEFAADQiMACAABoRGABAAA0IrAAAAAaEVgAAACNzBv0AoB9W63Jffcl4+PJ3/99cv/9ycaNyaJFydFHJ8cfn6xcmRx44KBXCgCwewILGIgf/Si55JLkoouSH/4w2W+/ZO3aLrget99+XWht2JA897nJ296WvOpV3fcBAIaRSwSBvtq6NfmjP0oOOST5vd9LvvOdZP365NFHnxhXSbJ5c/f9TZuSVauSc85JDj44+dKXBrN2AIDdEVhA39x5Z3LcccmFF3ZRNTGxZz+/dm3yT/+UvPa1ya/9WncWDABgmAgsoC9uvDEZG0tuvTVZt25mY01MJFdc0Y33/e+3WR8AQAsCC+i5m29OTjmlOwO1bVubMTdu7B6OceKJ3T1cAADDQGABPfXoo8kv/mLy2GPtx96ypbuH69Wv/sn7twAABkFgAT113nm9iavHbdrUPd79s5/t3RwAANMlsICeufba5Atf6B6z3kvr1iX/6T91D8AAABgkgQX0zDvfuedPCtxbW7cm/+t/9WcuAICdEVhAT9x3X3Lddf2bb/365AMfaPcQDQCAvSGwgJ740z/tf+ysW9ffqAMA2JHAAnriq1/tHkDRT48/8AIAYFCaBFYp5eWllDtKKatLKRdMsX1BKeXzk9tvLKWsaDEvMLxuuaX/c27c2D1YAwBgUGYcWKWUuUk+muTUJEcnOb2UcvQOu52T5JFa67OTXJzkPTOdFxheExPd+18Nwq23DmZeAICkzRmsFyZZXWu9p9a6KcmfJzlth31OS3LJ5NeXJ/mFUkppMDcwhCYmkrlzBzP3+vWDmRcAIGkTWIcmeWC71w9Ofm/KfWqtW5L8OMlTdxyolPLGUsp4KWV8zZo1DZYGDMKg4mrQcwMAtAisqc5E1b3YJ7XWT9Zax2qtY8uXL2+wNGAQli7t3pdqEJ785MHMCwCQtAmsB5Mcvt3rw5J8d2f7lFLmJXlSkh82mBsYQvvtlxx++O7364UTThjMvAAASZvA+laSI0spzyilzE/yuiRX7LDPFUnOnPz61Um+Wmv9iTNYwOh40Yv6P+fSpcmLX9z/eQEAHjfjwJq8p+q8JFcluT3JpbXWW0sp7yylvHJyt08neWopZXWS85P8xKPcgdFy6qld8PTTli3JS17S3zkBALZXhvVE0tjYWB0fHx/0MoC9NDGRPO1pybp1/ZvzxBOT667r33wAwL6plLKq1jo21bYmbzQMsKPFi5Ozzurux+qHpUuTt72tP3MBAOyMwAJ65nd/N1mwoPfzlJL81E8lv/IrvZ8LAGBXBBbQM4ccknzoQ8mSJb2dZ+HC5LLLvAcWADB4AgvoqbPO6u6NWriwN+MvWZK84x3J0Uf3ZnwAgD0hsICeKiX5y79MjjqqfWQtXpy8/vXuvQIAhofAAnpuyZLk7/4uWbmy3eWCixcnb3pT8vGPdxEHADAMBBbQF0uXJtdem/yP/5EsWpTM2cvfPgsWJAcc0N1z9YEPiCsAYLgILKBv5s5N3vrW5JZbkl/8xS6WpvuUwSVLujA766zk7ruTX/7l3q4VAGBvzBv0AoB9z0//dPLXf5185zvJxz6W/MVfJKtXd/dobX9ma/Pm7vOxxyZnn93db7V06WDWDAAwHaXWOug1TGlsbKyOj48PehlAn2zZktx2W/Lww8mmTd2ZrWc8o/twGSAAMExKKatqrWNTbXMGCxgK8+Ylz3veoFcBADAz7sECAABoRGABAAA0IrAAAAAaEVgAAACNCCwAAIBGBBYAAEAjAgsAAKARgQUAANCIwAIAAGhEYAEAADQisAAAABoRWAAAAI0ILAAAgEYEFgAAQCMCCwAAoBGBBQAA0IjAAgAAaERgAQAANCKwAAAAGhFYAAAAjQgsAACARgQWAABAIwILAACgEYEFAADQiMACAABoRGABAAA0IrAAAAAaEVgAAACNCCwAAIBGBBYAAEAjAgsAAKARgQUAANCIwAIAAGhEYAEAADQisAAAABoRWAAAAI0ILAAAgEYEFgAAQCMCCwAAoBGBBQAA0IjAAgAAaERgAQAANCKwAAAAGhFYAAAAjQgsAACARgQWAABAIwILAACgEYEFAADQiMACAABoRGABAAA0IrAAAAAaEVgAAACNCCwAAIBGBBYAAEAjAgsAAKARgQUAANCIwAIAAGhEYAEAADQisAAAABoRWAAAAI0ILAAAgEYEFgAAQCMCCwAAoBGBBQAA0IjAAgAAaERgAQAANCKwAAAAGhFYAAAAjQgsAACARgQWAABAIwILAACgEYEFAADQiMACAABoRGABAAA0IrAAAAAaEVgAAACNCCwAAIBGBBYAAEAjAgsAAKARgQUAANCIwAIAAGhEYAEAADQisAAAABoRWAAAAI0ILAAAgEYEFgAAQCMCCwAAoBGBBQAA0IjAAgAAaERgAQAANCKwAAAAGhFYAAAAjQgsAACARgQWAABAIwILAACgEYEFAADQiMACAABoRGABAAA0IrAAAAAamVFglVIOKKV8pZRy1+Tnp0yxzwtKKdeXUm4tpXy7lPLamcwJAAAwrGZ6BuuCJNfUWo9Mcs3k6x1NJDmj1npMkpcn+WAp5ckznBcAAGDozDSwTktyyeTXlyR51Y471FrvrLXeNfn1d5M8nGT5DOcFAAAYOjMNrKfXWh9KksnPT9vVzqWUFyaZn+TunWx/YyllvJQyvmbNmhkuDQAAoL/m7W6HUsrVSQ6aYtPb92SiUsrBST6b5Mxa67ap9qm1fjLJJ5NkbGys7sn4AAAAg7bbwKq1nrKzbaWU75dSDq61PjQZUA/vZL9lSa5M8vu11hv2erUAAABDbKaXCF6R5MzJr89M8lc77lBKmZ/ki0k+U2u9bIbzAQAADK2ZBta7k7yslHJXkpdNvk4pZayU8seT+/xakpck+Y1Syi2THy+Y4bwAAABDp9Q6nLc6jY2N1fHx8UEvAwAA4AlKKatqrWNTbZvpGSwAAAAmCSwAAIBGBBYAAEAjAgsAAKARgQUAANCIwAIAAGhEYAEAADQyb9ALAAAASJJs3Zrcc0+ydm1SSvKUpyRHHNF9PUsILAAAYHDuuy/52MeSK69M7rormTcvmTu3i6rNm5Nak6OPTl7zmuScc5IDDxz0inep1FoHvYYpjY2N1fHx8UEvAwAA6IXbb0/OOy+57rpk27Zk06Zd779oURdbr3hF8sEPJocc0p91TqGUsqrWOjbVNvdgAQAA/bN1a/KHf5isXJl87WvJhg27j6skWb++2/eLX0ye85zkM5/pgmvICCwAAKA/JiaSU05JLrywC6a9CaQtW5LHHkvOPTc566wu2IaIe7AAAIDe27gxednLkptu6s5EzdS6dclll3WXF15yydA8CMMZLAAAoPfOOy+5+eY2cfW4iYnkC1/o7skaEgILAADora9/PfmzP+suC2xtYiL5/d9PVq9uP/ZeEFgAAEDvbNmS/Pt/35u4etyGDckZZ/Ru/D0gsAAAgN658sruoRS9tG1bcsstyW239XaeaRBYAABA77znPcnatb2fZ/Pm5OKLez/PbggsAACgN9auTcbH+zPXli3J5Zf3Z65dEFgAAEBv3HxzsmhR/+Zbvz753vf6N98UBBYAANAbN93Uvf9VvyxYkKxa1b/5piCwAACA3vjOd/obWFu3Jt//fv/mm4LAAgAAemPz5v7Ot21b/+fcgcACAAB6Y+nS/s43d26yeHF/59yBwAIAAHrj6KOT/ffv33ylJD/zM/2bbwoCCwAA6I2VK7vL9vplw4bkuc/t33xTEFgAAEBvHHlkMqePyXHkkd2TBAdIYAEAAL0xZ05yzjnJ/Pm9n2vp0uT883s/z24ILAAAoHf+83/uz1msbduS00/v/Ty7IbAAAIDeeeYzk1e/Olm4sHdzLFmSvP3tA3+CYCKwAACAXvvoR3v3yPY5c5JnPCN529t6M/4eElgAAEBvLVuWXHppsmhR+7GXLEkuv7x7D6whILAAAIDe+1f/KrnkkraRtXRpctVVyXOe027MGRJYAABAf7zmNclf/EV3RmsmTxZctCg56KDk2muTE09st74GBBYAANA/L395ctddyS/8Qnd5XynT/9m5c7u4+vVfT1avTn72Z3u3zr0ksAAAgP562tOSK69M/uZvkle8onvC4LJlUz/Ofb/9um2LFiVnnJHceGPyiU90cTaE5g16AQAAwD6olOSkk7qPNWuS665L/v7vk+uvT3784277gQcmJ5+cjI11lwIuWzboVe+WwAIAAAZr+fLktNO6j1nOJYIAAACNCCwAAIBGBBYAAEAjAgsAAKARgQUAANCIwAIAAGhEYAEAADQisAAAABoRWAAAAI0ILAAAgEYEFgAAQCMCCwAAoBGBBQAA0IjAAgAAaERgAQAANCKwAAAAGpk36AUA9NPmzcmttyarViXf+173esGC5FnPSlauTJ75zKSUQa8SAJitBBYw8rZtS66+Onnve5NvfCNZuLD73sREUmsyd26yeHGydWsXV6efnvyX/5Icc8ygVw4AzDYuEQRG2te+lhxxRPKrv5pcc013xmrt2mTdui6uki6s1q7tgmvduuR//+/k+OOTk09O7r13kKsHAGYbgQWMpHXrknPOSX7lV5IHH0wee2z6P7tlS7J+fXL99d1ZrI9+9F9iDABgVwQWMHL+6Z+SF70o+dznurNSe2vr1u7nf+d3krPP7i4rBADYFfdgASPl0UeTk05K7r67uxywhYmJ5NJLu/uzPv1pD8EAAHbOGSxgpJxxRvL//l+7uHrcxETy+c8nn/pU23EBgNEisICR8cUvJl/5SrJxY2/Gn5hIzj8/uf/+3owPAMx+AgsYCRMT3X1SM7nnajo2buwengEAMBWBBYyEz32u/WWBU9myJfnmN7t7vAAAdiSwgFmv1uTd7+4ezd4PW7cmH/5wf+YCAGYXgQXMeqtXJw891L/5Nm9O/vRP+zcfADB7CCxg1hsfT+bO7e+cjz2WPPxwf+cEAIafwAJmveuv74KnnxYuTFat6u+cAMDwE1jArHf77d19WP20aVNy7739nRMAGH4CC5j1Nmzo/5xbtw5mXgBguAksYNabP7//c86ZM5h5AYDhJrCAWe9Zz+r/nPPnJ4ce2v95AYDhJrCAWe/FL06WLOnvnJs3J2Nj/Z0TABh+AguY9Vau7P+c8+Y5gwUA/CSBBcx6xxyTLFvWv/nmzk1e9aqklP7NCQDMDgILmPXmzEnOPz9ZvLg/882f380HALAjgQWMhLPP7s88pSRHHZW84AX9mQ8AmF0EFjASDjggee97e/+wi4ULk0su6e0cAMDsJbCAkfHmNyfHHts9gKIXFi9O3va25LnP7c34AMDsJ7CAkTFnTvKFL3Rns+Y0/u22cGFywgnJ29/edlwAYLQILGCkHHpocv31yfLl7c5kLV7cxdWXvtS7s2MAwGgQWMDIeeYzk5tu6qJopvdkLVrUPUDjqqu6rwEAdkVgASPpkEOSb3wjufjiLrL2NLT23z857LDk6quTD3+4ezQ7AMDuCCxgZJWSvOENyUMPJe97X7JiRXcWatmyn3yT4P32S570pC6kTjop+dznknvvTV784kGsHACYrUqtddBrmNLY2FgdHx8f9DKAEVJrct99yapVyY03dl9v3NjdY3Xsscnxxyc/+7PJU5866JUCAMOslLKq1jo21Ta3awP7jFK6s1grViS/+quDXg0AMIpcIggAANCIwAIAAGhEYAEAADQisAAAABoRWAAAAI0ILAAAgEYEFgAAQCMCCwAAoBGBBQAA0IjAAgAAaERgAQAANCKwAAAAGhFYAAAAjQgsAACARgQWAABAIwILAACgEYEFAADQiMACAABoRGABAAA0IrAAAAAaEVgAAACNCCwAAIBGBBYAAEAjAgsAAKARgQUAANDIjAKrlHJAKeUrpZS7Jj8/ZRf7LiulfKeU8pGZzAkAADCsZnoG64Ik19Raj0xyzeTrnXlXkmtnOB8AAMDQmmlgnZbkksmvL0nyqql2KqWsTPL0JH87w/kAAACG1kwD6+m11oeSZPLz03bcoZQyJ8n7k/z27gYrpbyxlDJeShlfs2bNDJcGAADQX/N2t0Mp5eokB02x6e3TnOPcJF+utT5QStnljrXWTyb5ZJKMjY3VaY4PAAAwFHYbWLXWU3a2rZTy/VLKwbXWh0opByd5eIrdTkxycinl3CRLk8wvpTxWa93V/VoAAACzzm4DazeuSHJmkndPfv6rHXeotb7+8a9LKb+RZExcAQAAo2im92C9O8nLSil3JXnZ5OuUUsZKKX8808UBAADMJqXW4bzVaWxsrI6Pjw96GQAAAE9QSllVax2battMz2ABAAAwSWABAAA0IrAAAAAaEVgAAACNCCwAAIBGBBYAAEAjAgsAAKARgQUAANCIwAIAAGhEYAEAADQisAAAABoRWAAAAI0ILAAAgEYEFgAAQL2ks5EAAAkXSURBVCMCCwAAoBGBBQAA0IjAAgAAaERgAQAANCKwAAAAGhFYAAAAjcwb9AJmhfXrk5tuSlatSm64IfnhD5NSkoMOSk48MVm5Mnn+85N5/nMCAMC+TBHsyh13JBdfnHz2s108bdqUbNjwxH0uvTSZO7f7OO+85M1vTg45ZDDrBQAABsolglNZty5505uS445LPv3pZGIiefTRn4yrpNu2dm3yox8lF12UPPvZyYUXJlu29H/dAADAQAmsHa1a1UXSZz/bXRq4J6G0cWP3M3/0R12c3X9/79YJAAAMHYG1vW9+M3npS5Pvfa8Lpb21bl1y++3dvVl3391ufQAAwFATWI+79dbk1FO7OGph69buYRg/93PJD37QZkwAAGCoCawk2bw5+Xf/rl1cPW7btuSRR5Kzz247LgAAMJQEVpL8wR8kDz6Y1Np+7E2bkmuuSb7whfZjAwAAQ0VgPfpo9/S/iYnezTExkfzX/9qbgAMAAIaGwPrMZ5I5ffjP8MgjybXX9n4eAABgYATWhz7U/t6rqaxb180FAACMrH07sNatS+69tz9z1Zpcd11/5gIAAAZi3w6sf/iHZPHi/s33yCPdBwAAMJL27cC6447u/ar6ZfHi5M47+zcfAADQV/t2YK1f371XVb/nBAAARtK+HVj77ZeU0v85AQCAkbRvB9Yhh/Q3eDZv7uYEAABG0r4dWCtXJhs29G++UpIVK/o3HwAA0Ff7dmAddFB/nyJ47LH9vyQRAADom307sJLk9a/vz2WCS5cmb3hD7+cBAAAGRmD95m8mc+f2fp5t25LTT+/9PAAAwMAIrCOPTE4+OZk3r3dzLFqUnHtufy9HBAAA+k5gJcmf/EmycGHvxn/qU5N3vrN34wMAAENBYCXJoYcmH/lIb84wLVqUXHZZ9xkAABhpAutxZ56ZvOUtbSNr0aLkU59KTjih3ZgAAMDQEljbu/DC5IILZn62ac6cbow/+ZPuKYUAAMA+QWBtr5Tkv/235KqrkoMP3rvQWrIkOeaY5Kabkte+tv0aAQCAoSWwpnLyyclddyW/93vJgQcm+++/6/1L6cJqxYrk/e9Pbr45OeqoviwVAAAYHqXWOug1TGlsbKyOj48PehnJ1q3Jl7/cndX65jeTO+9MNmzoomrx4u5s1UtekrziFclJJ3XfBwAARlYpZVWtdWyqbT1886cRMXduF0+veMWgVwIAAAw5lwgCAAA0IrAAAAAaEVgAAACNCCwAAIBGBBYAAEAjAgsAAKARgQUAANCIwAIAAGhEYAEAADQisAAAABoRWAAAAI0ILAAAgEYEFgAAQCMCCwAAoBGBBQAA0IjAAgAAaERgAQAANCKwAAAAGhFYAAAAjQgsAACARgQWAABAIwILAACgkVJrHfQaplRKWZPkvkGvY5Y6MMkPBr0IesoxHm2O7+hzjEeb4zv6HOPRNp3je0StdflUG4Y2sNh7pZTxWuvYoNdB7zjGo83xHX2O8WhzfEefYzzaZnp8XSIIAADQiMACAABoRGCNpk8OegH0nGM82hzf0ecYjzbHd/Q5xqNtRsfXPVgAAACNOIMFAADQiMACAABoRGCNgFLKAaWUr5RS7pr8/JRd7LuslPKdUspH+rlGZmY6x7iUckQpZVUp5ZZSyq2llP84iLWy56Z5fF9QSrl+8th+u5Ty2kGslb0z3d/TpZS/KaX8qJTypX6vkT1XSnl5KeWOUsrqUsoFU2xfUEr5/OT2G0spK/q/SvbWNI7vS0opN5VStpRSXj2INTIz0zjG55dSbpv8/+41pZQjpjOuwBoNFyS5ptZ6ZJJrJl/vzLuSXNuXVdHSdI7xQ0leXGt9QZIXJbmglHJIH9fI3pvO8Z1Ickat9ZgkL0/ywVLKk/u4RmZmur+nL0ry631bFXutlDI3yUeTnJrk6CSnl1KO3mG3c5I8Umt9dpKLk7ynv6tkb03z+N6f5DeSfK6/q6OFaR7jm5OM1Vqfl+TyJO+dztgCazScluSSya8vSfKqqXYqpaxM8vQkf9unddHObo9xrXVTrXXj5MsF8ed7NpnO8b2z1nrX5NffTfJwkinfQZ6hNK3f07XWa5Ks7deimJEXJllda72n1ropyZ+nO87b2/64X57kF0oppY9rZO/t9vjWWu+ttX47ybZBLJAZm84x/lqtdWLy5Q1JDpvOwP4CNhqeXmt9KEkmPz9txx1KKXOSvD/Jb/d5bbSx22OcJKWUw0sp307yQJL3TP5FnOE3reP7uFLKC5PMT3J3H9ZGG3t0jJkVDk33u/ZxD05+b8p9aq1bkvw4yVP7sjpmajrHl9ltT4/xOUn+ejoDz5vBouijUsrVSQ6aYtPbpznEuUm+XGt9wD+eDacGxzi11geSPG/y0sC/LKVcXmv9fqs1svdaHN/JcQ5O8tkkZ9Za/avpEGl1jJk1pvqf6Y7vfTOdfRhOjt3om/YxLqX8hyRjSV46nYEF1ixRaz1lZ9tKKd8vpRxca31o8i9fD0+x24lJTi6lnJtkaZL5pZTHaq27ul+LPmpwjLcf67ullFuTnJzushQGrMXxLaUsS3Jlkt+vtd7Qo6Wyl1r+GWZWeDDJ4du9PizJjlcNPL7Pg6WUeUmelOSH/VkeMzSd48vsNq1jXEo5Jd0/lL10u1sxdsklgqPhiiRnTn59ZpK/2nGHWuvra60/VWtdkeStST4jrmaV3R7jUsphpZRFk18/JcnPJbmjbytkJqZzfOcn+WK6P7uX9XFttLHbY8ys860kR5ZSnjH55/N16Y7z9rY/7q9O8tVaq7Mgs8N0ji+z226PcSnluCSfSPLKWuu0/2FMYI2Gdyd5WSnlriQvm3ydUspYKeWPB7oyWpnOMf6ZJDeWUv4h3ZMi31dr/T8DWS17ajrH99eSvCTJb0w+iv+WUsoLBrNc9sK0fk+XUv4uyWXpHobwYCnllwayWnZr8p6q85JcleT2JJfWWm8tpbyzlPLKyd0+neSppZTVSc7Prp/yyxCZzvEtpRxfSnkwyWuSfGLyyhFmiWn+Gb4o3ZVfl03+f3dakV38QwoAAEAbzmABAAA0IrAAAAAaEVgAAACNCCwAAIBGBBYAAEAjAgsAAKARgQUAANDI/wf5piX0aCTnAwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sinkhorn divergences over actual points. blur, cluster_scale = 0.0625 0.1\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]], grad_fn=<CopySlices>) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]], grad_fn=<CopySlices>) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]], grad_fn=<CopySlices>) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]], grad_fn=<CopySlices>) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]], grad_fn=<CopySlices>) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]], grad_fn=<CopySlices>) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]], grad_fn=<CopySlices>) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]], grad_fn=<CopySlices>) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]], grad_fn=<CopySlices>) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]], grad_fn=<CopySlices>) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]], grad_fn=<CopySlices>) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]], grad_fn=<CopySlices>) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]], grad_fn=<CopySlices>) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]], grad_fn=<CopySlices>) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]], grad_fn=<CopySlices>) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]], grad_fn=<CopySlices>) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]], grad_fn=<CopySlices>) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]], grad_fn=<CopySlices>) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]], grad_fn=<CopySlices>) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]], grad_fn=<CopySlices>) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]], grad_fn=<CopySlices>) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]], grad_fn=<CopySlices>) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]], grad_fn=<CopySlices>) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]], grad_fn=<CopySlices>) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32) None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]], grad_fn=<IndexBackward>) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) None None None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) None None None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) None None None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]], grad_fn=<IndexBackward>) tensor([[-0.4325, -0.4685],\n",
      "        [-0.2870,  0.4321],\n",
      "        [ 0.1750, -0.2466]]) None None None\n",
      "x, y, ranges_x, ranges_y, ranges_xy = tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]], grad_fn=<IndexBackward>) tensor([[-0.2304, -0.3259],\n",
      "        [-0.2528,  0.0006],\n",
      "        [-0.1919,  0.1364]]) None None (tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32), tensor([2, 5, 7], dtype=torch.int32), tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32), tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32), tensor([2, 5, 7], dtype=torch.int32), tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3],\n",
      "        [1, 2],\n",
      "        [2, 3]], dtype=torch.int32))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[KeOps] Wrong value of the 'j' dimension 0for arg number 2 : is 9 but was 3 in previous 'j' arguments.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f527f5b02fa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m Loss_p2 = SamplesLoss(\"sinkhorn\", p=2, blur=blur, diameter=1., cluster_scale = cluster_scale,\n\u001b[1;32m     60\u001b[0m                         scaling=scaling, backend=\"multiscale\")\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mloss_p2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoss_p2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/geomloss/samples_loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0mdebias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpotentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotentials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                     \u001b[0mlabels_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                     verbose = self.verbose )\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/geomloss/sinkhorn_samples.py\u001b[0m in \u001b[0;36msinkhorn_multiscale\u001b[0;34m(α, x, β, y, p, blur, reach, diameter, scaling, truncate, cost, cluster_scale, debias, potentials, labels_x, labels_y, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m                                         \u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                                         \u001b[0mextrapolate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextrapolate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                                         debias = debias)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msinkhorn_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mε\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mρ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mα\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mβ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpotentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpotentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/geomloss/sinkhorn_divergence.py\u001b[0m in \u001b[0;36msinkhorn_loop\u001b[0;34m(softmin, α_logs, β_logs, C_xxs, C_yys, C_xys, C_yxs, ε_s, ρ, jumps, kernel_truncation, truncate, cost, extrapolate, debias, last_extrapolation)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# \"Coordinate ascent\" on the dual problems:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdebias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mat_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mλ\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msoftmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mε\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_xx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mα_log\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma_x\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mε\u001b[0m \u001b[0;34m)\u001b[0m  \u001b[0;31m# OT(α,α)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0mbt_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mλ\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msoftmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mε\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_yy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mβ_log\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_y\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mε\u001b[0m \u001b[0;34m)\u001b[0m  \u001b[0;31m# OT(β,β)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mat_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mλ\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msoftmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mε\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_yx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mα_log\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_x\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mε\u001b[0m \u001b[0;34m)\u001b[0m  \u001b[0;31m# OT(α,β) wrt. a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/geomloss/sinkhorn_samples.py\u001b[0m in \u001b[0;36msoftmin_multiscale\u001b[0;34m(ε, C_xy, f_y, log_conv)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x, y, ranges_x, ranges_y, ranges_xy =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranges_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranges_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranges_xy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m# KeOps is pretty picky on the input shapes...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mε\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_conv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mε\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranges\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mranges_xy\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pykeops/torch/generic/generic_red.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, backend, device_id, ranges, *args)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \"\"\"\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenredAutograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maliases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0mnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maliases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mnout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pykeops/torch/generic/generic_red.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, formula, aliases, backend, dtype, device_id, ranges, *args)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_aliases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maliases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         result = myconv.genred_pytorch(tagCPUGPU, tag1D2D, tagHostDevice, device_id, ranges, categories, dimensions,\n\u001b[0;32m---> 43\u001b[0;31m                                        *args)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# relying on the 'ctx.saved_variables' attribute is necessary  if you want to be able to differentiate the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [KeOps] Wrong value of the 'j' dimension 0for arg number 2 : is 9 but was 3 in previous 'j' arguments."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "scaling, Nits = .5, 9\n",
    "cluster_scale = .1 if not use_cuda else .05\n",
    "i = 3\n",
    "blur = scaling**i\n",
    "\n",
    "if blur > cluster_scale:\n",
    "    print('Calculating Sinkhorn divergences over coarse clusters. blur, cluster_scale =', blur, cluster_scale)\n",
    "else:\n",
    "    print('Calculating Sinkhorn divergences over actual points. blur, cluster_scale =', blur, cluster_scale)\n",
    "\n",
    "# Create a copy of the data...\n",
    "A_i_torch = torch.from_numpy(A_i).type(dtype)\n",
    "X_i_torch = torch.from_numpy(X_i).contiguous().type(dtype)\n",
    "B_j_torch = torch.from_numpy(B_j).type(dtype)\n",
    "Y_j_torch = torch.from_numpy(Y_j).contiguous().type(dtype)\n",
    "a_i, x_i = A_i_torch.clone(), X_i_torch.clone()\n",
    "b_j, y_j = B_j_torch.clone(), Y_j_torch.clone()\n",
    "\n",
    "# And require grad:\n",
    "a_i.requires_grad = True\n",
    "x_i.requires_grad = True\n",
    "b_j.requires_grad = True\n",
    "\n",
    "# Compute the loss + gradients:\n",
    "# Loss_p1 = SamplesLoss(\"sinkhorn\", p=1, blur=blur, diameter=1., cluster_scale = cluster_scale,\n",
    "#                         scaling=scaling, backend=\"multiscale\", verbose=True)\n",
    "# loss_p1 = Loss_p1(a_i, x_i, b_j, y_j)\n",
    "Loss_p2 = SamplesLoss(\"sinkhorn\", p=2, blur=blur, diameter=1., cluster_scale = cluster_scale,\n",
    "                        scaling=scaling, backend=\"multiscale\", verbose=True)\n",
    "loss_p2 = Loss_p2(a_i, x_i, b_j, y_j)\n",
    "\n",
    "\n",
    "# print(\"Loss_p1 =\", Loss_p1, \"Loss_p2 =\", Loss_p2)\n",
    "print(\"loss_p1 =\", loss_p1, \"loss_p2 =\", loss_p2)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=((12, 9)))\n",
    "\n",
    "size_scale = 2000\n",
    "ax = plt.scatter(X_i[:, 0], X_i[:, 1], s=size_scale * A_i, c='blue')\n",
    "ax = plt.scatter(Y_j[:, 0], Y_j[:, 1], s=size_scale * B_j, c='red')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "i = 4\n",
    "blur = scaling**i\n",
    "\n",
    "if blur > cluster_scale:\n",
    "    print('Calculating Sinkhorn divergences over coarse clusters. blur, cluster_scale =', blur, cluster_scale)\n",
    "else:\n",
    "    print('Calculating Sinkhorn divergences over actual points. blur, cluster_scale =', blur, cluster_scale)\n",
    "Loss_p2 = SamplesLoss(\"sinkhorn\", p=2, blur=blur, diameter=1., cluster_scale = cluster_scale,\n",
    "                        scaling=scaling, backend=\"multiscale\")\n",
    "loss_p2 = Loss_p2(a_i, x_i, b_j, y_j)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=( (12, ((Nits-1)//3 + 1) * 4)))\n",
    "\n",
    "from pykeops.torch.cluster import grid_cluster, cluster_ranges_centroids\n",
    "for i in range(Nits):\n",
    "    blur = scaling**i\n",
    "    Loss = SamplesLoss(\"sinkhorn\", p=2, blur=blur, diameter=1., cluster_scale = cluster_scale,\n",
    "                        scaling=scaling, backend=\"multiscale\")\n",
    "\n",
    "    # Create a copy of the data...\n",
    "    A_i_torch = torch.from_numpy(A_i).type(dtype)\n",
    "    X_i_torch = torch.from_numpy(X_i).contiguous().type(dtype)\n",
    "    B_j_torch = torch.from_numpy(B_j).type(dtype)\n",
    "    Y_j_torch = torch.from_numpy(Y_j).contiguous().type(dtype)\n",
    "    a_i, x_i = A_i_torch.clone(), X_i_torch.clone()\n",
    "    b_j, y_j = B_j_torch.clone(), Y_j_torch.clone()\n",
    "\n",
    "\n",
    "    # And require grad:\n",
    "    a_i.requires_grad = True\n",
    "    x_i.requires_grad = True\n",
    "    b_j.requires_grad = True\n",
    "\n",
    "    # Compute the loss + gradients:\n",
    "    Loss_xy = Loss(a_i, x_i, b_j, y_j)\n",
    "#     [F_i, G_j, dx_i] = grad( Loss_xy, [a_i, b_j, x_i] )\n",
    "\n",
    "#     print(\"F_i.shape, dx_i.shape\", F_i.shape, dx_i.shape)\n",
    "    print(\"Loss_xy\", Loss_xy)\n",
    "    # The generalized \"Brenier map\" is (minus) the gradient of the Sinkhorn loss\n",
    "    # with respect to the Wasserstein metric:\n",
    "#     BrenierMap = - dx_i / (a_i.view(-1,1) + 1e-7)\n",
    "\n",
    "    # Compute the coarse measures for display ----------------------------------\n",
    "\n",
    "    x_lab = grid_cluster(x_i, cluster_scale)\n",
    "    _, x_c, a_c = cluster_ranges_centroids(x_i, x_lab, weights=a_i)\n",
    "\n",
    "    y_lab = grid_cluster(y_j, cluster_scale)\n",
    "    _, y_c, b_c = cluster_ranges_centroids(y_j, y_lab, weights=b_j)\n",
    "\n",
    "\n",
    "    # Fancy display: -----------------------------------------------------------\n",
    "\n",
    "    ax = plt.subplot(((Nits-1)//3 + 1) , 3, i+1)\n",
    "    ax.scatter( [10], [10] )  # shameless hack to prevent a slight change of axis...\n",
    "    \n",
    "#     display_potential(ax, G_j, \"#E2C5C5\")\n",
    "#     display_potential(ax, F_i, \"#C8DFF9\")\n",
    "\n",
    "\n",
    "#     if blur > cluster_scale:\n",
    "#         display_samples(ax, y_j, b_j, [(.55,.55,.95, .2)])\n",
    "#         display_samples(ax, x_i, a_i, [(.95,.55,.55, .2)], v = BrenierMap)\n",
    "#         display_samples(ax, y_c, b_c, [(.55,.55,.95)])\n",
    "#         display_samples(ax, x_c, a_c, [(.95,.55,.55)])\n",
    "\n",
    "#     else:\n",
    "#     display_samples(ax, y_j, b_j, [(.55,.55,.95)])\n",
    "#     display_samples(ax, x_i, a_i, [(.95,.55,.55)])#, v = BrenierMap)\n",
    "\n",
    "\n",
    "    ax.set_title(\"iteration {}, blur = {:.3f}\".format(i+1, blur))\n",
    "\n",
    "    ax.set_xticks([0, 1]) ; ax.set_yticks([0, 1])\n",
    "    ax.axis([0,1,0,1]) ; ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
